{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "from matplotlib import pyplot\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from itertools import product\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dash import html\n",
    "from dash import dcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Delay Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "#Wait Assessment 2020 Onwards - \"https://data.ny.gov/resource/swky-c3v4.csv\"\n",
    "\n",
    "# Create a directory to store the csv files\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Download the csv file\n",
    "wait_assessment_2020 = \"https://data.ny.gov/resource/swky-c3v4.csv?$limit=1000000000\"\n",
    "response = requests.get(wait_assessment_2020)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"wait_assessment_2020.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "wait_assessment_2020 = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column and row count\n",
    "print(wait_assessment_2020.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "wait_assessment_2020.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column name and data type\n",
    "print(wait_assessment_2020.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Split the month and year into separate columns\n",
    "wait_assessment_2020[[\"Year\", \"Month\"]] = wait_assessment_2020[\"month\"].str.split(\"-\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataframe\n",
    "wait_assessment_2020.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Wait Assessment 2015 - 2019 - \"https://data.ny.gov/resource/bmix-dpzc.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "wait_assessment_2015 = \"https://data.ny.gov/resource/bmix-dpzc.csv?$limit=1000000000\"\n",
    "response = requests.get(wait_assessment_2015)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"wait_assessment_2015.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "wait_assessment_2015 = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(wait_assessment_2015.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "wait_assessment_2015.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Split the month and year into separate columns\n",
    "wait_assessment_2015[[\"Year\", \"Month\"]] = wait_assessment_2015[\"month\"].str.split(\"-\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the two dataframes\n",
    "wait_assessment_2015_2020 = pd.concat([wait_assessment_2020, wait_assessment_2015], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(wait_assessment_2015_2020.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "wait_assessment_2015_2020.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Deliviered 2020 Onwards - \"https://data.ny.gov/resource/2e6s-9gpm.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "service_delivered_2020 = \"https://data.ny.gov/resource/2e6s-9gpm.csv?$limit=1000000000\"\n",
    "response = requests.get(service_delivered_2020)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"service_delivered_2020.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "service_delivered_2020 = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Deliviered 2015 - 2019 - \"https://data.ny.gov/resource/tw28-zvtk.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "service_delivered_2015 = \"https://data.ny.gov/resource/tw28-zvtk.csv?$limit=1000000000\"\n",
    "response = requests.get(service_delivered_2015)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"service_delivered_2015.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "service_delivered_2015 = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Traffic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a large file and takes some time to download.  It is not included in the repository. but the transformed data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly Traffic on (MTA) Bridges and Tunnels: Beginning 2010 - \"https://data.ny.gov/resource/qzve-kjga.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "hourly_traffic = \"https://data.ny.gov/resource/qzve-kjga.csv?$limit=1000000000\"\n",
    "response = requests.get(hourly_traffic)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"hourly_traffic.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "hourly_traffic = pd.read_csv(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the csv file for hourly_traffic\n",
    "hourly_traffic = pd.read_csv('hourly_traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(hourly_traffic.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "hourly_traffic.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new column named total_vehicles by adding the vehicles_e_zpass and vehicles_vtoll columns\n",
    "hourly_traffic[\"total_vehicles\"] = hourly_traffic[\"vehicles_e_zpass\"] + hourly_traffic[\"vehicles_vtoll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the year from the date_time column\n",
    "hourly_traffic[\"year\"] = hourly_traffic[\"date\"].str[:4]\n",
    "\n",
    "# Extract the month from the date column\n",
    "hourly_traffic[\"month\"] = hourly_traffic[\"date\"].str[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the dataframe to group by the Year, Month, plaza_id, and direction columns, giving the sum of the total_vehicles, vehicles_e_zpass, and vehicles_vtoll columns\n",
    "hourly_traffic_transformed = hourly_traffic.groupby([\"year\", \"month\", \"plaza_id\", \"direction\"]).agg({\"total_vehicles\": \"sum\", \"vehicles_e_zpass\": \"sum\", \"vehicles_vtoll\": \"sum\"}).reset_index()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(hourly_traffic_transformed.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "hourly_traffic_transformed.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column named 'value_type', all the values in this column should say 'vehicle_count'\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.assign(value_type=\"vehicle_count\")\n",
    "\n",
    "# change the plaza_id column to location_id, and change total_vehicles to value\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.rename(columns={\"plaza_id\": \"location_id\", \"total_vehicles\": \"value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep columns 1-5 and column 8 and drop the rest\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.iloc[:, list(range(5)) + [7]]\n",
    "\n",
    "# swap the order of the last 2 columns\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.iloc[:, [0, 1, 2, 3, 5, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column named 'data_source', all the values in this column should say 'hourly_traffic'\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.assign(data_source=\"hourly_traffic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "hourly_traffic_transformed.to_csv(\"hourly_traffic_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file for hourly_traffic_transformed\n",
    "hourly_traffic_transformed = pd.read_csv(\"hourly_traffic_transformed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hourly_traffic_transformed is one traffic df\n",
    "columns are:\n",
    "year\n",
    "month\n",
    "location_id\n",
    "direction\n",
    "value_type\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following csv is a large file available at https://data.cityofnewyork.us/resource/7ym2-wayt\n",
    "The full file has been downloaded and is used in the following script.\n",
    "The aggregate output will also be made available and it is recommended this is the version to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a CSV file and write it to a df using pandas\n",
    "# Open the CSV file\n",
    "\n",
    "traffic_speeds = pd.read_csv('DOT_Traffic_Speeds_NBE_20240121.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_backup = traffic_speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(traffic_speeds.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "traffic_speeds.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the Speed, travel_time, status, data_as_of, link_id, and borough columns\n",
    "traffic_speeds = traffic_speeds[['SPEED', 'TRAVEL_TIME', 'STATUS', 'DATA_AS_OF', 'LINK_ID', 'BOROUGH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the data_as_of column which is in the format of 09/20/2019 07:27:03 AM\n",
    "traffic_speeds[\"year\"] = traffic_speeds[\"DATA_AS_OF\"].str[6:10]\n",
    "\n",
    "# Extract the month from the data_as_of column which is in the format of 09/20/2019 07:27:03 AM\n",
    "traffic_speeds[\"month\"] = traffic_speeds[\"DATA_AS_OF\"].str[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by the Year, Month, and BOROUGH and LINK_ID, columns, giving the mean of the speed and travel_time columns\n",
    "traffic_speeds_transformed = traffic_speeds.groupby([\"year\", \"month\", \"BOROUGH\", \"LINK_ID\"]).agg({\"SPEED\": \"mean\", \"TRAVEL_TIME\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(traffic_speeds_transformed.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "traffic_speeds_transformed.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "traffic_speeds_transformed.to_csv(\"traffic_speeds_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load the transformed dataframe from a csv file\n",
    "traffic_speeds_transformed = pd.read_csv(\"traffic_speeds_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the dataframe so that the values in the speed and travel_time columns are in the same column and the column names are in a column named 'value_type'\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.melt(id_vars=[\"year\", \"month\", \"BOROUGH\", \"LINK_ID\"], value_vars=[\"SPEED\", \"TRAVEL_TIME\"], var_name=\"value_type\", value_name=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase the value_type column\n",
    "traffic_speeds_transformed[\"value_type\"] = traffic_speeds_transformed[\"value_type\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the BOROUGH column and change the LINK_ID column to location_id\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.drop(columns=[\"BOROUGH\"])\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.rename(columns={\"LINK_ID\": \"location_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column named 'direction' with all the values in this column should be null\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.assign(direction=\"null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the direction column to behind the location_id column\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.iloc[:, [0, 1, 2, 5, 3, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column named 'data_source' with all the values in this column should be 'traffic_speeds'\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.assign(data_source=\"traffic_speeds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "traffic_speeds_transformed.to_csv(\"traffic_speeds_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load the transformed dataframe from a csv file\n",
    "traffic_speeds_transformed = pd.read_csv(\"traffic_speeds_transformed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traffic_speeds_transformed is one traffic df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip download and use the transformed data instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://data.cityofnewyork.us/Transportation/Automated-Traffic-Volume-Counts/7ym2-wayt\n",
    "\n",
    "# Download the csv file\n",
    "# Use a select and group by statement to get the count of the volume column grouped by the year, month, and roadway_name columns\n",
    "\n",
    "automated_traffic_volume_counts = \"https://data.ny.gov/resource/7ym2-wayt.csv?$select=Yr,M,Boro,sum(Vol)&$group=Yr,M,Boro&$limit=1000000000\" \n",
    "response = requests.get(automated_traffic_volume_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the csv file to disk\n",
    "csv_file = \"automated_traffic_volume_counts.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file to a dataframe\n",
    "automated_traffic_volume_counts = pd.read_csv(\"automated_traffic_volume_counts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automated_traffic_volume_counts.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names to year, month, location_id, and value\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.rename(columns={\"Yr\": \"year\", \"M\": \"month\", \"Boro\": \"location_id\", \"sum_Vol\": \"value\"})\n",
    "\n",
    "# Add a column named 'value_type' with all the values in this column should say 'vehicle_count'\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.assign(value_type=\"vehicle_count\")\n",
    "\n",
    "# Add a column named 'direction' with all the values in this column should be null\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.assign(direction=\"null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the order of the columns to 0,1,2,5,4,3\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.iloc[:, [0, 1, 2, 5, 4, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column named 'data_source' with all the values in this column should be 'automated_traffic_volume_counts'\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.assign(data_source=\"automated_traffic_volume_counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "automated_traffic_volume_counts.to_csv(\"automated_traffic_volume_counts_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "automated_traffic_volume_counts_transformed = pd.read_csv(\"automated_traffic_volume_counts_transformed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "automated_traffic_volume_counts_transformed is one traffic df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Traffic - \"https://data.ny.gov/resource/cwhc-n4ek.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "daily_traffic = \"https://data.ny.gov/resource/cwhc-n4ek.csv?$limit=1000000000\"\n",
    "response = requests.get(daily_traffic)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"daily_traffic.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "daily_traffic = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file\n",
    "daily_traffic = pd.read_csv('daily_traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(daily_traffic.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "daily_traffic.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the date column\n",
    "daily_traffic[\"year\"] = daily_traffic[\"date\"].str[:4]\n",
    "\n",
    "# Extract the month from the date column\n",
    "daily_traffic[\"month\"] = daily_traffic[\"date\"].str[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the vehicles_e_zpass and vehicles_vtoll columns to get the total_vehicles column\n",
    "daily_traffic[\"value\"] = daily_traffic[\"vehicles_e_zpass\"] + daily_traffic[\"vehicles_vtoll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sum of the total_vehicles, vehicles_e_zpass, and vehicles_vtoll columns grouped by the Year, Month, plaza_id, and direction columns\n",
    "daily_traffic_transformed = daily_traffic.groupby([\"year\", \"month\", \"plaza_id\", \"direction\"]).agg({\"value\": \"sum\", \"vehicles_e_zpass\": \"sum\", \"vehicles_vtoll\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dataframe to a csv file\n",
    "daily_traffic_transformed.to_csv(\"daily_traffic_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file\n",
    "daily_traffic_transformed = pd.read_csv('daily_traffic_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(daily_traffic_transformed.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "daily_traffic_transformed.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column named 'value_type' with all the values in this column should say 'vehicle_count'\n",
    "daily_traffic_transformed = daily_traffic_transformed.assign(value_type=\"vehicle_count\")\n",
    "\n",
    "# change the plaza_id column to location_id\n",
    "daily_traffic_transformed = daily_traffic_transformed.rename(columns={\"plaza_id\": \"location_id\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap the order of the last 2 columns\n",
    "daily_traffic_transformed = daily_traffic_transformed.iloc[:, [0, 1, 2, 3, 7, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column named 'data_source' with all the values in this column should be 'daily_traffic'\n",
    "daily_traffic_transformed = daily_traffic_transformed.assign(data_source=\"daily_traffic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "daily_traffic_transformed.to_csv(\"daily_traffic_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load the transformed dataframe from a csv file\n",
    "daily_traffic_transformed = pd.read_csv(\"daily_traffic_transformed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daily_traffic_transformed is one traffic df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic Volume Count Smaller - \"https://data.cityofnewyork.us/resource/btm5-ppia.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "volume_count_small = \"https://data.cityofnewyork.us/resource/btm5-ppia.csv?$limit=1000000000\"\n",
    "response = requests.get(volume_count_small)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"volume_count_small.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "volume_count_small = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(volume_count_small.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "volume_count_small.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named all day which is the sum of all columns ending in am or pm\n",
    "volume_count_small[\"value\"] = volume_count_small.filter(regex=\"am|pm\").sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Year column by extracting the year from the date column\n",
    "volume_count_small[\"year\"] = volume_count_small[\"date\"].str[0:4]\n",
    "\n",
    "# Create a Month column by extracting the month from the date column\n",
    "volume_count_small[\"month\"] = volume_count_small[\"date\"].str[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe by grouping the volume_count_small dataframe by the Year, Month, roadway_name, direction columns, giving the sum of the all_day column\n",
    "volume_count_small_transformed = volume_count_small.groupby([\"year\", \"month\", \"roadway_name\", \"direction\"]).agg({\"value\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names to year, month, location_id, and value\n",
    "volume_count_small_transformed = volume_count_small_transformed.rename(columns={\"roadway_name\": \"location_id\"})\n",
    "\n",
    "# Add a column named 'value_type' with all the values in this column should say 'vehicle_count'\n",
    "volume_count_small_transformed = volume_count_small_transformed.assign(value_type=\"vehicle_count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the order of the last 2 columns\n",
    "volume_count_small_transformed = volume_count_small_transformed.iloc[:, [0, 1, 2, 3, 5, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(volume_count_small_transformed.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "volume_count_small_transformed.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column named 'data_source' with all the values in this column should be 'volume_count_small'\n",
    "volume_count_small_transformed = volume_count_small_transformed.assign(data_source=\"volume_count_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "volume_count_small_transformed.to_csv(\"volume_count_small_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file\n",
    "volume_count_small_transformed = pd.read_csv('volume_count_small_transformed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "volume_count_small_transformed is one traffic df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently have:\n",
    "<b>Delays :</b>\n",
    "\n",
    "Wait Assesment 2015-2024\n",
    "\n",
    "<b>Impact :</b>\n",
    "\n",
    "hourly_traffic_transformed,\n",
    "\n",
    "traffic_speeds_transformed,\n",
    "\n",
    "automated_traffic_valume_counts_tranformed,\n",
    "\n",
    "daily_traffic_transformed\n",
    "\n",
    "volume_count_small_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Merge all the dataframes into one dataframe\n",
    "traffic = pd.concat([hourly_traffic_transformed, traffic_speeds_transformed, automated_traffic_volume_counts_transformed, daily_traffic_transformed, volume_count_small_transformed], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(traffic.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "traffic.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Set the year and month columns to integers\n",
    "traffic[\"year\"] = traffic[\"year\"].astype(int)\n",
    "traffic[\"month\"] = traffic[\"month\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum and maximum year\n",
    "print(traffic[\"year\"].min())\n",
    "print(traffic[\"year\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather data uploaded from local file\n",
    "\n",
    "Weather data is available from https://scacis.rcc-acis.org/\n",
    "\n",
    "Copied to csv and then loaded locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all the csv files\n",
    "weather_avg_perc = pd.read_csv('NYC Weather - average_percipitation.csv')\n",
    "weather_avg_temp = pd.read_csv('NYC Weather - avg_temp.csv')\n",
    "weather_max_perc = pd.read_csv('NYC Weather - max_precipitation.csv')\n",
    "weather_max_snow_depth = pd.read_csv('NYC Weather - max_snow_depth.csv')\n",
    "weather_max_snowfall = pd.read_csv('NYC Weather - max_snowfall.csv')\n",
    "weather_max_temp = pd.read_csv('NYC Weather - Max_Temp.csv')\n",
    "weather_min_temp = pd.read_csv('NYC Weather - Min_Temp.csv')\n",
    "weather_total_perc = pd.read_csv('NYC Weather - total_percipitation.csv')\n",
    "weather_total_snow_depth = pd.read_csv('NYC Weather - total_snow_depth.csv')\n",
    "weather_total_snowfall = pd.read_csv('NYC Weather - total_snowfall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the weather dataframes into one dataframe with a column named weather_type to indicate the type of weather\n",
    "weather_avg_perc[\"weather_type\"] = \"average_percipitation\"\n",
    "weather_avg_temp[\"weather_type\"] = \"avg_temp\"\n",
    "weather_max_perc[\"weather_type\"] = \"max_precipitation\"\n",
    "weather_max_snow_depth[\"weather_type\"] = \"max_snow_depth\"\n",
    "weather_max_snowfall[\"weather_type\"] = \"max_snowfall\"\n",
    "weather_max_temp[\"weather_type\"] = \"max_temp\"   \n",
    "weather_min_temp[\"weather_type\"] = \"min_temp\"\n",
    "weather_total_perc[\"weather_type\"] = \"total_percipitation\"\n",
    "weather_total_snow_depth[\"weather_type\"] = \"total_snow_depth\"\n",
    "weather_total_snowfall[\"weather_type\"] = \"total_snowfall\"\n",
    "\n",
    "# Combine all the weather dataframes into one dataframe\n",
    "weather = pd.concat([weather_avg_perc, weather_avg_temp, weather_max_perc, weather_max_snow_depth, weather_max_snowfall, weather_max_temp, weather_min_temp, weather_total_perc, weather_total_snow_depth, weather_total_snowfall], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take everything from 2000 onwards\n",
    "weather2000 = weather[weather['Year'] >= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2000.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Annual column  \n",
    "weather2000 = weather2000.drop(columns=['Annual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the dataframe so it is in long format\n",
    "weather2001 = weather2000.melt(id_vars=[\"Year\", \"weather_type\"], var_name=\"month\", value_name=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2001.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Year column to year\n",
    "weather2001 = weather2001.rename(columns={\"Year\": \"year\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the month column from Jan to 01, Feb to 02, etc.\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Jan\", \"01\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Feb\", \"02\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Mar\", \"03\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Apr\", \"04\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"May\", \"05\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Jun\", \"06\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Jul\", \"07\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Aug\", \"08\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Sep\", \"09\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Oct\", \"10\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Nov\", \"11\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Dec\", \"12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the order of the last 2 columns\n",
    "weather = weather2001.iloc[:, [0, 2, 1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "weather.to_csv(\"weather.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load the transformed dataframe from a csv file\n",
    "weather = pd.read_csv(\"weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random sample of 50 rows\n",
    "weather2002 = weather.sample(n=50, random_state=1) \n",
    "\n",
    "weather2002.describe(include='all')\n",
    "\n",
    "print(weather2002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of weather data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bus Delay Time Years are from 2015 - 2024\n",
    "# The Earliest Weather Data is from 2000 - 2024\n",
    "# The Earliest Traffic Data is from 2000 - 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform EDA on the delay data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Change the month column to date and the Year column to year\n",
    "delays = wait_assessment_2015_2020.rename(columns={\"month\": \"date\", \"Year\": \"year\", \"Month\": \"month\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EDA on the wait_assessment_2015_2020 dataframe\n",
    "delays.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation between the columns\n",
    "delays.corr()\n",
    "\n",
    "# Print a correlation heatmap\n",
    "sns.heatmap(delays.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for the columns\n",
    "delays.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the wait assessment data where the route_id is BX1\n",
    "delays[delays[\"route_id\"] == 'BX1'].plot(x=\"date\", y=\"wait_assessment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a df with the wait assessment data where the wait_assessment is an average of the wait_assessment column grouped by the year and month columns\n",
    "delays2 = delays.groupby([\"year\", \"month\"]).agg({\"wait_assessment\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display histogram of the wait_assessment column\n",
    "delays2.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the wait assessment data\n",
    "delays2.plot(x=\"year\", y=\"wait_assessment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform EDA on the traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EDA on the traffic dataframe\n",
    "traffic.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation between the columns\n",
    "traffic.corr()\n",
    "\n",
    "# Print a correlation heatmap\n",
    "\n",
    "sns.heatmap(traffic.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for the columns\n",
    "traffic.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the traffic data\n",
    "traffic.plot(x=\"year\", y=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the value counts for the value_type column\n",
    "traffic[\"value_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the rows where the value_type is vehicle_count\n",
    "traffic2 = traffic[traffic[\"value_type\"] == \"vehicle_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_speed = traffic[traffic[\"value_type\"] == \"speed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_time = traffic[traffic[\"value_type\"] == \"travel_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataframe\n",
    "traffic_speed.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum and maximum year\n",
    "print(traffic_speed[\"year\"].min())\n",
    "print(traffic_speed[\"year\"].max())\n",
    "\n",
    "print(traffic_time[\"year\"].min())\n",
    "print(traffic_time[\"year\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traffic2[\"year\"].min())\n",
    "print(traffic2[\"year\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataframe\n",
    "traffic2.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seperate dataframe for the traffic data where the location_id is 3\n",
    "traffic3 = traffic2[traffic2[\"location_id\"] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataframe\n",
    "traffic3.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take value counts of the data_source column\n",
    "traffic3[\"data_source\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seperate dataframes for the traffic data where the data_source is hourly_traffic and daily_traffic\n",
    "traffic_hourly = traffic3[traffic3[\"data_source\"] == \"hourly_traffic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sum of the value column grouped by the year and month columns\n",
    "traffic3 = traffic3.groupby([\"year\", \"month\"]).agg({\"value\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a date column by combining the year and month columns\n",
    "traffic3[\"date\"] = traffic3[\"year\"].astype(str) + \"-\" + traffic3[\"month\"].astype(str)\n",
    "\n",
    "# Convert the date column to a date data type\n",
    "traffic3[\"date\"] = pd.to_datetime(traffic3[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the traffic data with year and month on the x-axis and value on the y-axis\n",
    "traffic3.plot(x=\"date\", y=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform EDA on the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EDA on the weather dataframe\n",
    "weather.describe(include='all')\n",
    "\n",
    "\n",
    "# Check the correlation between the columns\n",
    "weather.corr()\n",
    "\n",
    "# Print a correlation heatmap\n",
    "sns.heatmap(weather.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Replace any alpha characters with null in the value column\n",
    "weather[\"value\"] = pd.to_numeric(weather[\"value\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the number of null values in the value column grouped by the weather_type column\n",
    "weather.groupby(\"weather_type\").agg({\"value\": \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a date column by combining the year and month columns\n",
    "weather[\"date\"] = weather[\"year\"].astype(str) + \"-\" + weather[\"month\"].astype(str)\n",
    "\n",
    "# Convert the date column to a date data type\n",
    "weather[\"date\"] = pd.to_datetime(weather[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the weather data with year and month on the x-axis and value on the y-axis where the weather_type is the title\n",
    "weather[weather[\"weather_type\"] == \"max_temp\"].plot(x=\"date\", y=\"value\", title=\"max_temp\")\n",
    "weather[weather[\"weather_type\"] == \"min_temp\"].plot(x=\"date\", y=\"value\", title=\"min_temp\")\n",
    "weather[weather[\"weather_type\"] == \"avg_temp\"].plot(x=\"date\", y=\"value\", title=\"avg_temp\")\n",
    "weather[weather[\"weather_type\"] == \"max_precipitation\"].plot(x=\"date\", y=\"value\", title=\"max_precipitation\")\n",
    "weather[weather[\"weather_type\"] == \"average_percipitation\"].plot(x=\"date\", y=\"value\", title=\"average_percipitation\")\n",
    "weather[weather[\"weather_type\"] == \"total_percipitation\"].plot(x=\"date\", y=\"value\", title=\"total_percipitation\")\n",
    "weather[weather[\"weather_type\"] == \"max_snowfall\"].plot(x=\"date\", y=\"value\", title=\"max_snowfall\")\n",
    "weather[weather[\"weather_type\"] == \"total_snowfall\"].plot(x=\"date\", y=\"value\", title=\"total_snowfall\")\n",
    "weather[weather[\"weather_type\"] == \"max_snow_depth\"].plot(x=\"date\", y=\"value\", title=\"max_snow_depth\")\n",
    "weather[weather[\"weather_type\"] == \"total_snow_depth\"].plot(x=\"date\", y=\"value\", title=\"total_snow_depth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Fill in null values with interpolation\n",
    "weather[\"value\"] = weather.groupby(\"weather_type\")[\"value\"].transform(lambda x: x.interpolate())\n",
    "\n",
    "# Check if there are any remaining null values\n",
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the value counts for the weather_type column\n",
    "weather[\"weather_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the date range for avg_temp and max_temp weather types\n",
    "print(weather[weather[\"weather_type\"] == \"avg_temp\"][\"date\"].min())\n",
    "print(weather[weather[\"weather_type\"] == \"avg_temp\"][\"date\"].max())\n",
    "\n",
    "print(weather[weather[\"weather_type\"] == \"max_temp\"][\"date\"].min())\n",
    "print(weather[weather[\"weather_type\"] == \"max_temp\"][\"date\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an avg_temp dataframe and a max_temp dataframe\n",
    "avg_temp = weather[weather[\"weather_type\"] == \"avg_temp\"]\n",
    "max_temp = weather[weather[\"weather_type\"] == \"max_temp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the month column to a float data type\n",
    "avg_temp[\"month\"] = avg_temp[\"month\"].astype(float)\n",
    "\n",
    "# describe the avg_temp dataframe\n",
    "avg_temp.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the year and the month values, ordered by year and month\n",
    "avg_temp.sort_values([\"year\", \"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Remove any rows where the date is after 2023-12-01\n",
    "weather = weather[weather[\"date\"] <= \"2023-12-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the weather dataframe\n",
    "weather.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Value Counts on the weather_type column\n",
    "weather[\"weather_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows where period is Systemwide\n",
    "\n",
    "delays_clean = delays[delays[\"period\"] != \"Systemwide\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows where borough is Systemwide or Misc\n",
    "delays_clean = delays_clean[delays_clean[\"borough\"] != \"Systemwide\"]\n",
    "delays_clean = delays_clean[delays_clean[\"borough\"] != \"Misc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_clean.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an anova_delays df grouped by the date, bourough, route id, and period, with the mean of the wait_assessment column\n",
    "anova_delays = delays_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Delays_clean by date, borough and period and get the mean of the wait_assessment column\n",
    "delays_clean = delays_clean.groupby([\"date\", \"borough\", \"period\"]).agg({\"wait_assessment\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print value counts for the period and borough columns\n",
    "delays_clean[\"period\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "grouped_data = anova_delays.groupby(['borough', 'period'])['wait_assessment']\n",
    "\n",
    "# Convert the grouped data to a list of arrays\n",
    "data = [group.values for name, group in grouped_data]\n",
    "\n",
    "# Perform Levene's test\n",
    "statistic, p_value = levene(*data)\n",
    "\n",
    "# Check the result\n",
    "if p_value > 0.05:\n",
    "    print(\"Homogeneity of variances is satisfied (p > 0.05)\")\n",
    "else:\n",
    "    print(\"Homogeneity of variances is not satisfied (p <= 0.05)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "grouped_data = anova_delays.groupby(['borough', 'period'])['wait_assessment']\n",
    "\n",
    "for name, group in grouped_data:\n",
    "    # Perform Shapiro-Wilk test for normality\n",
    "    stat, p_value = shapiro(group)\n",
    "    \n",
    "    # Check the result\n",
    "    if p_value > 0.05:\n",
    "        print(f\"Data for {name} is normally distributed (p > 0.05)\")\n",
    "    else:\n",
    "        print(f\"Data for {name} is not normally distributed (p <= 0.05)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Generate a boxplot of the wait_assessment column grouped by the borough and period columns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.boxplot(x=\"borough\", y=\"wait_assessment\", hue=\"period\", data=anova_delays, palette=\"Set1\")\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Wait Assessment')\n",
    "plt.title('Wait Assessment by Borough and Period')\n",
    "plt.legend(title='Period', loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean and standard deviation for each borough and period combination\n",
    "for x in anova_delays['borough'].unique():\n",
    "    for y in anova_delays['period'].unique():\n",
    "        print(x, y, \"Mean :\", round(anova_delays[(anova_delays['borough'] == x) & (anova_delays['period'] == y)]['wait_assessment'].mean(),2))\n",
    "        print(x, y, \"Standard Deviation :\", round(anova_delays[(anova_delays['borough'] == x) & (anova_delays['period'] == y)]['wait_assessment'].std(),2),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform an ANOVA on the delay data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform two-way ANOVA\n",
    "# The effect of borough, the effect of period, and the interaction between borough and period\n",
    "model = ols('wait_assessment ~ borough + period + borough:period', data = anova_delays).fit()\n",
    "aov2 = sm.stats.anova_lm(model, type=2)\n",
    "print(aov2, '\\n')\n",
    "\n",
    "# print the results of the two-way ANOVA hypothesis tests\n",
    "print(f\"Borough p-value: {aov2['PR(>F)'][0]:.4f}\")\n",
    "print(f\"Period p-value: {aov2['PR(>F)'][1]:.4f}\")\n",
    "print(f\"Interaction p-value: {aov2['PR(>F)'][2]:.4f}\", '\\n')\n",
    "\n",
    "# Print the results of the two-way ANOVA hypothesis tests\n",
    "if aov2['PR(>F)'][0] < 0.05:\n",
    "    print(\"Reject null hypothesis - Significant differences exist between Borough groups.\")\n",
    "else:\n",
    "    print(\"Accept null hypothesis - No significant difference between Borough groups.\")\n",
    "    \n",
    "if aov2['PR(>F)'][1] < 0.05:\n",
    "    print(\"Reject null hypothesis - Significant differences exist between Period groups.\")\n",
    "else:\n",
    "    print(\"Accept null hypothesis - No significant difference between Period groups.\")\n",
    "    \n",
    "if aov2['PR(>F)'][2] < 0.05:\n",
    "    print(\"Reject null hypothesis - Interaction occurs between factors.\")\n",
    "else:\n",
    "    print(\"Accept null hypothesis - No interaction occurs between factors.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.factorplots import interaction_plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = interaction_plot(x=anova_delays['period'].values, trace=anova_delays['borough'].values, response=anova_delays['wait_assessment'].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Post Hoc Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a Tukey's Range Test to determine which groups are significantly different from each other\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Perform Tukey's Range Test\n",
    "tukey_results = pairwise_tukeyhsd(anova_delays['wait_assessment'], anova_delays['borough'], 0.05)\n",
    "\n",
    "# Print the results\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a Tukey's Range Test to determine which groups are significantly different from each other\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Perform Tukey's Range Test\n",
    "tukey_results = pairwise_tukeyhsd(anova_delays['wait_assessment'], anova_delays['period'], 0.05)\n",
    "\n",
    "# Print the results\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Kruska-Wallis Test for Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise the date distribution of the wait_assessment column\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.boxplot(x=\"period\", y=\"wait_assessment\", data=delays_clean, palette=\"Set1\")\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Wait Assessment')\n",
    "plt.title('Wait Assessment by Period')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis Test Results:\n",
      "Test statistic: 495.7221\n",
      "P-value: 0.0000\n",
      "Critical value: 5.9915\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "stat, p = kruskal(*[delays_clean[delays_clean['period'] == geo]['wait_assessment'] for geo in delays_clean['period'].unique()])\n",
    "\n",
    "# Print the results\n",
    "print(\"Kruskal-Wallis Test Results:\")\n",
    "print(f\"Test statistic: {stat:.4f}\")\n",
    "print(f\"P-value: {p:.4f}\")\n",
    "\n",
    "# Calculate the critical value for the significance level of 0.05\n",
    "critical_value = chi2.ppf(1-0.05, 2)\n",
    "\n",
    "print(f\"Critical value: {critical_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.105196e-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.105196e-110</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1              2\n",
       "1   1.000000e+00  8.105196e-110\n",
       "2  8.105196e-110   1.000000e+00"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform post-hoc test\n",
    "sp.posthoc_dunn([delays_clean[delays_clean['period'] == geo]['wait_assessment'] for geo in delays_clean['period'].unique()], p_adjust='holm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Kruska-Wallis Test for Boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise the date distribution of the wait_assessment column\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.boxplot(x=\"borough\", y=\"wait_assessment\", data=delays_clean, palette=\"Set1\")\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Wait Assessment')\n",
    "plt.title('Wait Assessment by Borough')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis Test Results:\n",
      "Test statistic: 106.8759\n",
      "P-value: 0.0000\n",
      "Critical value: 5.9915\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "stat, p = kruskal(*[delays_clean[delays_clean['borough'] == geo]['wait_assessment'] for geo in delays_clean['borough'].unique()])\n",
    "\n",
    "# Print the results\n",
    "print(\"Kruskal-Wallis Test Results:\")\n",
    "print(f\"Test statistic: {stat:.4f}\")\n",
    "print(f\"P-value: {p:.4f}\")\n",
    "\n",
    "# Calculate the critical value for the significance level of 0.05\n",
    "critical_value = chi2.ppf(1-0.05, 2)\n",
    "\n",
    "print(f\"Critical value: {critical_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.454215e-20</td>\n",
       "      <td>2.027918e-03</td>\n",
       "      <td>4.752132e-01</td>\n",
       "      <td>1.188688e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.454215e-20</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.142191e-08</td>\n",
       "      <td>2.928954e-15</td>\n",
       "      <td>5.060410e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.027918e-03</td>\n",
       "      <td>5.142191e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.640166e-02</td>\n",
       "      <td>4.752132e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.752132e-01</td>\n",
       "      <td>2.928954e-15</td>\n",
       "      <td>8.640166e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.752132e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.188688e-01</td>\n",
       "      <td>5.060410e-12</td>\n",
       "      <td>4.752132e-01</td>\n",
       "      <td>4.752132e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1             2             3             4             5\n",
       "1  1.000000e+00  7.454215e-20  2.027918e-03  4.752132e-01  1.188688e-01\n",
       "2  7.454215e-20  1.000000e+00  5.142191e-08  2.928954e-15  5.060410e-12\n",
       "3  2.027918e-03  5.142191e-08  1.000000e+00  8.640166e-02  4.752132e-01\n",
       "4  4.752132e-01  2.928954e-15  8.640166e-02  1.000000e+00  4.752132e-01\n",
       "5  1.188688e-01  5.060410e-12  4.752132e-01  4.752132e-01  1.000000e+00"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scikit_posthocs as sp\n",
    "\n",
    "# Perform post-hoc test\n",
    "sp.posthoc_dunn([delays_clean[delays_clean['borough'] == geo]['wait_assessment'] for geo in delays_clean['borough'].unique()], p_adjust='holm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which Weather Data to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Weather Data in wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Melt the weather dataframe so all the weather types are in seperate columns, with only the date column remaining\n",
    "weather_wide = weather.pivot(index=\"date\", columns=\"weather_type\", values=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the weather_wide dataframe\n",
    "weather_wide.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the delays dataframe\n",
    "delays2.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# create a date column by combining the year and month columns\n",
    "delays2[\"date\"] = delays2[\"year\"].astype(str) + \"-\" + delays2[\"month\"].astype(str)\n",
    "\n",
    "# Convert the date column to a date data type\n",
    "delays2[\"date\"] = pd.to_datetime(delays2[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join with Delay Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "delays_weather = pd.merge(weather_wide, delays2, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the delays_weather dataframe\n",
    "delays_weather.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Null values in the delays_weather dataframe\n",
    "delays_weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the Null values from the delays_weather dataframe\n",
    "delays_weather = delays_weather.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA to understand which weather data has the most impact on delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peform Princicpal Component Analysis (PCA) on the delays_weather dataframe to understand which columns have the most impact on the wait_assessment column\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(delays_weather)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate the features (weather type columns) from the target (wait assessment column)\n",
    "features = delays_weather.drop(columns=['date', 'wait_assessment', 'year', 'month'])\n",
    "target = delays_weather['wait_assessment']\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca.fit(features)\n",
    "\n",
    "# Get the explained variance ratio for each principal component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "pca_results = pd.DataFrame({'Weather Type': features.columns, 'Explained Variance Ratio': explained_variance_ratio})\n",
    "\n",
    "# Sort the dataframe by the explained variance ratio in descending order, round the values to 2 decimal places\n",
    "pca_results = pca_results.round(2)\n",
    "pca_results = pca_results.sort_values(by='Explained Variance Ratio', ascending=False)\n",
    "\n",
    "# Print the results\n",
    "print(pca_results)\n",
    "\n",
    "# Print the Top 3 Weather Types\n",
    "print(pca_results.iloc[0:3, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Keep only the avg_perc and avg_temp columns\n",
    "weather_features = delays_weather[['date', 'average_percipitation', 'avg_temp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Average Percipitation and Average Temperature as the weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which Traffic Data to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Traffic Data in wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the traffic dataframe\n",
    "traffic.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "traffic_wide = traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate the 'value_type' and 'data_source' columns to create a new column named 'traffic_type'\n",
    "traffic_wide[\"traffic_type\"] = traffic_wide[\"value_type\"] + \"_\" + traffic_wide[\"data_source\"]\n",
    "\n",
    "# Get rid of the 'value_type' and 'data_source' columns\n",
    "traffic_wide = traffic_wide.drop(columns=[\"value_type\", \"data_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concate the 'location_id' and 'traffic_type' columns to create a new column named 'location_traffic_type'\n",
    "#traffic_wide[\"location_traffic_type\"] = traffic_wide[\"location_id\"].astype(str) + \"_\" + traffic_wide[\"traffic_type\"]\n",
    "\n",
    "# Get rid of the 'location_id' column\n",
    "#traffic_wide = traffic_wide.drop(columns=[\"location_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a date column by combining the year and month columns\n",
    "traffic_wide[\"date\"] = traffic_wide[\"year\"].astype(str) + \"-\" + traffic_wide[\"month\"].astype(str)\n",
    "\n",
    "# Convert the date column to a date data type\n",
    "traffic_wide[\"date\"] = pd.to_datetime(traffic_wide[\"date\"])\n",
    "\n",
    "# Drop the year and month columns\n",
    "traffic_wide = traffic_wide.drop(columns=[\"year\", \"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the traffic_wide dataframe\n",
    "traffic_wide.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the traffic_wide dataframe so that the values for where the location_id and traffic_type columns are added together\n",
    "traffic_wide = traffic_wide.groupby([\"date\", \"location_id\", \"traffic_type\"]).agg({\"value\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the traffic_wide dataframe so that the values for where the location_id and traffic_type are the same are averaged together\n",
    "traffic_wide = traffic_wide.groupby([\"date\", \"traffic_type\"]).agg({\"value\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Melt the traffic_wide dataframe so all the traffic_type column values are in seperate columns, with only the date column remaining\n",
    "traffic_wide = traffic_wide.pivot(index=\"date\", columns=\"traffic_type\", values=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the traffic_wide dataframe\n",
    "traffic_wide.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join with Delay Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Join the traffic_wide and delays dataframes together\n",
    "traffic_delays = pd.merge(traffic_wide, delays2, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the traffic_delays dataframe\n",
    "traffic_delays.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Null values in the traffic_delays dataframe\n",
    "traffic_delays.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Take only the rows where the wait_assessment column is not null\n",
    "traffic_delays = traffic_delays[traffic_delays[\"wait_assessment\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a time series graph of the traffic columns in the traffic_delays dataframe\n",
    "traffic_delays.plot(x=\"date\", y=[\"speed_traffic_speeds\", \"travel_time_traffic_speeds\",\"vehicle_count_automated_traffic_volume_counts\",\"vehicle_count_daily_traffic\", \"vehicle_count_hourly_traffic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Use interpolation to fill in the Null values in the traffic_delays dataframe\n",
    "traffic_delays = traffic_delays.interpolate(method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the vehicle_count_volume_count_small column and all rows after 2023-12-01\n",
    "traffic_delays = traffic_delays.drop(columns=[\"vehicle_count_volume_count_small\", \"travel_time_traffic_speeds\", \"speed_traffic_speeds\", \"vehicle_count_daily_traffic\"])\n",
    "traffic_delays = traffic_delays[traffic_delays[\"date\"] <= \"2023-12-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_delays.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of Null values in the traffic_delays dataframe\n",
    "traffic_delays.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA to understand which weather data has the most impact on delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features (weather type columns) from the target (wait assessment column)\n",
    "features = traffic_delays.drop(columns=['date', 'wait_assessment', 'year', 'month'])\n",
    "target = traffic_delays['wait_assessment']\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca.fit(features)\n",
    "\n",
    "# Get the explained variance ratio for each principal component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "pca_results = pd.DataFrame({'Traffic Type': features.columns, 'Explained Variance Ratio': explained_variance_ratio})\n",
    "\n",
    "# Sort the dataframe by the explained variance ratio in descending order, round the values to 2 decimal places\n",
    "pca_results = pca_results.round(2)\n",
    "pca_results = pca_results.sort_values(by='Explained Variance Ratio', ascending=False)\n",
    "\n",
    "# Print the results\n",
    "print(pca_results)\n",
    "\n",
    "# Print the Top 2 Traffic Types\n",
    "print(pca_results.iloc[0:2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Keep only the avg_perc and avg_temp columns\n",
    "traffic_features = traffic_delays[['date', 'vehicle_count_automated_traffic_volume_counts']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use vehicle_count_automated_traffic_volume_counts as the traffic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data for the model, combining the delays, weather and traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the year and month columns\n",
    "delays2 = delays2.drop(columns=[\"year\", \"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays2.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_features.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_features.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Join the weather_features and traffic_features and delays2 dataframes together\n",
    "features = pd.merge(delays2, weather_features, on=\"date\", how=\"left\")\n",
    "features = pd.merge(features, traffic_features, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the features dataframe\n",
    "features.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompose the time series to understand the trend and seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the date column to a date data type\n",
    "features[\"date\"] = pd.to_datetime(features[\"date\"])\n",
    "\n",
    "# Have the date column as the index\n",
    "features = features.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# set the frequncey of the index to monthly\n",
    "features.index = pd.date_range(start='2015-01-01', periods=len(features), freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose_data = seasonal_decompose(features['wait_assessment'], model=\"additive\")\n",
    "decompose_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonality=decompose_data.seasonal\n",
    "seasonality.plot(color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the stationarity of the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = adfuller(features.wait_assessment, autolag = 'AIC')\n",
    "print(\"1. ADF : \",dftest[0])\n",
    "print(\"2. P-Value : \", dftest[1])\n",
    "print(\"3. Num Of Lags : \", dftest[2])\n",
    "print(\"4. Num Of Observations Used For ADF Regression and Critical Values Calculation :\", dftest[3])\n",
    "print(\"5. Critical Values :\")\n",
    "for key, val in dftest[4].items():\n",
    "    print(\"\\t\",key, \": \", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Use a rolling mean to smooth out the data and make it stationary\n",
    "rolling_mean = features['wait_assessment'].rolling(window = 12).mean()\n",
    "features['rolling_mean_diff'] = rolling_mean - rolling_mean.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['wait_assessment'].plot(title='Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['rolling_mean_diff'].plot(title='Post Rolling Mean & Differencing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the features dataframe\n",
    "features.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "#Check for Null values in the features dataframe\n",
    "features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Use interpolation to fill in the Null values in the features dataframe\n",
    "features = features.interpolate(method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Show the index for the rows of rolling_mean_diff where the value is null\n",
    "features[features['rolling_mean_diff'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Fill in the Null values in the rolling_mean_diff column With the mean of the rolling_mean_diff column\n",
    "features['rolling_mean_diff'] = features['rolling_mean_diff'].fillna(features['rolling_mean_diff'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = adfuller(features.rolling_mean_diff, autolag = 'AIC')\n",
    "print(\"1. ADF : \",dftest[0])\n",
    "print(\"2. P-Value : \", dftest[1])\n",
    "print(\"3. Num Of Lags : \", dftest[2])\n",
    "print(\"4. Num Of Observations Used For ADF Regression and Critical Values Calculation :\", dftest[3])\n",
    "print(\"5. Critical Values :\")\n",
    "for key, val in dftest[4].items():\n",
    "    print(\"\\t\",key, \": \", val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Sarimax model to predict the delays\n",
    "\n",
    "Use the weather and traffic data as exogenous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the endogenous variable (target)\n",
    "endog = features['rolling_mean_diff']\n",
    "\n",
    "# Define the exogenous variables\n",
    "exog = features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']]\n",
    "\n",
    "# Add a constant to the exogenous variables\n",
    "exog = sm.add_constant(exog)\n",
    "\n",
    "# Perform test/train split\n",
    "train_size = 0.8  # You can adjust this ratio as needed\n",
    "endog_train, endog_test, exog_train, exog_test = train_test_split(\n",
    "    endog, exog, train_size=train_size, shuffle=False\n",
    ")\n",
    "\n",
    "# Set the frequency to monthly\n",
    "freq = \"M\"\n",
    "\n",
    "# Create the SARIMAX model for training\n",
    "model = sm.tsa.SARIMAX(endog_train, exog=exog_train, order=(1, 0, 0), seasonal_order=(0, 0, 0, 0), freq=freq)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())\n",
    "\n",
    "# Predict on the test set\n",
    "forecast = results.get_forecast(steps=len(endog_test), exog=exog_test)\n",
    "predicted_values = forecast.predicted_mean\n",
    "\n",
    "# Evaluate the accuracy (you can use any appropriate metric depending on your task)\n",
    "mae = mean_absolute_error(endog_test, predicted_values)\n",
    "rmse = np.sqrt(mean_squared_error(endog_test, predicted_values))\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Scale the numerical features in the features dataframe using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts', 'wait_assessment', 'rolling_mean_diff']] = scaler.fit_transform(features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts', 'wait_assessment', 'rolling_mean_diff']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the endogenous variable (target)\n",
    "endog = features['rolling_mean_diff']\n",
    "\n",
    "# Define the exogenous variables\n",
    "exog = features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']]\n",
    "\n",
    "# Add a constant to the exogenous variables\n",
    "exog = sm.add_constant(exog)\n",
    "\n",
    "# Perform test/train split\n",
    "train_size = 0.8  # You can adjust this ratio as needed\n",
    "endog_train, endog_test, exog_train, exog_test = train_test_split(\n",
    "    endog, exog, train_size=train_size, shuffle=False\n",
    ")\n",
    "\n",
    "# Set the frequency to monthly\n",
    "freq = \"M\"\n",
    "\n",
    "# Create the SARIMAX model for training\n",
    "model = sm.tsa.SARIMAX(endog_train, exog=exog_train, order=(1, 0, 0), seasonal_order=(0, 0, 0, 0), freq=freq)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())\n",
    "\n",
    "# Predict on the test set\n",
    "forecast = results.get_forecast(steps=len(endog_test), exog=exog_test)\n",
    "predicted_values = forecast.predicted_mean\n",
    "\n",
    "# Evaluate the accuracy (you can use any appropriate metric depending on your task)\n",
    "mae = mean_absolute_error(endog_test, predicted_values)\n",
    "rmse = np.sqrt(mean_squared_error(endog_test, predicted_values))\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the endogenous variable (target)\n",
    "endog = features['rolling_mean_diff']\n",
    "\n",
    "# Define the exogenous variables\n",
    "exog = features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']]\n",
    "\n",
    "# Add a constant to the exogenous variables\n",
    "exog = sm.add_constant(exog)\n",
    "\n",
    "# Perform test/train split\n",
    "train_size = 0.8\n",
    "endog_train, endog_test, exog_train, exog_test = train_test_split(\n",
    "    endog, exog, train_size=train_size, shuffle=False\n",
    ")\n",
    "\n",
    "# Define the range of parameters to search\n",
    "p_values = range(0, 3)  # Replace with your desired range\n",
    "d_values = range(0, 2)  # Replace with your desired range\n",
    "q_values = range(0, 3)  # Replace with your desired range\n",
    "P_values = range(0, 2)  # Replace with your desired range\n",
    "D_values = range(0, 2)  # Replace with your desired range\n",
    "Q_values = range(0, 2)  # Replace with your desired range\n",
    "\n",
    "# Create a list of all possible parameter combinations\n",
    "param_combinations = list(itertools.product(p_values, d_values, q_values, P_values, D_values, Q_values))\n",
    "\n",
    "best_mae = float('inf')\n",
    "best_params = None\n",
    "\n",
    "# Perform grid search\n",
    "for params in param_combinations:\n",
    "    order = (params[0], params[1], params[2])\n",
    "    seasonal_order = (params[3], params[4], params[5], 12)\n",
    "    \n",
    "    # Specify the frequency of the time series\n",
    "    freq = 'M'\n",
    "    \n",
    "    # Create a datetime index with the specified frequency\n",
    "    date_index = pd.date_range(start=features.index.min(), end=features.index.max(), freq=freq)\n",
    "    \n",
    "    # Reindex the endogenous and exogenous variables\n",
    "    #endog = endog.reindex(date_index)\n",
    "    exog = exog.reindex(date_index)\n",
    "\n",
    "    # Create the SARIMAX model for training\n",
    "    model = sm.tsa.SARIMAX(endog_train, exog=exog_train, order=order, seasonal_order=seasonal_order, freq=freq)\n",
    "\n",
    "    # Fit the model\n",
    "    results = model.fit(maxiter=5000, disp=True)\n",
    "\n",
    "    # Predict on the test set\n",
    "    forecast = results.get_forecast(steps=len(endog_test), exog=exog_test)\n",
    "    predicted_values = forecast.predicted_mean\n",
    "\n",
    "    # Evaluate the accuracy using Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(endog_test, predicted_values)\n",
    "\n",
    "    # Check if the current combination has a lower MAE\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_params = params\n",
    "\n",
    "# Print the best parameters and corresponding MAE\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Mean Absolute Error: {best_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the endogenous variable (target)\n",
    "endog = features['rolling_mean_diff']\n",
    "\n",
    "# Define the exogenous variables\n",
    "exog = features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']]\n",
    "\n",
    "# Add a constant to the exogenous variables\n",
    "exog = sm.add_constant(exog)\n",
    "\n",
    "# Perform test/train split\n",
    "train_size = 0.8  # You can adjust this ratio as needed\n",
    "endog_train, endog_test, exog_train, exog_test = train_test_split(\n",
    "    endog, exog, train_size=train_size, shuffle=False\n",
    ")\n",
    "\n",
    "# Set the frequency of the time series to monthly\n",
    "freq = 'M'\n",
    "\n",
    "# Create the SARIMAX model for training\n",
    "model = sm.tsa.SARIMAX(endog_train, exog=exog_train, order=(0, 1, 0), seasonal_order=(0, 1, 1, 12), freq=freq)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())\n",
    "\n",
    "# Predict on the test set\n",
    "forecast = results.get_forecast(steps=len(endog_test), exog=exog_test)\n",
    "predicted_values = forecast.predicted_mean\n",
    "\n",
    "# Evaluate the accuracy (you can use any appropriate metric depending on your task)\n",
    "mae = mean_absolute_error(endog_test, predicted_values)\n",
    "rmse = np.sqrt(mean_squared_error(endog_test, predicted_values))\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model on the entire dataset to be used in the hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a full model for training the hybrid model\n",
    "\n",
    "# Define the endogenous variable (target)\n",
    "endog1 = features['wait_assessment']\n",
    "\n",
    "# Define the exogenous variables\n",
    "exog1 = features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']]\n",
    "\n",
    "# Add a constant to the exogenous variables\n",
    "exog1 = sm.add_constant(exog1)\n",
    "\n",
    "# Set the frequency of the time series to monthly\n",
    "freq = 'M'\n",
    "\n",
    "# Create the SARIMAX model for training\n",
    "model1 = sm.tsa.SARIMAX(endog1, exog=exog1, order=(0, 1, 0), seasonal_order=(0, 1, 1, 12), freq=freq)\n",
    "\n",
    "# Fit the model\n",
    "results1 = model1.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the endog_train, endog_test, exog_train, exog_test dataframe shapes\n",
    "print(endog_train.shape)\n",
    "print(endog_test.shape)\n",
    "print(exog_train.shape)\n",
    "print(exog_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Actual vs Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual values from the training set\n",
    "plt.plot(endog_train.index, endog_train, label='Actual (Training Set)', color='blue')\n",
    "\n",
    "# Plot the actual values from the test set\n",
    "plt.plot(endog_test.index, endog_test, label='Actual (Test Set)', color='blue', linestyle='--')\n",
    "\n",
    "# Plot the predicted values from the test set\n",
    "plt.plot(endog_test.index, predicted_values, label='Predicted (Test Set)', color='orange')\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Wait Assessment')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data for the Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data for the model, combining the delays, weather and traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Join the delays2 and features dataframes together\n",
    "features2 = pd.merge(delays2, traffic_features, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "features2 = pd.merge(features2, weather_features, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the data with a categorical variable showing the traffic and weather performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vehicle_count_automated_traffic_volume_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the wait_assessment column\n",
    "features2['vehicle_count_automated_traffic_volume_counts'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Percentile Thresholds\n",
    "from numpy import array\n",
    "rating_pctile = np.percentile(features2['vehicle_count_automated_traffic_volume_counts'], [75, 90])\n",
    "# The percentile thresholds are\n",
    "rating_pctile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named w_rating in the features2 dataframe \n",
    "features2['vc_rating'] = 0\n",
    "features2['vc_rating'] = np.where(features2['vehicle_count_automated_traffic_volume_counts'] < rating_pctile[0], 1, features2['vc_rating'])\n",
    "features2['vc_rating'] = np.where((features2['vehicle_count_automated_traffic_volume_counts'] >= rating_pctile[0]) & (features2['vehicle_count_automated_traffic_volume_counts'] <= rating_pctile[1]), 2, features2['vc_rating'])\n",
    "features2['vc_rating'] = np.where(features2['vehicle_count_automated_traffic_volume_counts'] > rating_pctile[1], 3, features2['vc_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a histogram of the w_rating column\n",
    "features2['vc_rating'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average_percipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the wait_assessment column\n",
    "features2['average_percipitation'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Percentile Thresholds\n",
    "from numpy import array\n",
    "rating_pctile = np.percentile(features2['average_percipitation'], [75, 90])\n",
    "# The percentile thresholds are\n",
    "rating_pctile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named w_rating in the features2 dataframe \n",
    "features2['ap_rating'] = 0\n",
    "features2['ap_rating'] = np.where(features2['average_percipitation'] < rating_pctile[0], 1, features2['ap_rating'])\n",
    "features2['ap_rating'] = np.where((features2['average_percipitation'] >= rating_pctile[0]) & (features2['average_percipitation'] <= rating_pctile[1]), 2, features2['ap_rating'])\n",
    "features2['ap_rating'] = np.where(features2['average_percipitation'] > rating_pctile[1], 3, features2['ap_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a histogram of the w_rating column\n",
    "features2['ap_rating'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avg_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the wait_assessment column\n",
    "features2['avg_temp'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Percentile Thresholds\n",
    "from numpy import array\n",
    "rating_pctile = np.percentile(features2['avg_temp'], [75, 90])\n",
    "# The percentile thresholds are\n",
    "rating_pctile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named w_rating in the features2 dataframe \n",
    "features2['at_rating'] = 0\n",
    "features2['at_rating'] = np.where(features2['avg_temp'] < rating_pctile[0], 1, features2['at_rating'])\n",
    "features2['at_rating'] = np.where((features2['avg_temp'] >= rating_pctile[0]) & (features2['avg_temp'] <= rating_pctile[1]), 2, features2['at_rating'])\n",
    "features2['at_rating'] = np.where(features2['avg_temp'] > rating_pctile[1], 3, features2['at_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a histogram of the w_rating column\n",
    "features2['at_rating'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the data with time based variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datepart(df, fldname, drop=True):\n",
    "    fld = df[fldname]\n",
    "    if not np.issubdtype(fld.dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, \n",
    "                                     infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    for n in ('Year', 'Month', 'Week', 'Day', 'Dayofweek', \n",
    "            'Dayofyear', 'Is_month_end', 'Is_month_start', \n",
    "            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', \n",
    "            'Is_year_start'):\n",
    "        df[targ_pre+n] = getattr(fld.dt,n.lower())        \n",
    "    df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to a date data type\n",
    "features2[\"date\"] = pd.to_datetime(features2[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(features2, 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that are not needed: Week, Day, Dayofweek, Dayofyear, Is_month_end, Is_month_start, Is_quarter_end, Is_year_end\n",
    "features2 = features2.drop(columns=[\"Week\", \"Day\", \"Dayofweek\", \"Dayofyear\", \"Is_month_end\", \"Is_month_start\", \"Is_quarter_end\", \"Is_year_end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sliding window to shift the data and create samples for a supervised learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features3 = features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size\n",
    "window_size = 6  # You can adjust this based on your preference\n",
    "\n",
    "# Create empty lists to store features and target variable\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Iterate through the dataset with the sliding window\n",
    "for i in range(len(features3) - window_size):\n",
    "    window = features3.iloc[i:i+window_size]\n",
    "    features_here = window[['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp', 'vc_rating', 'ap_rating', 'at_rating', 'Year','Month','Is_quarter_start','Is_year_start','Elapsed']].values.flatten()\n",
    "    target = window['wait_assessment'].iloc[-1]\n",
    "    \n",
    "    X.append(features_here)\n",
    "    y.append(target)\n",
    "\n",
    "# Convert lists to arrays\n",
    "X = pd.DataFrame(X, columns=['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed'] * window_size)\n",
    "y = pd.Series(y, name='wait_assessment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is break the dataset up into windows of 6 months to predict the next month. It is a sliding window approach. Essentially each row will be a 6 month window of data and the target will be the next month. This is due to the fact that we are doing a time series analysis and need to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a Random Forest Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the random forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances\n",
    "\n",
    "# Assuming X_train is a DataFrame\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Get the unique feature names and their corresponding importances\n",
    "unique_feature_names, unique_importances = [], []\n",
    "\n",
    "for name in set(feature_names):\n",
    "    indices = [i for i, x in enumerate(feature_names) if x == name]\n",
    "    unique_feature_names.append(name)\n",
    "    unique_importances.append(sum(feature_importances[indices]))\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "unique_feature_names = np.array(unique_feature_names)\n",
    "unique_importances = np.array(unique_importances)\n",
    "\n",
    "# Get the top ten indices\n",
    "top_ten_idx = np.argsort(unique_importances)[-10:]\n",
    "\n",
    "# Create a bar plot of the top ten feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Top 10 Feature Importances (Aggregated)')\n",
    "plt.barh(range(len(top_ten_idx)), unique_importances[top_ten_idx], align='center')\n",
    "plt.yticks(range(len(top_ten_idx)), unique_feature_names[top_ten_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the variables in the features2 dataframe\n",
    "features3_scaled = scaler.fit_transform(features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with the standardized variables\n",
    "features3_standardized = pd.DataFrame(features3_scaled, columns = features3.columns)\n",
    "\n",
    "# Print the first few rows of the standardized dataframe\n",
    "print(features3_standardized.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features3_standardized.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size\n",
    "window_size = 6  # You can adjust this based on your preference\n",
    "\n",
    "# Create empty lists to store features and target variable\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Iterate through the dataset with the sliding window\n",
    "for i in range(len(features3_standardized) - window_size):\n",
    "    window = features3_standardized.iloc[i:i+window_size]\n",
    "    features_here = window[['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed']].values.flatten()\n",
    "    target = window['wait_assessment'].iloc[-1]\n",
    "    \n",
    "    X.append(features_here)\n",
    "    y.append(target)\n",
    "\n",
    "# Convert lists to arrays\n",
    "X = pd.DataFrame(X, columns=['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed'] * window_size)\n",
    "y = pd.Series(y, name='wait_assessment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the random forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances\n",
    "\n",
    "# Assuming X_train is a DataFrame\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Get the unique feature names and their corresponding importances\n",
    "unique_feature_names, unique_importances = [], []\n",
    "\n",
    "for name in set(feature_names):\n",
    "    indices = [i for i, x in enumerate(feature_names) if x == name]\n",
    "    unique_feature_names.append(name)\n",
    "    unique_importances.append(sum(feature_importances[indices]))\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "unique_feature_names = np.array(unique_feature_names)\n",
    "unique_importances = np.array(unique_importances)\n",
    "\n",
    "# Get the top ten indices\n",
    "top_ten_idx = np.argsort(unique_importances)[-10:]\n",
    "\n",
    "# Create a bar plot of the top ten feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Top 10 Feature Importances (Aggregated)')\n",
    "plt.barh(range(len(top_ten_idx)), unique_importances[top_ten_idx], align='center')\n",
    "plt.yticks(range(len(top_ten_idx)), unique_feature_names[top_ten_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size\n",
    "window_size = 6  # You can adjust this based on your preference\n",
    "\n",
    "# Create empty lists to store features and target variable\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Iterate through the dataset with the sliding window\n",
    "for i in range(len(features3_standardized) - window_size):\n",
    "    window = features3_standardized.iloc[i:i+window_size]\n",
    "    features_here = window[['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed']].values.flatten()\n",
    "    target = window['wait_assessment'].iloc[-1]\n",
    "    \n",
    "    X.append(features_here)\n",
    "    y.append(target)\n",
    "\n",
    "# Convert lists to arrays\n",
    "X = pd.DataFrame(X, columns=['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed'] * window_size)\n",
    "y = pd.Series(y, name='wait_assessment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create the random forest model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size\n",
    "window_size = 6  # You can adjust this based on your preference\n",
    "\n",
    "# Create empty lists to store features and target variable\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Iterate through the dataset with the sliding window\n",
    "for i in range(len(features3_standardized) - window_size):\n",
    "    window = features3_standardized.iloc[i:i+window_size]\n",
    "    features_here = window[['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed']].values.flatten()\n",
    "    target = window['wait_assessment'].iloc[-1]\n",
    "    \n",
    "    X.append(features_here)\n",
    "    y.append(target)\n",
    "\n",
    "# Convert lists to arrays\n",
    "X = pd.DataFrame(X, columns=['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed'] * window_size)\n",
    "y = pd.Series(y, name='wait_assessment')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the random forest model with specified hyperparameters\n",
    "model = RandomForestRegressor(\n",
    "    max_depth=None,\n",
    "    max_features='log2',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances\n",
    "\n",
    "# Assuming X_train is a DataFrame\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Get the unique feature names and their corresponding importances\n",
    "unique_feature_names, unique_importances = [], []\n",
    "\n",
    "for name in set(feature_names):\n",
    "    indices = [i for i, x in enumerate(feature_names) if x == name]\n",
    "    unique_feature_names.append(name)\n",
    "    unique_importances.append(sum(feature_importances[indices]))\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "unique_feature_names = np.array(unique_feature_names)\n",
    "unique_importances = np.array(unique_importances)\n",
    "\n",
    "# Get the top ten indices\n",
    "top_ten_idx = np.argsort(unique_importances)[-10:]\n",
    "\n",
    "# Create a bar plot of the top ten feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Top 10 Feature Importances (Aggregated)')\n",
    "plt.barh(range(len(top_ten_idx)), unique_importances[top_ten_idx], align='center')\n",
    "plt.yticks(range(len(top_ten_idx)), unique_feature_names[top_ten_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Hybrid Model using the Random Forest and Sarimax Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the Residuals and append to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features3_standardized.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = results1.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the indices\n",
    "print(residuals.index)\n",
    "print(features3_standardized.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the index to a datetime index starting from 2015-01-01\n",
    "features3_standardized.index = pd.date_range(start='2015-01-01', freq='M', periods=len(features3_standardized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add residuals to the DataFrame\n",
    "features3_standardized['sarimax_residuals'] = residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features3_standardized.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a Random Forest Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size\n",
    "window_size = 6  # You can adjust this based on your preference\n",
    "\n",
    "# Create empty lists to store features and target variable\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Iterate through the dataset with the sliding window\n",
    "for i in range(len(features3_standardized) - window_size):\n",
    "    window = features3_standardized.iloc[i:i+window_size]\n",
    "    features_here = window[['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed', 'sarimax_residuals']].values.flatten()\n",
    "    target = window['wait_assessment'].iloc[-1]\n",
    "    \n",
    "    X.append(features_here)\n",
    "    y.append(target)\n",
    "\n",
    "# Convert lists to arrays\n",
    "X = pd.DataFrame(X, columns=['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed', 'sarimax_residuals'] * window_size)\n",
    "y = pd.Series(y, name='wait_assessment')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the random forest model with specified hyperparameters\n",
    "model = RandomForestRegressor(\n",
    "    max_depth=None,\n",
    "    max_features='log2',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Get the top ten indices\n",
    "top_ten_idx = np.argsort(feature_importances)[-10:]\n",
    "\n",
    "# Create a bar plot of the top ten feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.barh(range(len(top_ten_idx)), feature_importances[top_ten_idx], align='center')\n",
    "plt.yticks(range(len(top_ten_idx)), feature_names[top_ten_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances\n",
    "\n",
    "# Assuming X_train is a DataFrame\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Get the unique feature names and their corresponding importances\n",
    "unique_feature_names, unique_importances = [], []\n",
    "\n",
    "for name in set(feature_names):\n",
    "    indices = [i for i, x in enumerate(feature_names) if x == name]\n",
    "    unique_feature_names.append(name)\n",
    "    unique_importances.append(sum(feature_importances[indices]))\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "unique_feature_names = np.array(unique_feature_names)\n",
    "unique_importances = np.array(unique_importances)\n",
    "\n",
    "# Get the top ten indices\n",
    "top_ten_idx = np.argsort(unique_importances)[-10:]\n",
    "\n",
    "# Create a bar plot of the top ten feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Top 10 Feature Importances (Aggregated)')\n",
    "plt.barh(range(len(top_ten_idx)), unique_importances[top_ten_idx], align='center')\n",
    "plt.yticks(range(len(top_ten_idx)), unique_feature_names[top_ten_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Multiple Route Models and Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the Delay Data needed for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the delays dataframe\n",
    "delays.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Join the weather_features and traffic_features dataframes together\n",
    "weather_traffic_features = pd.merge(weather_features, traffic_features, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime data type\n",
    "delays['date'] = pd.to_datetime(delays['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime format\n",
    "weather_traffic_features['date'] = pd.to_datetime(weather_traffic_features['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Join the delays and weather_traffic_features dataframes together\n",
    "delays_features = pd.merge(delays, weather_traffic_features, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the weather_traffic_features dataframe\n",
    "print(delays_features.shape)\n",
    "\n",
    "# Describe the weather_traffic_features dataframe\n",
    "delays_features.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Print a value count of the route_id column\n",
    "delays_features[\"route_id\"].value_counts()\n",
    "\n",
    "# List the route_id values that have 432 rows\n",
    "delays_features[\"route_id\"].value_counts().index[delays_features[\"route_id\"].value_counts() == 432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a route specific dataframe for the BX26 route\n",
    "delays_bx26 = delays_features[delays_features[\"route_id\"] == \"BX26\"]\n",
    "\n",
    "delays_bx26.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of the route_id values that have 432 rows\n",
    "route_ids = delays_features[\"route_id\"].value_counts().index[delays_features[\"route_id\"].value_counts() == 432].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Valid Combinations of Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with only the route_id values that have 432 rows based on the route_ids list\n",
    "delays_features_432 = delays_features[delays_features[\"route_id\"].isin(route_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime data type\n",
    "delays_features_432[\"date\"] = pd.to_datetime(delays_features_432[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Group the data by the route_id and date columns and take the mean of the wait_assessment column\n",
    "delays_features_432 = delays_features_432.groupby([\"route_id\", \"date\"]).agg({\"wait_assessment\": \"mean\", \"average_percipitation\": \"mean\", \"avg_temp\": \"mean\",\"vehicle_count_automated_traffic_volume_counts\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of the route_id values that don't have 108 rows\n",
    "route_ids2 = delays_features_432[\"route_id\"].value_counts().index[delays_features_432[\"route_id\"].value_counts() != 108].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "route_ids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the route_id values that don't have 108 rows\n",
    "delays_features_432 = delays_features_432[~delays_features_432[\"route_id\"].isin(route_ids2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime data type\n",
    "delays_features_432[\"date\"] = pd.to_datetime(delays_features_432[\"date\"])\n",
    "\n",
    "# Set the date column as the index\n",
    "delays_features_432 = delays_features_432.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "filtered_df = delays_features_432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the size of each group\n",
    "group_sizes = filtered_df.groupby(['route_id']).size().reset_index(name='group_size')\n",
    "\n",
    "# Filter groupings with 108 rows\n",
    "valid_groups = group_sizes[group_sizes['group_size'] == 108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the valid_groups dataframe\n",
    "valid_groups.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the filtered_df dataframe\n",
    "filtered_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Merge with the original DataFrame to get the rows from valid groups\n",
    "filtered_df = pd.merge(filtered_df, valid_groups[['route_id']], on=['route_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Scale the numerical columns in the filtered_df dataframe\n",
    "scaler = StandardScaler()\n",
    "filtered_df[['wait_assessment', 'average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']] = scaler.fit_transform(filtered_df[['wait_assessment', 'average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']])\n",
    "filtered_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Make the date column a datetime data type\n",
    "filtered_df['date'] = pd.to_datetime(filtered_df['date'])\n",
    "\n",
    "# Move the date column to the index\n",
    "filtered_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a rolling mean to smooth out the data and make it stationary\n",
    "rolling_mean = features['wait_assessment'].rolling(window = 12).mean()\n",
    "features['rolling_mean_diff'] = rolling_mean - rolling_mean.shift()\n",
    "# Use interpolation to fill in the Null values in the features dataframe\n",
    "features = features.interpolate(method='pad')\n",
    "# Fill in the Null values in the rolling_mean_diff column With the mean of the rolling_mean_diff column\n",
    "features['rolling_mean_diff'] = features['rolling_mean_diff'].fillna(features['rolling_mean_diff'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Model Looping through the Valid Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to store the models, predictions, and route_ids\n",
    "sarimax_results = {}\n",
    "\n",
    "# Iterate over the unique route_ids\n",
    "for route_id in filtered_df['route_id'].unique():\n",
    "    # Filter the data for the current route_id\n",
    "    route_data = filtered_df[filtered_df['route_id'] == route_id]\n",
    "    \n",
    "    # Use a rolling mean to smooth out the data and make it stationary\n",
    "    rolling_mean = route_data['wait_assessment'].rolling(window = 12).mean()\n",
    "    route_data['rolling_mean_diff'] = rolling_mean - rolling_mean.shift()\n",
    "    \n",
    "    # Use interpolation to fill in the Null values in the features dataframe\n",
    "    route_data = route_data.interpolate(method='pad')\n",
    "    \n",
    "    # Fill in the Null values in the rolling_mean_diff column With the mean of the rolling_mean_diff column\n",
    "    route_data['rolling_mean_diff'] = route_data['rolling_mean_diff'].fillna(route_data['rolling_mean_diff'].mean())\n",
    "    \n",
    "    # Set the frequency of the index to monthly\n",
    "    route_data.index = pd.date_range(start='2015-01-01', periods=len(route_data), freq='M')\n",
    "    \n",
    "    # Define the endogenous variable (target)\n",
    "    endog = route_data['wait_assessment']\n",
    "\n",
    "    # Define the exogenous variables\n",
    "    exog = route_data[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']]\n",
    "    \n",
    "    # Add a constant to the exogenous variables\n",
    "    exog = sm.add_constant(exog)\n",
    "    \n",
    "    # Perform test/train split\n",
    "    train_size = 0.8  # You can adjust this ratio as needed\n",
    "    endog_train, endog_test, exog_train, exog_test = train_test_split(\n",
    "    endog, exog, train_size=train_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Set the frequency of the time series to monthly\n",
    "    freq = 'M'\n",
    "    \n",
    "    # Create the SARIMAX model\n",
    "    model = sm.tsa.SARIMAX(endog_train, exog = exog_train, order=(0, 1, 0), seasonal_order=(0, 1, 1, 12), freq = freq)\n",
    "    \n",
    "    # Fit the model\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    forecast = model_fit.get_forecast(steps=len(endog_test), exog=exog_test)\n",
    "    \n",
    "    # Save the model, predictions, and route_id to the dictionary\n",
    "    sarimax_results[route_id] = {'model': model_fit, 'predictions': forecast, 'route_id': route_id}\n",
    "\n",
    "# Print the dictionary of models, predictions, and route_ids\n",
    "print(sarimax_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dashboard to visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dropdown with unique route_ids\n",
    "route_id_options = [{'label': str(route_id), 'value': route_id} for route_id in sarimax_results.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dash app\n",
    "app = dash.Dash(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.Label('Select Route Id:'),\n",
    "    dcc.Dropdown(\n",
    "        id='route-id-dropdown',\n",
    "        options=route_id_options,\n",
    "        value=route_id_options[0]['value']\n",
    "    ),\n",
    "    dcc.Graph(id='time-series-plot')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback to update the plot based on the selected Route Id\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('time-series-plot', 'figure'),\n",
    "    [dash.dependencies.Input('route-id-dropdown', 'value')]\n",
    ")\n",
    "def update_plot(selected_route_id):\n",
    "    # Retrieve model and predictions for the selected Route Id\n",
    "    model_fit = sarimax_results[selected_route_id]['model']\n",
    "    predictions = sarimax_results[selected_route_id]['predictions']\n",
    "    route_data = filtered_df[filtered_df['route_id'] == selected_route_id]\n",
    "    endog_train = route_data['wait_assessment'][:int(len(route_data) * 0.8)]\n",
    "    endog_test = route_data['wait_assessment'][int(len(route_data) * 0.8):]\n",
    "\n",
    "    # Plot actual values from the training set\n",
    "    trace1 = go.Scatter(x=endog_train.index, y=endog_train, mode='lines', name='Actual (Training Set)', line=dict(color='blue'))\n",
    "\n",
    "    # Plot actual values from the test set\n",
    "    trace2 = go.Scatter(x=endog_test.index, y=endog_test, mode='lines', name='Actual (Test Set)', line=dict(color='blue', dash='dash'))\n",
    "\n",
    "    # Plot predicted values from the test set\n",
    "    trace3 = go.Scatter(x=endog_test.index, y=predictions.predicted_mean.to_numpy(), mode='lines', name='Predicted (Test Set)', line=dict(color='orange'))\n",
    "\n",
    "    # Set layout options\n",
    "    layout = dict(\n",
    "        title='Actual vs Predicted Values',\n",
    "        xaxis=dict(title='Date'),\n",
    "        yaxis=dict(title='Wait Assessment'),\n",
    "        legend=dict(x=0, y=1, traceorder='normal')\n",
    "    )\n",
    "\n",
    "    # Create the figure\n",
    "    figure = dict(data=[trace1, trace2, trace3], layout=layout)\n",
    "\n",
    "    return figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, use_reloader=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
