{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from sodapy import Socrata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Delay Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "#Wait Assessment 2020 Onwards - \"https://data.ny.gov/resource/swky-c3v4.csv\"\n",
    "\n",
    "# Create a directory to store the csv files\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Download the csv file\n",
    "wait_assessment_2020 = \"https://data.ny.gov/resource/swky-c3v4.csv?$limit=1000000000\"\n",
    "response = requests.get(wait_assessment_2020)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"wait_assessment_2020.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "wait_assessment_2020 = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column and row count\n",
    "print(wait_assessment_2020.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "wait_assessment_2020.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column name and data type\n",
    "print(wait_assessment_2020.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Split the month and year into separate columns\n",
    "wait_assessment_2020[[\"Year\", \"Month\"]] = wait_assessment_2020[\"month\"].str.split(\"-\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataframe\n",
    "wait_assessment_2020.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Wait Assessment 2015 - 2019 - \"https://data.ny.gov/resource/bmix-dpzc.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "wait_assessment_2015 = \"https://data.ny.gov/resource/bmix-dpzc.csv?$limit=1000000000\"\n",
    "response = requests.get(wait_assessment_2015)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"wait_assessment_2015.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "wait_assessment_2015 = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(wait_assessment_2015.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "wait_assessment_2015.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Split the month and year into separate columns\n",
    "wait_assessment_2015[[\"Year\", \"Month\"]] = wait_assessment_2015[\"month\"].str.split(\"-\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the two dataframes\n",
    "wait_assessment_2015_2020 = pd.concat([wait_assessment_2020, wait_assessment_2015], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(wait_assessment_2015_2020.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "wait_assessment_2015_2020.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Deliviered 2020 Onwards - \"https://data.ny.gov/resource/2e6s-9gpm.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "service_delivered_2020 = \"https://data.ny.gov/resource/2e6s-9gpm.csv?$limit=1000000000\"\n",
    "response = requests.get(service_delivered_2020)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"service_delivered_2020.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "service_delivered_2020 = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Deliviered 2015 - 2019 - \"https://data.ny.gov/resource/tw28-zvtk.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "service_delivered_2015 = \"https://data.ny.gov/resource/tw28-zvtk.csv?$limit=1000000000\"\n",
    "response = requests.get(service_delivered_2015)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"service_delivered_2015.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "service_delivered_2015 = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Traffic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a large file and takes some time to download.  It is not included in the repository. but the transformed data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly Traffic on (MTA) Bridges and Tunnels: Beginning 2010 - \"https://data.ny.gov/resource/qzve-kjga.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "hourly_traffic = \"https://data.ny.gov/resource/qzve-kjga.csv?$limit=1000000000\"\n",
    "response = requests.get(hourly_traffic)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"hourly_traffic.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "hourly_traffic = pd.read_csv(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the csv file for hourly_traffic\n",
    "hourly_traffic = pd.read_csv('hourly_traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(hourly_traffic.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "hourly_traffic.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new column named total_vehicles by adding the vehicles_e_zpass and vehicles_vtoll columns\n",
    "hourly_traffic[\"total_vehicles\"] = hourly_traffic[\"vehicles_e_zpass\"] + hourly_traffic[\"vehicles_vtoll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the year from the date_time column\n",
    "hourly_traffic[\"year\"] = hourly_traffic[\"date\"].str[:4]\n",
    "\n",
    "# Extract the month from the date column\n",
    "hourly_traffic[\"month\"] = hourly_traffic[\"date\"].str[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the dataframe to group by the Year, Month, plaza_id, and direction columns, giving the sum of the total_vehicles, vehicles_e_zpass, and vehicles_vtoll columns\n",
    "hourly_traffic_transformed = hourly_traffic.groupby([\"year\", \"month\", \"plaza_id\", \"direction\"]).agg({\"total_vehicles\": \"sum\", \"vehicles_e_zpass\": \"sum\", \"vehicles_vtoll\": \"sum\"}).reset_index()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(hourly_traffic_transformed.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "hourly_traffic_transformed.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column named 'value_type', all the values in this column should say 'vehicle_count'\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.assign(value_type=\"vehicle_count\")\n",
    "\n",
    "# change the plaza_id column to location_id, and change total_vehicles to value\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.rename(columns={\"plaza_id\": \"location_id\", \"total_vehicles\": \"value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep columns 1-5 and column 8 and drop the rest\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.iloc[:, list(range(5)) + [7]]\n",
    "\n",
    "# swap the order of the last 2 columns\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.iloc[:, [0, 1, 2, 3, 5, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hourly_traffic_transformed is one traffic df\n",
    "columns are:\n",
    "year\n",
    "month\n",
    "location_id\n",
    "direction\n",
    "value_type\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following csv is a large file available at https://data.cityofnewyork.us/resource/7ym2-wayt\n",
    "The full file has been downloaded and is used in the following script.\n",
    "The aggregate output will also be made available and it is recommended this is the version to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a CSV file and write it to a df using pandas\n",
    "# Open the CSV file\n",
    "\n",
    "traffic_speeds = pd.read_csv('DOT_Traffic_Speeds_NBE_20240121.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_backup = traffic_speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(traffic_speeds.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "traffic_speeds.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the Speed, travel_time, status, data_as_of, link_id, and borough columns\n",
    "traffic_speeds = traffic_speeds[['SPEED', 'TRAVEL_TIME', 'STATUS', 'DATA_AS_OF', 'LINK_ID', 'BOROUGH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the data_as_of column which is in the format of 09/20/2019 07:27:03 AM\n",
    "traffic_speeds[\"year\"] = traffic_speeds[\"DATA_AS_OF\"].str[6:10]\n",
    "\n",
    "# Extract the month from the data_as_of column which is in the format of 09/20/2019 07:27:03 AM\n",
    "traffic_speeds[\"month\"] = traffic_speeds[\"DATA_AS_OF\"].str[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by the Year, Month, and BOROUGH and LINK_ID, columns, giving the mean of the speed and travel_time columns\n",
    "traffic_speeds_transformed = traffic_speeds.groupby([\"year\", \"month\", \"BOROUGH\", \"LINK_ID\"]).agg({\"SPEED\": \"mean\", \"TRAVEL_TIME\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(traffic_speeds_transformed.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "traffic_speeds_transformed.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "traffic_speeds_transformed.to_csv(\"traffic_speeds_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load the transformed dataframe from a csv file\n",
    "traffic_speeds_transformed = pd.read_csv(\"traffic_speeds_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the dataframe so that the values in the speed and travel_time columns are in the same column and the column names are in a column named 'value_type'\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.melt(id_vars=[\"year\", \"month\", \"BOROUGH\", \"LINK_ID\"], value_vars=[\"SPEED\", \"TRAVEL_TIME\"], var_name=\"value_type\", value_name=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase the value_type column\n",
    "traffic_speeds_transformed[\"value_type\"] = traffic_speeds_transformed[\"value_type\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the BOROUGH column and change the LINK_ID column to location_id\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.drop(columns=[\"BOROUGH\"])\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.rename(columns={\"LINK_ID\": \"location_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column named 'direction' with all the values in this column should be null\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.assign(direction=\"null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the direction column to behind the location_id column\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.iloc[:, [0, 1, 2, 5, 3, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "traffic_speeds_transformed.to_csv(\"traffic_speeds_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load the transformed dataframe from a csv file\n",
    "traffic_speeds_transformed = pd.read_csv(\"traffic_speeds_transformed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traffic_speeds_transformed is one traffic df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip download and use the transformed data instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://data.cityofnewyork.us/Transportation/Automated-Traffic-Volume-Counts/7ym2-wayt\n",
    "\n",
    "# Download the csv file\n",
    "# Use a select and group by statement to get the count of the volume column grouped by the year, month, and roadway_name columns\n",
    "\n",
    "automated_traffic_volume_counts = \"https://data.ny.gov/resource/7ym2-wayt.csv?$select=Yr,M,Boro,sum(Vol)&$group=Yr,M,Boro&$limit=1000000000\" \n",
    "response = requests.get(automated_traffic_volume_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the csv file to disk\n",
    "csv_file = \"automated_traffic_volume_counts.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file to a dataframe\n",
    "automated_traffic_volume_counts = pd.read_csv(\"automated_traffic_volume_counts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automated_traffic_volume_counts.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names to year, month, location_id, and value\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.rename(columns={\"Yr\": \"year\", \"M\": \"month\", \"Boro\": \"location_id\", \"sum_Vol\": \"value\"})\n",
    "\n",
    "# Add a column named 'value_type' with all the values in this column should say 'vehicle_count'\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.assign(value_type=\"vehicle_count\")\n",
    "\n",
    "# Add a column named 'direction' with all the values in this column should be null\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.assign(direction=\"null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the order of the columns to 0,1,2,5,4,3\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.iloc[:, [0, 1, 2, 5, 4, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "automated_traffic_volume_counts.to_csv(\"automated_traffic_volume_counts_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "automated_traffic_volume_counts_transformed = pd.read_csv(\"automated_traffic_volume_counts_transformed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "automated_traffic_volume_counts_transformed is one traffic df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Traffic - \"https://data.ny.gov/resource/cwhc-n4ek.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "daily_traffic = \"https://data.ny.gov/resource/cwhc-n4ek.csv?$limit=1000000000\"\n",
    "response = requests.get(daily_traffic)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"daily_traffic.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "daily_traffic = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file\n",
    "daily_traffic = pd.read_csv('daily_traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(daily_traffic.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "daily_traffic.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the date column\n",
    "daily_traffic[\"year\"] = daily_traffic[\"date\"].str[:4]\n",
    "\n",
    "# Extract the month from the date column\n",
    "daily_traffic[\"month\"] = daily_traffic[\"date\"].str[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the vehicles_e_zpass and vehicles_vtoll columns to get the total_vehicles column\n",
    "daily_traffic[\"value\"] = daily_traffic[\"vehicles_e_zpass\"] + daily_traffic[\"vehicles_vtoll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sum of the total_vehicles, vehicles_e_zpass, and vehicles_vtoll columns grouped by the Year, Month, plaza_id, and direction columns\n",
    "daily_traffic_transformed = daily_traffic.groupby([\"year\", \"month\", \"plaza_id\", \"direction\"]).agg({\"value\": \"sum\", \"vehicles_e_zpass\": \"sum\", \"vehicles_vtoll\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dataframe to a csv file\n",
    "daily_traffic_transformed.to_csv(\"daily_traffic_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file\n",
    "daily_traffic_transformed = pd.read_csv('daily_traffic_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(daily_traffic_transformed.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "daily_traffic_transformed.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column named 'value_type' with all the values in this column should say 'vehicle_count'\n",
    "daily_traffic_transformed = daily_traffic_transformed.assign(value_type=\"vehicle_count\")\n",
    "\n",
    "# change the plaza_id column to location_id\n",
    "daily_traffic_transformed = daily_traffic_transformed.rename(columns={\"plaza_id\": \"location_id\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap the order of the last 2 columns\n",
    "daily_traffic_transformed = daily_traffic_transformed.iloc[:, [0, 1, 2, 3, 7, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "daily_traffic_transformed.to_csv(\"daily_traffic_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load the transformed dataframe from a csv file\n",
    "daily_traffic_transformed = pd.read_csv(\"daily_traffic_transformed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daily_traffic_transformed is one traffic df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic Volume Count Smaller - \"https://data.cityofnewyork.us/resource/btm5-ppia.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "volume_count_small = \"https://data.cityofnewyork.us/resource/btm5-ppia.csv?$limit=1000000000\"\n",
    "response = requests.get(volume_count_small)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"volume_count_small.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "volume_count_small = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(volume_count_small.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "volume_count_small.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named all day which is the sum of all columns ending in am or pm\n",
    "volume_count_small[\"value\"] = volume_count_small.filter(regex=\"am|pm\").sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Year column by extracting the year from the date column\n",
    "volume_count_small[\"year\"] = volume_count_small[\"date\"].str[0:4]\n",
    "\n",
    "# Create a Month column by extracting the month from the date column\n",
    "volume_count_small[\"month\"] = volume_count_small[\"date\"].str[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe by grouping the volume_count_small dataframe by the Year, Month, roadway_name, direction columns, giving the sum of the all_day column\n",
    "volume_count_small_transformed = volume_count_small.groupby([\"year\", \"month\", \"roadway_name\", \"direction\"]).agg({\"value\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names to year, month, location_id, and value\n",
    "volume_count_small_transformed = volume_count_small_transformed.rename(columns={\"roadway_name\": \"location_id\"})\n",
    "\n",
    "# Add a column named 'value_type' with all the values in this column should say 'vehicle_count'\n",
    "volume_count_small_transformed = volume_count_small_transformed.assign(value_type=\"vehicle_count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the order of the last 2 columns\n",
    "volume_count_small_transformed = volume_count_small_transformed.iloc[:, [0, 1, 2, 3, 5, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(volume_count_small_transformed.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "volume_count_small_transformed.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "volume_count_small_transformed.to_csv(\"volume_count_small_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file\n",
    "volume_count_small_transformed = pd.read_csv('volume_count_small_transformed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "volume_count_small_transformed is one traffic df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently have:\n",
    "<b>Delays :</b>\n",
    "\n",
    "Wait Assesment 2015-2024\n",
    "\n",
    "<b>Impact :</b>\n",
    "\n",
    "hourly_traffic_transformed,\n",
    "\n",
    "traffic_speeds_transformed,\n",
    "\n",
    "automated_traffic_valume_counts_tranformed,\n",
    "\n",
    "daily_traffic_transformed\n",
    "\n",
    "volume_count_small_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the dataframes into one dataframe\n",
    "traffic = pd.concat([hourly_traffic_transformed, traffic_speeds_transformed, automated_traffic_volume_counts_transformed, daily_traffic_transformed, volume_count_small_transformed], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(traffic.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "traffic.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year and month columns to integers\n",
    "traffic[\"year\"] = traffic[\"year\"].astype(int)\n",
    "traffic[\"month\"] = traffic[\"month\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum and maximum year\n",
    "print(traffic[\"year\"].min())\n",
    "print(traffic[\"year\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather data uploaded from local file\n",
    "\n",
    "Weather data is available from https://scacis.rcc-acis.org/\n",
    "\n",
    "Copied to csv and then loaded locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all the csv files\n",
    "weather_avg_perc = pd.read_csv('NYC Weather - average_percipitation.csv')\n",
    "weather_avg_temp = pd.read_csv('NYC Weather - avg_temp.csv')\n",
    "weather_max_perc = pd.read_csv('NYC Weather - max_precipitation.csv')\n",
    "weather_max_snow_depth = pd.read_csv('NYC Weather - max_snow_depth.csv')\n",
    "weather_max_snowfall = pd.read_csv('NYC Weather - max_snowfall.csv')\n",
    "weather_max_temp = pd.read_csv('NYC Weather - Max_Temp.csv')\n",
    "weather_min_temp = pd.read_csv('NYC Weather - Min_Temp.csv')\n",
    "weather_total_perc = pd.read_csv('NYC Weather - total_percipitation.csv')\n",
    "weather_total_snow_depth = pd.read_csv('NYC Weather - total_snow_depth.csv')\n",
    "weather_total_snowfall = pd.read_csv('NYC Weather - total_snowfall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the weather dataframes into one dataframe with a column named weather_type to indicate the type of weather\n",
    "weather_avg_perc[\"weather_type\"] = \"average_percipitation\"\n",
    "weather_avg_temp[\"weather_type\"] = \"avg_temp\"\n",
    "weather_max_perc[\"weather_type\"] = \"max_precipitation\"\n",
    "weather_max_snow_depth[\"weather_type\"] = \"max_snow_depth\"\n",
    "weather_max_snowfall[\"weather_type\"] = \"max_snowfall\"\n",
    "weather_max_temp[\"weather_type\"] = \"max_temp\"   \n",
    "weather_min_temp[\"weather_type\"] = \"min_temp\"\n",
    "weather_total_perc[\"weather_type\"] = \"total_percipitation\"\n",
    "weather_total_snow_depth[\"weather_type\"] = \"total_snow_depth\"\n",
    "weather_total_snowfall[\"weather_type\"] = \"total_snowfall\"\n",
    "\n",
    "# Combine all the weather dataframes into one dataframe\n",
    "weather = pd.concat([weather_avg_perc, weather_avg_temp, weather_max_perc, weather_max_snow_depth, weather_max_snowfall, weather_max_temp, weather_min_temp, weather_total_perc, weather_total_snow_depth, weather_total_snowfall], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take everything from 2000 onwards\n",
    "weather2000 = weather[weather['Year'] >= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2000.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Annual column  \n",
    "weather2000 = weather2000.drop(columns=['Annual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the dataframe so it is in long format\n",
    "weather2001 = weather2000.melt(id_vars=[\"Year\", \"weather_type\"], var_name=\"month\", value_name=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2001.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Year column to year\n",
    "weather2001 = weather2001.rename(columns={\"Year\": \"year\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the month column from Jan to 01, Feb to 02, etc.\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Jan\", \"01\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Feb\", \"02\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Mar\", \"03\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Apr\", \"04\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"May\", \"05\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Jun\", \"06\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Jul\", \"07\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Aug\", \"08\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Sep\", \"09\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Oct\", \"10\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Nov\", \"11\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Dec\", \"12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the order of the last 2 columns\n",
    "weather = weather2001.iloc[:, [0, 2, 1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "weather.to_csv(\"weather.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load the transformed dataframe from a csv file\n",
    "weather = pd.read_csv(\"weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random sample of 50 rows\n",
    "weather2002 = weather.sample(n=50, random_state=1) \n",
    "\n",
    "weather2002.describe(include='all')\n",
    "\n",
    "print(weather2002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of weather data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bus Delay Time Years are from 2015 - 2024\n",
    "# The Earliest Weather Data is from 2000 - 2024\n",
    "# The Earliest Traffic Data is from 2000 - 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform EDA on the delay data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EDA on the wait_assessment_2015_2020 dataframe\n",
    "delays.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the month column to date and the Year column to year\n",
    "delays = wait_assessment_2015_2020.rename(columns={\"month\": \"date\", \"Year\": \"year\", \"Month\": \"month\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation between the columns\n",
    "delays.corr()\n",
    "\n",
    "# Print a correlation heatmap\n",
    "import seaborn as sns\n",
    "sns.heatmap(delays.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for the columns\n",
    "delays.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the wait assessment data where the route_id is BX1\n",
    "delays[delays[\"route_id\"] == 'BX1'].plot(x=\"date\", y=\"wait_assessment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with the wait assessment data where the wait_assessment is an average of the wait_assessment column grouped by the year and month columns\n",
    "delays2 = delays.groupby([\"year\", \"month\"]).agg({\"wait_assessment\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display histogram of the wait_assessment column\n",
    "delays2.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the wait assessment data\n",
    "delays2.plot(x=\"year\", y=\"wait_assessment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform EDA on the traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EDA on the traffic dataframe\n",
    "traffic.describe(include='all')\n",
    "\n",
    "# Check the correlation between the columns\n",
    "traffic.corr()\n",
    "\n",
    "# Print a correlation heatmap\n",
    "import seaborn as sns\n",
    "sns.heatmap(traffic.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for the columns\n",
    "traffic.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the traffic data\n",
    "traffic.plot(x=\"year\", y=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the value counts for the value_type column\n",
    "traffic[\"value_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the rows where the value_type is vehicle_count\n",
    "traffic2 = traffic[traffic[\"value_type\"] == \"vehicle_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_speed = traffic[traffic[\"value_type\"] == \"speed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_time = traffic[traffic[\"value_type\"] == \"travel_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataframe\n",
    "traffic_speed.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum and maximum year\n",
    "print(traffic_speed[\"year\"].min())\n",
    "print(traffic_speed[\"year\"].max())\n",
    "\n",
    "print(traffic_time[\"year\"].min())\n",
    "print(traffic_time[\"year\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traffic2[\"year\"].min())\n",
    "print(traffic2[\"year\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataframe\n",
    "traffic2.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what locations_ids are present for years 2000-2013?\n",
    "traffic2000_2013 = traffic2[traffic2[\"year\"] <= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic2000_2013[\"location_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic2000_2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seperate dataframe for the traffic data where the location_id is 3\n",
    "traffic3 = traffic2[traffic2[\"location_id\"] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataframe\n",
    "traffic3.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sum of the value column grouped by the year and month columns\n",
    "traffic3 = traffic3.groupby([\"year\", \"month\"]).agg({\"value\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a date column by combining the year and month columns\n",
    "traffic3[\"date\"] = traffic3[\"year\"].astype(str) + \"-\" + traffic3[\"month\"].astype(str)\n",
    "\n",
    "# Convert the date column to a date data type\n",
    "traffic3[\"date\"] = pd.to_datetime(traffic3[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the traffic data with year and month on the x-axis and value on the y-axis\n",
    "traffic3.plot(x=\"date\", y=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform EDA on the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2988.000000</td>\n",
       "      <td>2988</td>\n",
       "      <td>2988</td>\n",
       "      <td>2813.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>average_percipitation</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2011.951807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.785393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.186479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.409790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2006.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2012.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>280.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               year           weather_type month        value\n",
       "count   2988.000000                   2988  2988  2813.000000\n",
       "unique          NaN                     10    12          NaN\n",
       "top             NaN  average_percipitation    01          NaN\n",
       "freq            NaN                    300   249          NaN\n",
       "mean    2011.951807                    NaN   NaN    19.785393\n",
       "std        7.186479                    NaN   NaN    30.409790\n",
       "min     2000.000000                    NaN   NaN    -1.000000\n",
       "25%     2006.000000                    NaN   NaN     0.000000\n",
       "50%     2012.000000                    NaN   NaN     2.040000\n",
       "75%     2018.000000                    NaN   NaN    36.700000\n",
       "max     2024.000000                    NaN   NaN   280.000000"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform EDA on the weather dataframe\n",
    "weather.describe(include='all')\n",
    "\n",
    "\n",
    "# Check the correlation between the columns\n",
    "#weather.corr()\n",
    "\n",
    "# Print a correlation heatmap\n",
    "#import seaborn as sns\n",
    "#sns.heatmap(weather.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace any alpha characters with null in the value column\n",
    "weather[\"value\"] = pd.to_numeric(weather[\"value\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>average_percipitation</th>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_temp</th>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_precipitation</th>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_snow_depth</th>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_snowfall</th>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_temp</th>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_temp</th>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_percipitation</th>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_snow_depth</th>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_snowfall</th>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       value\n",
       "weather_type                \n",
       "average_percipitation    289\n",
       "avg_temp                 288\n",
       "max_precipitation        289\n",
       "max_snow_depth           283\n",
       "max_snowfall             254\n",
       "max_temp                 289\n",
       "min_temp                 289\n",
       "total_percipitation      289\n",
       "total_snow_depth         289\n",
       "total_snowfall           254"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the number of null values in the value column grouped by the weather_type column\n",
    "weather.groupby(\"weather_type\").agg({\"value\": \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a date column by combining the year and month columns\n",
    "weather[\"date\"] = weather[\"year\"].astype(str) + \"-\" + weather[\"month\"].astype(str)\n",
    "\n",
    "# Convert the date column to a date data type\n",
    "weather[\"date\"] = pd.to_datetime(weather[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the weather data with year and month on the x-axis and value on the y-axis where the weather_type is the title\n",
    "weather[weather[\"weather_type\"] == \"max_temp\"].plot(x=\"date\", y=\"value\", title=\"max_temp\")\n",
    "weather[weather[\"weather_type\"] == \"min_temp\"].plot(x=\"date\", y=\"value\", title=\"min_temp\")\n",
    "weather[weather[\"weather_type\"] == \"avg_temp\"].plot(x=\"date\", y=\"value\", title=\"avg_temp\")\n",
    "weather[weather[\"weather_type\"] == \"max_precipitation\"].plot(x=\"date\", y=\"value\", title=\"max_precipitation\")\n",
    "weather[weather[\"weather_type\"] == \"average_percipitation\"].plot(x=\"date\", y=\"value\", title=\"average_percipitation\")\n",
    "weather[weather[\"weather_type\"] == \"total_percipitation\"].plot(x=\"date\", y=\"value\", title=\"total_percipitation\")\n",
    "weather[weather[\"weather_type\"] == \"max_snowfall\"].plot(x=\"date\", y=\"value\", title=\"max_snowfall\")\n",
    "weather[weather[\"weather_type\"] == \"total_snowfall\"].plot(x=\"date\", y=\"value\", title=\"total_snowfall\")\n",
    "weather[weather[\"weather_type\"] == \"max_snow_depth\"].plot(x=\"date\", y=\"value\", title=\"max_snow_depth\")\n",
    "weather[weather[\"weather_type\"] == \"total_snow_depth\"].plot(x=\"date\", y=\"value\", title=\"total_snow_depth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year            0\n",
       "weather_type    0\n",
       "month           0\n",
       "value           0\n",
       "date            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in null values with interpolation\n",
    "weather[\"value\"] = weather.groupby(\"weather_type\")[\"value\"].transform(lambda x: x.interpolate())\n",
    "\n",
    "# Check if there are any remaining null values\n",
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_percipitation    300\n",
       "max_precipitation        300\n",
       "max_snow_depth           300\n",
       "max_snowfall             300\n",
       "max_temp                 300\n",
       "min_temp                 300\n",
       "total_percipitation      300\n",
       "total_snow_depth         300\n",
       "total_snowfall           300\n",
       "avg_temp                 288\n",
       "Name: weather_type, dtype: int64"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the value counts for the weather_type column\n",
    "weather[\"weather_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01 00:00:00\n",
      "2023-12-01 00:00:00\n",
      "2000-01-01 00:00:00\n",
      "2024-12-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Find the date range for avg_temp and max_temp weather types\n",
    "print(weather[weather[\"weather_type\"] == \"avg_temp\"][\"date\"].min())\n",
    "print(weather[weather[\"weather_type\"] == \"avg_temp\"][\"date\"].max())\n",
    "\n",
    "print(weather[weather[\"weather_type\"] == \"max_temp\"][\"date\"].min())\n",
    "print(weather[weather[\"weather_type\"] == \"max_temp\"][\"date\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an avg_temp dataframe and a max_temp dataframe\n",
    "avg_temp = weather[weather[\"weather_type\"] == \"avg_temp\"]\n",
    "max_temp = weather[weather[\"weather_type\"] == \"max_temp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_10508\\951554189.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  avg_temp[\"month\"] = avg_temp[\"month\"].astype(float)\n",
      "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_10508\\951554189.py:5: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  avg_temp.describe(include=\"all\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>288.000000</td>\n",
       "      <td>288</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>avg_temp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2011.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>55.886111</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.934236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.458061</td>\n",
       "      <td>15.537295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2005.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>41.925000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2011.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>55.850000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2017.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>81.300000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               year weather_type       month       value                 date\n",
       "count    288.000000          288  288.000000  288.000000                  288\n",
       "unique          NaN            1         NaN         NaN                  288\n",
       "top             NaN     avg_temp         NaN         NaN  2000-01-01 00:00:00\n",
       "freq            NaN          288         NaN         NaN                    1\n",
       "first           NaN          NaN         NaN         NaN  2000-01-01 00:00:00\n",
       "last            NaN          NaN         NaN         NaN  2023-12-01 00:00:00\n",
       "mean    2011.500000          NaN    6.500000   55.886111                  NaN\n",
       "std        6.934236          NaN    3.458061   15.537295                  NaN\n",
       "min     2000.000000          NaN    1.000000   23.900000                  NaN\n",
       "25%     2005.750000          NaN    3.750000   41.925000                  NaN\n",
       "50%     2011.500000          NaN    6.500000   55.850000                  NaN\n",
       "75%     2017.250000          NaN    9.250000   71.000000                  NaN\n",
       "max     2023.000000          NaN   12.000000   81.300000                  NaN"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the month column to a float data type\n",
    "avg_temp[\"month\"] = avg_temp[\"month\"].astype(float)\n",
    "\n",
    "# describe the avg_temp dataframe\n",
    "avg_temp.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2000</td>\n",
       "      <td>avg_temp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>2000</td>\n",
       "      <td>avg_temp</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>2000-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>2000</td>\n",
       "      <td>avg_temp</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.2</td>\n",
       "      <td>2000-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>2000</td>\n",
       "      <td>avg_temp</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2000-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>2000</td>\n",
       "      <td>avg_temp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>63.5</td>\n",
       "      <td>2000-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>2023</td>\n",
       "      <td>avg_temp</td>\n",
       "      <td>8.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>2023</td>\n",
       "      <td>avg_temp</td>\n",
       "      <td>9.0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>2023-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>2023</td>\n",
       "      <td>avg_temp</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>2023-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>2023</td>\n",
       "      <td>avg_temp</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.7</td>\n",
       "      <td>2023-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>2023</td>\n",
       "      <td>avg_temp</td>\n",
       "      <td>12.0</td>\n",
       "      <td>44.6</td>\n",
       "      <td>2023-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year weather_type  month  value       date\n",
       "25    2000     avg_temp    1.0   31.3 2000-01-01\n",
       "274   2000     avg_temp    2.0   37.3 2000-02-01\n",
       "523   2000     avg_temp    3.0   47.2 2000-03-01\n",
       "772   2000     avg_temp    4.0   51.0 2000-04-01\n",
       "1021  2000     avg_temp    5.0   63.5 2000-05-01\n",
       "...    ...          ...    ...    ...        ...\n",
       "1791  2023     avg_temp    8.0   75.0 2023-08-01\n",
       "2040  2023     avg_temp    9.0   69.4 2023-09-01\n",
       "2289  2023     avg_temp   10.0   60.5 2023-10-01\n",
       "2538  2023     avg_temp   11.0   46.7 2023-11-01\n",
       "2787  2023     avg_temp   12.0   44.6 2023-12-01\n",
       "\n",
       "[288 rows x 5 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the year and the month values, ordered by year and month\n",
    "avg_temp.sort_values([\"year\", \"month\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
