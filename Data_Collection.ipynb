{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "import scikit_posthocs as sp\n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "from matplotlib import pyplot\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from itertools import product\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dash import html\n",
    "from dash import dcc\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import kruskal\n",
    "from statsmodels.graphics.factorplots import interaction_plot\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import levene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Delay Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "#Wait Assessment 2020 Onwards - \"https://data.ny.gov/resource/swky-c3v4.csv\"\n",
    "\n",
    "# Create a directory to store the csv files\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Download the csv file\n",
    "wait_assessment_2020 = \"https://data.ny.gov/resource/swky-c3v4.csv?$limit=1000000000\"\n",
    "response = requests.get(wait_assessment_2020)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"wait_assessment_2020.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "wait_assessment_2020 = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column and row count\n",
    "print(wait_assessment_2020.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "wait_assessment_2020.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column name and data type\n",
    "print(wait_assessment_2020.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Split the month and year into separate columns\n",
    "wait_assessment_2020[[\"Year\", \"Month\"]] = wait_assessment_2020[\"month\"].str.split(\"-\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataframe\n",
    "wait_assessment_2020.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Wait Assessment 2015 - 2019 - \"https://data.ny.gov/resource/bmix-dpzc.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "wait_assessment_2015 = \"https://data.ny.gov/resource/bmix-dpzc.csv?$limit=1000000000\"\n",
    "response = requests.get(wait_assessment_2015)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"wait_assessment_2015.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "wait_assessment_2015 = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(wait_assessment_2015.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "wait_assessment_2015.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Split the month and year into separate columns\n",
    "wait_assessment_2015[[\"Year\", \"Month\"]] = wait_assessment_2015[\"month\"].str.split(\"-\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the two dataframes\n",
    "wait_assessment_2015_2020 = pd.concat([wait_assessment_2020, wait_assessment_2015], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(wait_assessment_2015_2020.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "wait_assessment_2015_2020.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Deliviered 2020 Onwards - \"https://data.ny.gov/resource/2e6s-9gpm.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "service_delivered_2020 = \"https://data.ny.gov/resource/2e6s-9gpm.csv?$limit=1000000000\"\n",
    "response = requests.get(service_delivered_2020)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"service_delivered_2020.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "service_delivered_2020 = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Deliviered 2015 - 2019 - \"https://data.ny.gov/resource/tw28-zvtk.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "service_delivered_2015 = \"https://data.ny.gov/resource/tw28-zvtk.csv?$limit=1000000000\"\n",
    "response = requests.get(service_delivered_2015)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"service_delivered_2015.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "service_delivered_2015 = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Traffic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a large file and takes some time to download.  It is not included in the repository. but the transformed data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly Traffic on (MTA) Bridges and Tunnels: Beginning 2010 - \"https://data.ny.gov/resource/qzve-kjga.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "hourly_traffic = \"https://data.ny.gov/resource/qzve-kjga.csv?$limit=1000000000\"\n",
    "response = requests.get(hourly_traffic)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"hourly_traffic.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "hourly_traffic = pd.read_csv(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the csv file for hourly_traffic\n",
    "hourly_traffic = pd.read_csv('hourly_traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(hourly_traffic.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "hourly_traffic.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new column named total_vehicles by adding the vehicles_e_zpass and vehicles_vtoll columns\n",
    "hourly_traffic[\"total_vehicles\"] = hourly_traffic[\"vehicles_e_zpass\"] + hourly_traffic[\"vehicles_vtoll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the year from the date_time column\n",
    "hourly_traffic[\"year\"] = hourly_traffic[\"date\"].str[:4]\n",
    "\n",
    "# Extract the month from the date column\n",
    "hourly_traffic[\"month\"] = hourly_traffic[\"date\"].str[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the dataframe to group by the Year, Month, plaza_id, and direction columns, giving the sum of the total_vehicles, vehicles_e_zpass, and vehicles_vtoll columns\n",
    "hourly_traffic_transformed = hourly_traffic.groupby([\"year\", \"month\", \"plaza_id\", \"direction\"]).agg({\"total_vehicles\": \"sum\", \"vehicles_e_zpass\": \"sum\", \"vehicles_vtoll\": \"sum\"}).reset_index()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(hourly_traffic_transformed.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "hourly_traffic_transformed.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column named 'value_type', all the values in this column should say 'vehicle_count'\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.assign(value_type=\"vehicle_count\")\n",
    "\n",
    "# change the plaza_id column to location_id, and change total_vehicles to value\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.rename(columns={\"plaza_id\": \"location_id\", \"total_vehicles\": \"value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep columns 1-5 and column 8 and drop the rest\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.iloc[:, list(range(5)) + [7]]\n",
    "\n",
    "# swap the order of the last 2 columns\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.iloc[:, [0, 1, 2, 3, 5, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column named 'data_source', all the values in this column should say 'hourly_traffic'\n",
    "hourly_traffic_transformed = hourly_traffic_transformed.assign(data_source=\"hourly_traffic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "hourly_traffic_transformed.to_csv(\"hourly_traffic_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file for hourly_traffic_transformed\n",
    "hourly_traffic_transformed = pd.read_csv(\"hourly_traffic_transformed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hourly_traffic_transformed is one traffic df\n",
    "columns are:\n",
    "year\n",
    "month\n",
    "location_id\n",
    "direction\n",
    "value_type\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following csv is a large file available at https://data.cityofnewyork.us/resource/7ym2-wayt\n",
    "The full file has been downloaded and is used in the following script.\n",
    "The aggregate output will also be made available and it is recommended this is the version to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a CSV file and write it to a df using pandas\n",
    "# Open the CSV file\n",
    "\n",
    "traffic_speeds = pd.read_csv('DOT_Traffic_Speeds_NBE_20240121.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_backup = traffic_speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(traffic_speeds.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "traffic_speeds.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the Speed, travel_time, status, data_as_of, link_id, and borough columns\n",
    "traffic_speeds = traffic_speeds[['SPEED', 'TRAVEL_TIME', 'STATUS', 'DATA_AS_OF', 'LINK_ID', 'BOROUGH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the data_as_of column which is in the format of 09/20/2019 07:27:03 AM\n",
    "traffic_speeds[\"year\"] = traffic_speeds[\"DATA_AS_OF\"].str[6:10]\n",
    "\n",
    "# Extract the month from the data_as_of column which is in the format of 09/20/2019 07:27:03 AM\n",
    "traffic_speeds[\"month\"] = traffic_speeds[\"DATA_AS_OF\"].str[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by the Year, Month, and BOROUGH and LINK_ID, columns, giving the mean of the speed and travel_time columns\n",
    "traffic_speeds_transformed = traffic_speeds.groupby([\"year\", \"month\", \"BOROUGH\", \"LINK_ID\"]).agg({\"SPEED\": \"mean\", \"TRAVEL_TIME\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(traffic_speeds_transformed.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "traffic_speeds_transformed.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "traffic_speeds_transformed.to_csv(\"traffic_speeds_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load the transformed dataframe from a csv file\n",
    "traffic_speeds_transformed = pd.read_csv(\"traffic_speeds_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the dataframe so that the values in the speed and travel_time columns are in the same column and the column names are in a column named 'value_type'\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.melt(id_vars=[\"year\", \"month\", \"BOROUGH\", \"LINK_ID\"], value_vars=[\"SPEED\", \"TRAVEL_TIME\"], var_name=\"value_type\", value_name=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase the value_type column\n",
    "traffic_speeds_transformed[\"value_type\"] = traffic_speeds_transformed[\"value_type\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the BOROUGH column and change the LINK_ID column to location_id\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.drop(columns=[\"BOROUGH\"])\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.rename(columns={\"LINK_ID\": \"location_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column named 'direction' with all the values in this column should be null\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.assign(direction=\"null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the direction column to behind the location_id column\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.iloc[:, [0, 1, 2, 5, 3, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column named 'data_source' with all the values in this column should be 'traffic_speeds'\n",
    "traffic_speeds_transformed = traffic_speeds_transformed.assign(data_source=\"traffic_speeds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "traffic_speeds_transformed.to_csv(\"traffic_speeds_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load the transformed dataframe from a csv file\n",
    "traffic_speeds_transformed = pd.read_csv(\"traffic_speeds_transformed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traffic_speeds_transformed is one traffic df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip download and use the transformed data instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://data.cityofnewyork.us/Transportation/Automated-Traffic-Volume-Counts/7ym2-wayt\n",
    "\n",
    "# Download the csv file\n",
    "# Use a select and group by statement to get the count of the volume column grouped by the year, month, and roadway_name columns\n",
    "\n",
    "automated_traffic_volume_counts = \"https://data.ny.gov/resource/7ym2-wayt.csv?$select=Yr,M,Boro,sum(Vol)&$group=Yr,M,Boro&$limit=1000000000\" \n",
    "response = requests.get(automated_traffic_volume_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the csv file to disk\n",
    "csv_file = \"automated_traffic_volume_counts.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file to a dataframe\n",
    "automated_traffic_volume_counts = pd.read_csv(\"automated_traffic_volume_counts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automated_traffic_volume_counts.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names to year, month, location_id, and value\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.rename(columns={\"Yr\": \"year\", \"M\": \"month\", \"Boro\": \"location_id\", \"sum_Vol\": \"value\"})\n",
    "\n",
    "# Add a column named 'value_type' with all the values in this column should say 'vehicle_count'\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.assign(value_type=\"vehicle_count\")\n",
    "\n",
    "# Add a column named 'direction' with all the values in this column should be null\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.assign(direction=\"null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the order of the columns to 0,1,2,5,4,3\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.iloc[:, [0, 1, 2, 5, 4, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column named 'data_source' with all the values in this column should be 'automated_traffic_volume_counts'\n",
    "automated_traffic_volume_counts = automated_traffic_volume_counts.assign(data_source=\"automated_traffic_volume_counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "automated_traffic_volume_counts.to_csv(\"automated_traffic_volume_counts_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "automated_traffic_volume_counts_transformed = pd.read_csv(\"automated_traffic_volume_counts_transformed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "automated_traffic_volume_counts_transformed is one traffic df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Traffic - \"https://data.ny.gov/resource/cwhc-n4ek.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "daily_traffic = \"https://data.ny.gov/resource/cwhc-n4ek.csv?$limit=1000000000\"\n",
    "response = requests.get(daily_traffic)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"daily_traffic.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "daily_traffic = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file\n",
    "daily_traffic = pd.read_csv('daily_traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(daily_traffic.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "daily_traffic.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the date column\n",
    "daily_traffic[\"year\"] = daily_traffic[\"date\"].str[:4]\n",
    "\n",
    "# Extract the month from the date column\n",
    "daily_traffic[\"month\"] = daily_traffic[\"date\"].str[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the vehicles_e_zpass and vehicles_vtoll columns to get the total_vehicles column\n",
    "daily_traffic[\"value\"] = daily_traffic[\"vehicles_e_zpass\"] + daily_traffic[\"vehicles_vtoll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sum of the total_vehicles, vehicles_e_zpass, and vehicles_vtoll columns grouped by the Year, Month, plaza_id, and direction columns\n",
    "daily_traffic_transformed = daily_traffic.groupby([\"year\", \"month\", \"plaza_id\", \"direction\"]).agg({\"value\": \"sum\", \"vehicles_e_zpass\": \"sum\", \"vehicles_vtoll\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dataframe to a csv file\n",
    "daily_traffic_transformed.to_csv(\"daily_traffic_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file\n",
    "daily_traffic_transformed = pd.read_csv('daily_traffic_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(daily_traffic_transformed.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "daily_traffic_transformed.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column named 'value_type' with all the values in this column should say 'vehicle_count'\n",
    "daily_traffic_transformed = daily_traffic_transformed.assign(value_type=\"vehicle_count\")\n",
    "\n",
    "# change the plaza_id column to location_id\n",
    "daily_traffic_transformed = daily_traffic_transformed.rename(columns={\"plaza_id\": \"location_id\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap the order of the last 2 columns\n",
    "daily_traffic_transformed = daily_traffic_transformed.iloc[:, [0, 1, 2, 3, 7, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column named 'data_source' with all the values in this column should be 'daily_traffic'\n",
    "daily_traffic_transformed = daily_traffic_transformed.assign(data_source=\"daily_traffic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "daily_traffic_transformed.to_csv(\"daily_traffic_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load the transformed dataframe from a csv file\n",
    "daily_traffic_transformed = pd.read_csv(\"daily_traffic_transformed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daily_traffic_transformed is one traffic df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic Volume Count Smaller - \"https://data.cityofnewyork.us/resource/btm5-ppia.csv\"\n",
    "\n",
    "# Download the csv file\n",
    "volume_count_small = \"https://data.cityofnewyork.us/resource/btm5-ppia.csv?$limit=1000000000\"\n",
    "response = requests.get(volume_count_small)\n",
    "\n",
    "# Save the csv file to disk\n",
    "csv_file = \"volume_count_small.csv\"\n",
    "with open(csv_file, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "#Save the csv file to a dataframe    \n",
    "volume_count_small = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(volume_count_small.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "volume_count_small.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named all day which is the sum of all columns ending in am or pm\n",
    "volume_count_small[\"value\"] = volume_count_small.filter(regex=\"am|pm\").sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Year column by extracting the year from the date column\n",
    "volume_count_small[\"year\"] = volume_count_small[\"date\"].str[0:4]\n",
    "\n",
    "# Create a Month column by extracting the month from the date column\n",
    "volume_count_small[\"month\"] = volume_count_small[\"date\"].str[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe by grouping the volume_count_small dataframe by the Year, Month, roadway_name, direction columns, giving the sum of the all_day column\n",
    "volume_count_small_transformed = volume_count_small.groupby([\"year\", \"month\", \"roadway_name\", \"direction\"]).agg({\"value\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names to year, month, location_id, and value\n",
    "volume_count_small_transformed = volume_count_small_transformed.rename(columns={\"roadway_name\": \"location_id\"})\n",
    "\n",
    "# Add a column named 'value_type' with all the values in this column should say 'vehicle_count'\n",
    "volume_count_small_transformed = volume_count_small_transformed.assign(value_type=\"vehicle_count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the order of the last 2 columns\n",
    "volume_count_small_transformed = volume_count_small_transformed.iloc[:, [0, 1, 2, 3, 5, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(volume_count_small_transformed.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "volume_count_small_transformed.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column named 'data_source' with all the values in this column should be 'volume_count_small'\n",
    "volume_count_small_transformed = volume_count_small_transformed.assign(data_source=\"volume_count_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "volume_count_small_transformed.to_csv(\"volume_count_small_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv file\n",
    "volume_count_small_transformed = pd.read_csv('volume_count_small_transformed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "volume_count_small_transformed is one traffic df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Merge all the dataframes into one dataframe\n",
    "traffic = pd.concat([hourly_traffic_transformed, traffic_speeds_transformed, automated_traffic_volume_counts_transformed, daily_traffic_transformed, volume_count_small_transformed], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(traffic.shape)\n",
    "\n",
    "# Describe the dataframe\n",
    "traffic.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Set the year and month columns to integers\n",
    "traffic[\"year\"] = traffic[\"year\"].astype(int)\n",
    "traffic[\"month\"] = traffic[\"month\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum and maximum year\n",
    "print(traffic[\"year\"].min())\n",
    "print(traffic[\"year\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather data uploaded from local file\n",
    "\n",
    "Weather data is available from https://scacis.rcc-acis.org/\n",
    "\n",
    "Copied to csv and then loaded locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all the csv files\n",
    "weather_avg_perc = pd.read_csv('NYC Weather - average_percipitation.csv')\n",
    "weather_avg_temp = pd.read_csv('NYC Weather - avg_temp.csv')\n",
    "weather_max_perc = pd.read_csv('NYC Weather - max_precipitation.csv')\n",
    "weather_max_snow_depth = pd.read_csv('NYC Weather - max_snow_depth.csv')\n",
    "weather_max_snowfall = pd.read_csv('NYC Weather - max_snowfall.csv')\n",
    "weather_max_temp = pd.read_csv('NYC Weather - Max_Temp.csv')\n",
    "weather_min_temp = pd.read_csv('NYC Weather - Min_Temp.csv')\n",
    "weather_total_perc = pd.read_csv('NYC Weather - total_percipitation.csv')\n",
    "weather_total_snow_depth = pd.read_csv('NYC Weather - total_snow_depth.csv')\n",
    "weather_total_snowfall = pd.read_csv('NYC Weather - total_snowfall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the weather dataframes into one dataframe with a column named weather_type to indicate the type of weather\n",
    "weather_avg_perc[\"weather_type\"] = \"average_percipitation\"\n",
    "weather_avg_temp[\"weather_type\"] = \"avg_temp\"\n",
    "weather_max_perc[\"weather_type\"] = \"max_precipitation\"\n",
    "weather_max_snow_depth[\"weather_type\"] = \"max_snow_depth\"\n",
    "weather_max_snowfall[\"weather_type\"] = \"max_snowfall\"\n",
    "weather_max_temp[\"weather_type\"] = \"max_temp\"   \n",
    "weather_min_temp[\"weather_type\"] = \"min_temp\"\n",
    "weather_total_perc[\"weather_type\"] = \"total_percipitation\"\n",
    "weather_total_snow_depth[\"weather_type\"] = \"total_snow_depth\"\n",
    "weather_total_snowfall[\"weather_type\"] = \"total_snowfall\"\n",
    "\n",
    "# Combine all the weather dataframes into one dataframe\n",
    "weather = pd.concat([weather_avg_perc, weather_avg_temp, weather_max_perc, weather_max_snow_depth, weather_max_snowfall, weather_max_temp, weather_min_temp, weather_total_perc, weather_total_snow_depth, weather_total_snowfall], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take everything from 2000 onwards\n",
    "weather2000 = weather[weather['Year'] >= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2000.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Annual column  \n",
    "weather2000 = weather2000.drop(columns=['Annual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the dataframe so it is in long format\n",
    "weather2001 = weather2000.melt(id_vars=[\"Year\", \"weather_type\"], var_name=\"month\", value_name=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2001.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Year column to year\n",
    "weather2001 = weather2001.rename(columns={\"Year\": \"year\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the month column from Jan to 01, Feb to 02, etc.\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Jan\", \"01\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Feb\", \"02\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Mar\", \"03\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Apr\", \"04\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"May\", \"05\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Jun\", \"06\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Jul\", \"07\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Aug\", \"08\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Sep\", \"09\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Oct\", \"10\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Nov\", \"11\")\n",
    "weather2001[\"month\"] = weather2001[\"month\"].str.replace(\"Dec\", \"12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the order of the last 2 columns\n",
    "weather = weather2001.iloc[:, [0, 2, 1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "weather.to_csv(\"weather.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load the transformed dataframe from a csv file\n",
    "weather = pd.read_csv(\"weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random sample of 50 rows\n",
    "weather2002 = weather.sample(n=50, random_state=1) \n",
    "\n",
    "weather2002.describe(include='all')\n",
    "\n",
    "print(weather2002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of weather data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bus Delay Time Years are from 2015 - 2024\n",
    "# The Earliest Weather Data is from 2000 - 2024\n",
    "# The Earliest Traffic Data is from 2000 - 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform EDA on the delay data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Change the month column to date and the Year column to year\n",
    "delays = wait_assessment_2015_2020.rename(columns={\"month\": \"date\", \"Year\": \"year\", \"Month\": \"month\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EDA on the wait_assessment_2015_2020 dataframe\n",
    "delays.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation between the columns\n",
    "delays.corr()\n",
    "\n",
    "# Print a correlation heatmap\n",
    "sns.heatmap(delays.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for the columns\n",
    "delays.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the wait Assemsent column and plot a histogram\n",
    "sns.histplot(delays['wait_assessment'], kde=True).set(title='Wait Assessment Distribution', xlabel='Wait Assessment', ylabel='Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the wait Assemsent column and plot a boxplot\n",
    "sns.boxplot(x=delays[\"wait_assessment\"]).set(title='Wait Assessment Boxplot', xlabel='Wait Assessment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the wait_assessment column is normally distributed\n",
    "stat, p = shapiro(delays['wait_assessment'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Sample looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('Sample does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the percentiles of the wait_assessment column\n",
    "print(delays[\"wait_assessment\"].quantile([0.25, 0.5, 0.75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean, median and mode of the wait_assessment column with explanations for their meaning\n",
    "print(f\"The mean of the wait_assessment column is {delays['wait_assessment'].mean()}. \\\n",
    "    The mean is the average of the wait_assessment column. \\\n",
    "    It is the sum of all the values in the wait_assessment column divided by the number of values in the wait_assessment column.\")\n",
    "\n",
    "print(f\"The median of the wait_assessment column is {delays['wait_assessment'].median()}. \\\n",
    "      The median is the middle value of the wait_assessment column. \\\n",
    "      It is the value that splits the wait_assessment column into two halves.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the skewness and kurtosis of the wait_assessment column with explanations for their meaning\n",
    "print(f\"The skewness of the wait_assessment column is {delays['wait_assessment'].skew()}. \\\n",
    "    A skewness of 0 means the wait_assessment column is normally distributed. \\\n",
    "    A skewness less than 0 means the wait_assessment column is left skewed. \\\n",
    "    A skewness greater than 0 means the wait_assessment column is right skewed.\")\n",
    "\n",
    "print(f\"The kurtosis of the wait_assessment column is {delays['wait_assessment'].kurt()}. \\\n",
    "    The kurtosis is a measure of the tailedness of the wait_assessment column. \\\n",
    "    A kurtosis of 0 means the wait_assessment column has the same tailedness as a normal distribution. \\\n",
    "    A kurtosis less than 0 means the wait_assessment column is platykurtic. \\\n",
    "    A kurtosis greater than 0 means the wait_assessment column is leptokurtic.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the wait assessment data where the route_id is BX1\n",
    "delays[delays[\"route_id\"] == 'BX1'].plot(x=\"date\", y=\"wait_assessment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a df with the wait assessment data where the wait_assessment is an average of the wait_assessment column grouped by the year and month columns\n",
    "delays2 = delays.groupby([\"year\", \"month\"]).agg({\"wait_assessment\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display histogram of the wait_assessment column\n",
    "delays2.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the wait assessment data\n",
    "delays2.plot(x=\"year\", y=\"wait_assessment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by the date column, giving the mean of the wait_assessment column\n",
    "timeeda = delays.groupby(\"date\").agg({\"wait_assessment\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime object\n",
    "timeeda[\"date\"] = pd.to_datetime(timeeda[\"date\"])\n",
    "\n",
    "# Move the date column to the index\n",
    "timeeda = timeeda.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Time Series\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(timeeda.index, timeeda[\"wait_assessment\"], color=\"blue\")\n",
    "plt.title(\"Wait Assessment Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Wait Assessment\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeeda.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform EDA on the traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EDA on the traffic dataframe\n",
    "traffic.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation between the columns\n",
    "traffic.corr()\n",
    "\n",
    "# Print a correlation heatmap\n",
    "\n",
    "sns.heatmap(traffic.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for the columns\n",
    "traffic.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the traffic data\n",
    "traffic.plot(x=\"year\", y=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the value counts for the value_type column\n",
    "traffic[\"value_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the rows where the value_type is vehicle_count\n",
    "traffic2 = traffic[traffic[\"value_type\"] == \"vehicle_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_speed = traffic[traffic[\"value_type\"] == \"speed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_time = traffic[traffic[\"value_type\"] == \"travel_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataframe\n",
    "traffic_speed.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum and maximum year\n",
    "print(traffic_speed[\"year\"].min())\n",
    "print(traffic_speed[\"year\"].max())\n",
    "\n",
    "print(traffic_time[\"year\"].min())\n",
    "print(traffic_time[\"year\"].max())\n",
    "\n",
    "print(traffic2[\"year\"].min())\n",
    "print(traffic2[\"year\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traffic2[\"year\"].min())\n",
    "print(traffic2[\"year\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataframe\n",
    "traffic2.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seperate dataframe for the traffic data where the location_id is 3\n",
    "traffic3 = traffic2[traffic2[\"location_id\"] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataframe\n",
    "traffic3.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take value counts of the data_source column\n",
    "traffic3[\"data_source\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seperate dataframes for the traffic data where the data_source is hourly_traffic and daily_traffic\n",
    "traffic_hourly = traffic3[traffic3[\"data_source\"] == \"hourly_traffic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sum of the value column grouped by the year and month columns\n",
    "traffic3 = traffic3.groupby([\"year\", \"month\"]).agg({\"value\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a date column by combining the year and month columns\n",
    "traffic3[\"date\"] = traffic3[\"year\"].astype(str) + \"-\" + traffic3[\"month\"].astype(str)\n",
    "\n",
    "# Convert the date column to a date data type\n",
    "traffic3[\"date\"] = pd.to_datetime(traffic3[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the traffic data with year and month on the x-axis and value on the y-axis\n",
    "traffic3.plot(x=\"date\", y=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform EDA on the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EDA on the weather dataframe\n",
    "weather.describe(include='all')\n",
    "\n",
    "\n",
    "# Check the correlation between the columns\n",
    "weather.corr()\n",
    "\n",
    "# Print a correlation heatmap\n",
    "sns.heatmap(weather.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Replace any alpha characters with null in the value column\n",
    "weather[\"value\"] = pd.to_numeric(weather[\"value\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the number of null values in the value column grouped by the weather_type column\n",
    "weather.groupby(\"weather_type\").agg({\"value\": \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a date column by combining the year and month columns\n",
    "weather[\"date\"] = weather[\"year\"].astype(str) + \"-\" + weather[\"month\"].astype(str)\n",
    "\n",
    "# Convert the date column to a date data type\n",
    "weather[\"date\"] = pd.to_datetime(weather[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the weather data with year and month on the x-axis and value on the y-axis where the weather_type is the title\n",
    "weather[weather[\"weather_type\"] == \"max_temp\"].plot(x=\"date\", y=\"value\", title=\"max_temp\")\n",
    "weather[weather[\"weather_type\"] == \"min_temp\"].plot(x=\"date\", y=\"value\", title=\"min_temp\")\n",
    "weather[weather[\"weather_type\"] == \"avg_temp\"].plot(x=\"date\", y=\"value\", title=\"avg_temp\")\n",
    "weather[weather[\"weather_type\"] == \"max_precipitation\"].plot(x=\"date\", y=\"value\", title=\"max_precipitation\")\n",
    "weather[weather[\"weather_type\"] == \"average_percipitation\"].plot(x=\"date\", y=\"value\", title=\"average_percipitation\")\n",
    "weather[weather[\"weather_type\"] == \"total_percipitation\"].plot(x=\"date\", y=\"value\", title=\"total_percipitation\")\n",
    "weather[weather[\"weather_type\"] == \"max_snowfall\"].plot(x=\"date\", y=\"value\", title=\"max_snowfall\")\n",
    "weather[weather[\"weather_type\"] == \"total_snowfall\"].plot(x=\"date\", y=\"value\", title=\"total_snowfall\")\n",
    "weather[weather[\"weather_type\"] == \"max_snow_depth\"].plot(x=\"date\", y=\"value\", title=\"max_snow_depth\")\n",
    "weather[weather[\"weather_type\"] == \"total_snow_depth\"].plot(x=\"date\", y=\"value\", title=\"total_snow_depth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year            0\n",
       "month           0\n",
       "weather_type    0\n",
       "value           0\n",
       "date            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in null values with interpolation\n",
    "weather[\"value\"] = weather.groupby(\"weather_type\")[\"value\"].transform(lambda x: x.interpolate())\n",
    "\n",
    "# Check if there are any remaining null values\n",
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the value counts for the weather_type column\n",
    "weather[\"weather_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the date range for avg_temp and max_temp weather types\n",
    "print(weather[weather[\"weather_type\"] == \"avg_temp\"][\"date\"].min())\n",
    "print(weather[weather[\"weather_type\"] == \"avg_temp\"][\"date\"].max())\n",
    "\n",
    "print(weather[weather[\"weather_type\"] == \"max_temp\"][\"date\"].min())\n",
    "print(weather[weather[\"weather_type\"] == \"max_temp\"][\"date\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an avg_temp dataframe and a max_temp dataframe\n",
    "avg_temp = weather[weather[\"weather_type\"] == \"avg_temp\"]\n",
    "max_temp = weather[weather[\"weather_type\"] == \"max_temp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the month column to a float data type\n",
    "avg_temp[\"month\"] = avg_temp[\"month\"].astype(float)\n",
    "\n",
    "# describe the avg_temp dataframe\n",
    "avg_temp.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the year and the month values, ordered by year and month\n",
    "avg_temp.sort_values([\"year\", \"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Remove any rows where the date is after 2023-12-01\n",
    "weather = weather[weather[\"date\"] <= \"2023-12-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the weather dataframe\n",
    "weather.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Value Counts on the weather_type column\n",
    "weather[\"weather_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows where period is Systemwide\n",
    "\n",
    "delays_clean = delays[delays[\"period\"] != \"Systemwide\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows where borough is Systemwide or Misc\n",
    "delays_clean = delays_clean[delays_clean[\"borough\"] != \"Systemwide\"]\n",
    "delays_clean = delays_clean[delays_clean[\"borough\"] != \"Misc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_clean.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an anova_delays df grouped by the date, bourough, route id, and period, with the mean of the wait_assessment column\n",
    "anova_delays = delays_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Delays_clean by date, borough and period and get the mean of the wait_assessment column\n",
    "delays_clean = delays_clean.groupby([\"date\", \"borough\", \"period\"]).agg({\"wait_assessment\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print value counts for the period and borough columns\n",
    "delays_clean[\"period\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_clean.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_delays.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import levene\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Drop rows with NaN values in 'wait_assessment' column\n",
    "anova_delays_cleaned = anova_delays.dropna(subset=['wait_assessment'])\n",
    "\n",
    "# Group the cleaned data\n",
    "grouped_data = anova_delays_cleaned.groupby(['borough', 'period'])['wait_assessment']\n",
    "\n",
    "# Convert the grouped data to a list of arrays\n",
    "data = [group.values for name, group in grouped_data]\n",
    "\n",
    "# Perform Levene's test\n",
    "statistic, p_value = levene(*data)\n",
    "\n",
    "# Check the result\n",
    "if np.isnan(statistic) or np.isnan(p_value):\n",
    "    print(\"Unable to perform Levene's test due to NaN values in the data.\")\n",
    "elif p_value > 0.05:\n",
    "    print(\"Homogeneity of variances is satisfied (p > 0.05)\")\n",
    "else:\n",
    "    print(\"Homogeneity of variances is not satisfied (p <= 0.05)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistic, p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = anova_delays.groupby(['borough', 'period'])['wait_assessment']\n",
    "\n",
    "for name, group in grouped_data:\n",
    "    # Perform Shapiro-Wilk test for normality\n",
    "    stat, p_value = shapiro(group)\n",
    "    \n",
    "    # Check the result\n",
    "    if p_value > 0.05:\n",
    "        print(f\"Data for {name} is normally distributed (p > 0.05)\")\n",
    "    else:\n",
    "        print(f\"Data for {name} is not normally distributed (p <= 0.05)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table showing the result of the Shapiro-Wilk test for normality for each group\n",
    "shapiro_table = pd.DataFrame(columns=[\"group\", \"p_value\"])\n",
    "\n",
    "for name, group in grouped_data:\n",
    "    stat, p_value = shapiro(group)\n",
    "    shapiro_table = shapiro_table.append({\"group\": name, \"p_value\": p_value}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the shapiro_table to a csv file\n",
    "shapiro_table.to_csv(\"shapiro_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create probability plots for the wait_assessment column grouped by the period and borough columns\n",
    "for name, group in grouped_data:\n",
    "    sm.qqplot(group, line ='45')\n",
    "    plt.title(f\"Probability Plot for {name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a boxplot of the wait_assessment column grouped by the borough and period columns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.boxplot(x=\"borough\", y=\"wait_assessment\", hue=\"period\", data=anova_delays, palette=\"Set1\")\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Wait Assessment')\n",
    "plt.title('Wait Assessment by Borough and Period')\n",
    "plt.legend(title='Period', loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean and standard deviation for each borough and period combination\n",
    "for x in anova_delays['borough'].unique():\n",
    "    for y in anova_delays['period'].unique():\n",
    "        print(x, y, \"Mean :\", round(anova_delays[(anova_delays['borough'] == x) & (anova_delays['period'] == y)]['wait_assessment'].mean(),2))\n",
    "        print(x, y, \"Standard Deviation :\", round(anova_delays[(anova_delays['borough'] == x) & (anova_delays['period'] == y)]['wait_assessment'].std(),2),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table with the mean and standard deviation for each borough and period combination and save it to a csv file\n",
    "anova_delays.groupby(['borough', 'period'])['wait_assessment'].agg(['mean', 'std']).to_csv(\"delays_mean_stddev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types of the columns\n",
    "print(anova_delays.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform borough and period to categorical data types\n",
    "anova_delays[\"borough\"] = anova_delays[\"borough\"].astype(\"category\")\n",
    "anova_delays[\"period\"] = anova_delays[\"period\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform an ANOVA on the delay data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform two-way ANOVA\n",
    "# The effect of borough, the effect of period, and the interaction between borough and period\n",
    "model = ols('wait_assessment ~ borough + period + borough:period', data = anova_delays).fit()\n",
    "aov2 = sm.stats.anova_lm(model, type=2)\n",
    "print(aov2, '\\n')\n",
    "\n",
    "# print the results of the two-way ANOVA hypothesis tests\n",
    "print(f\"Borough p-value: {aov2['PR(>F)'][0]:.4f}\")\n",
    "print(f\"Period p-value: {aov2['PR(>F)'][1]:.4f}\")\n",
    "print(f\"Interaction p-value: {aov2['PR(>F)'][2]:.4f}\", '\\n')\n",
    "\n",
    "# Print the results of the two-way ANOVA hypothesis tests\n",
    "if aov2['PR(>F)'][0] < 0.05:\n",
    "    print(\"Reject null hypothesis - Significant differences exist between Borough groups.\")\n",
    "else:\n",
    "    print(\"Accept null hypothesis - No significant difference between Borough groups.\")\n",
    "    \n",
    "if aov2['PR(>F)'][1] < 0.05:\n",
    "    print(\"Reject null hypothesis - Significant differences exist between Period groups.\")\n",
    "else:\n",
    "    print(\"Accept null hypothesis - No significant difference between Period groups.\")\n",
    "    \n",
    "if aov2['PR(>F)'][2] < 0.05:\n",
    "    print(\"Reject null hypothesis - Interaction occurs between factors.\")\n",
    "else:\n",
    "    print(\"Accept null hypothesis - No interaction occurs between factors.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store to aov2 in a table and save it to a csv file\n",
    "aov2.to_csv(\"aov2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'period' and 'borough' columns to string type\n",
    "anova_delays['period'] = anova_delays['period'].astype(str)\n",
    "anova_delays['borough'] = anova_delays['borough'].astype(str)\n",
    "\n",
    "# Plot the interaction plot\n",
    "fig = interaction_plot(x=anova_delays['period'].values, trace=anova_delays['borough'].values, response=anova_delays['wait_assessment'].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Post Hoc Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a Tukey's Range Test to determine which groups are significantly different from each other\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Perform Tukey's Range Test\n",
    "tukey_results = pairwise_tukeyhsd(anova_delays['wait_assessment'], anova_delays['borough'], 0.05)\n",
    "\n",
    "# Print the results\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a Tukey's Range Test to determine which groups are significantly different from each other\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Perform Tukey's Range Test\n",
    "tukey_results = pairwise_tukeyhsd(anova_delays['wait_assessment'], anova_delays['period'], 0.05)\n",
    "\n",
    "# Print the results\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Kruskal-Wallus Test for Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the date distribution of the wait_assessment column\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.boxplot(x=\"period\", y=\"wait_assessment\", data=delays_clean, palette=\"Set1\")\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Wait Assessment')\n",
    "plt.title('Wait Assessment by Period')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kruskal-Wallis test\n",
    "stat, p = kruskal(*[delays_clean[delays_clean['period'] == rate]['wait_assessment'] for rate in delays_clean['period'].unique()])\n",
    "\n",
    "# Print the results\n",
    "print(\"Kruskal-Wallis Test Results:\")\n",
    "print(f\"Test statistic: {stat:.4f}\")\n",
    "print(f\"P-value: {p:.4f}\")\n",
    "\n",
    "# Calculate the critical value for the significance level of 0.05\n",
    "critical_value = chi2.ppf(1-0.05, 2)\n",
    "\n",
    "print(f\"Critical value: {critical_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform post-hoc test\n",
    "sp.posthoc_dunn([delays_clean[delays_clean['period'] == rate]['wait_assessment'] for rate in delays_clean['period'].unique()], p_adjust='holm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Kruska-Wallis Test for Boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the date distribution of the wait_assessment column\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.boxplot(x=\"borough\", y=\"wait_assessment\", data=delays_clean, palette=\"Set1\")\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Wait Assessment')\n",
    "plt.title('Wait Assessment by Borough')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the median value of the wait_assessment column grouped by the borough\n",
    "print(delays_clean.groupby(\"borough\")[\"wait_assessment\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kruskal-Wallis test\n",
    "stat, p = kruskal(*[delays_clean[delays_clean['borough'] == rate]['wait_assessment'] for rate in delays_clean['borough'].unique()])\n",
    "\n",
    "# Print the results\n",
    "print(\"Kruskal-Wallis Test Results:\")\n",
    "print(f\"Test statistic: {stat:.4f}\")\n",
    "print(f\"P-value: {p:.4f}\")\n",
    "\n",
    "# Calculate the critical value for the significance level of 0.05\n",
    "critical_value = chi2.ppf(1-0.05, 2)\n",
    "\n",
    "print(f\"Critical value: {critical_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform post-hoc test\n",
    "sp.posthoc_dunn([delays_clean[delays_clean['borough'] == rate]['wait_assessment'] for rate in delays_clean['borough'].unique()], p_adjust='holm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the post-hoc test results to a table and export it to a csv file\n",
    "sp.posthoc_dunn([delays_clean[delays_clean['borough'] == rate]['wait_assessment'] for rate in delays_clean['borough'].unique()], p_adjust='holm').to_csv(\"posthoc_dunn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which Weather Data to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Weather Data in wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Melt the weather dataframe so all the weather types are in seperate columns, with only the date column remaining\n",
    "weather_wide = weather.pivot(index=\"date\", columns=\"weather_type\", values=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the weather_wide dataframe\n",
    "weather_wide.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the delays dataframe\n",
    "delays2.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# create a date column by combining the year and month columns\n",
    "delays2[\"date\"] = delays2[\"year\"].astype(str) + \"-\" + delays2[\"month\"].astype(str)\n",
    "\n",
    "# Convert the date column to a date data type\n",
    "delays2[\"date\"] = pd.to_datetime(delays2[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join with Delay Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "delays_weather = pd.merge(weather_wide, delays2, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the delays_weather dataframe\n",
    "delays_weather.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Null values in the delays_weather dataframe\n",
    "delays_weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the Null values from the delays_weather dataframe\n",
    "delays_weather = delays_weather.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA to understand which weather data has the most impact on delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_weather.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate the features (weather type columns) from the target (wait assessment column)\n",
    "features = delays_weather.drop(columns=['date', 'wait_assessment', 'year', 'month'])\n",
    "target = delays_weather['wait_assessment']\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca.fit(features)\n",
    "\n",
    "# Get the explained variance ratio for each principal component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "pca_results = pd.DataFrame({'Weather Type': features.columns, 'Explained Variance Ratio': explained_variance_ratio})\n",
    "\n",
    "# Sort the dataframe by the explained variance ratio in descending order, round the values to 2 decimal places\n",
    "pca_results = pca_results.round(2)\n",
    "pca_results = pca_results.sort_values(by='Explained Variance Ratio', ascending=False)\n",
    "\n",
    "# Print the results\n",
    "print(pca_results)\n",
    "\n",
    "# Print the Top 3 Weather Types\n",
    "print(pca_results.iloc[0:3, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Keep only the avg_perc and avg_temp columns\n",
    "weather_features = delays_weather[['date', 'average_percipitation', 'avg_temp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Average Percipitation and Average Temperature as the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weathereda = weather_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime object\n",
    "weathereda[\"date\"] = pd.to_datetime(weathereda[\"date\"])\n",
    "\n",
    "# Move the date column to the index\n",
    "weathereda = weathereda.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the average_percipitation column\n",
    "sns.histplot(weather_features['average_percipitation'], kde=True).set(title='Average Percipitation Distribution', xlabel='Average Percipitation', ylabel='Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot with min max and median labels\n",
    "#sns.boxplot(x=weather_features[\"average_percipitation\"]).set(title='Average Percipitation Boxplot', xlabel='Average Percipitation')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the box plot\n",
    "plt.boxplot(weather_features[\"average_percipitation\"], labels=[\"Average Percipitation\"])\n",
    "\n",
    "# Add labels for min, max, and median values\n",
    "min_val = weather_features[\"average_percipitation\"].min()\n",
    "max_val = weather_features[\"average_percipitation\"].max()\n",
    "median_val = weather_features[\"average_percipitation\"].median()\n",
    "\n",
    "plt.text(1, min_val, f\"Min: {min_val:.2f}\", ha='center', va='bottom')\n",
    "plt.text(1, max_val, f\"Max: {max_val:.2f}\", ha='center', va='top')\n",
    "plt.text(1, median_val, f\"Median: {median_val:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "# Set the title and x-axis label\n",
    "plt.title('Average Percipitation Boxplot')\n",
    "plt.xlabel('Average Percipitation')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean and median of the average_percipitation column\n",
    "print(f\"The mean of the average_percipitation column is {weather_features['average_percipitation'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the 25th, 50th, 75th and 95th percentiles of the average_percipitation column\n",
    "print(weather_features[\"average_percipitation\"].quantile([0.25, 0.5, 0.75, 0.95]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The median of the average_percipitation column is {weather_features['average_percipitation'].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the skewness and kurtosis of the average_percipitation column\n",
    "print(f\"The skewness of the average_percipitation column is {weather_features['average_percipitation'].skew()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the avg_temp column\n",
    "sns.histplot(weather_features['avg_temp'], kde=True).set(title='Average Temperature Distribution', xlabel='Average Temperature', ylabel='Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and median of the average tempeture column\n",
    "print(f\"The mean of the avg_temp column is {weather_features['avg_temp'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The median of the avg_temp column is {weather_features['avg_temp'].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the skewness and kurtosis of the average tempeture column\n",
    "print(f\"The skewness of the avg_temp column is {weather_features['avg_temp'].skew()}\")\n",
    "print(f\"The kurtosis of the avg_temp column is {weather_features['avg_temp'].kurt()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a time series plot for the average tempeture column\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(weathereda.index, weathereda[\"avg_temp\"], color=\"blue\")\n",
    "plt.title(\"Average Temperature Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Temperature\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which Traffic Data to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Traffic Data in wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the traffic dataframe\n",
    "traffic.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "traffic_wide = traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate the 'value_type' and 'data_source' columns to create a new column named 'traffic_type'\n",
    "traffic_wide[\"traffic_type\"] = traffic_wide[\"value_type\"] + \"_\" + traffic_wide[\"data_source\"]\n",
    "\n",
    "# Get rid of the 'value_type' and 'data_source' columns\n",
    "traffic_wide = traffic_wide.drop(columns=[\"value_type\", \"data_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concate the 'location_id' and 'traffic_type' columns to create a new column named 'location_traffic_type'\n",
    "#traffic_wide[\"location_traffic_type\"] = traffic_wide[\"location_id\"].astype(str) + \"_\" + traffic_wide[\"traffic_type\"]\n",
    "\n",
    "# Get rid of the 'location_id' column\n",
    "#traffic_wide = traffic_wide.drop(columns=[\"location_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a date column by combining the year and month columns\n",
    "traffic_wide[\"date\"] = traffic_wide[\"year\"].astype(str) + \"-\" + traffic_wide[\"month\"].astype(str)\n",
    "\n",
    "# Convert the date column to a date data type\n",
    "traffic_wide[\"date\"] = pd.to_datetime(traffic_wide[\"date\"])\n",
    "\n",
    "# Drop the year and month columns\n",
    "traffic_wide = traffic_wide.drop(columns=[\"year\", \"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the traffic_wide dataframe\n",
    "traffic_wide.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the traffic_wide dataframe so that the values for where the location_id and traffic_type columns are added together\n",
    "traffic_wide = traffic_wide.groupby([\"date\", \"location_id\", \"traffic_type\"]).agg({\"value\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the traffic_wide dataframe so that the values for where the location_id and traffic_type are the same are averaged together\n",
    "traffic_wide = traffic_wide.groupby([\"date\", \"traffic_type\"]).agg({\"value\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Melt the traffic_wide dataframe so all the traffic_type column values are in seperate columns, with only the date column remaining\n",
    "traffic_wide = traffic_wide.pivot(index=\"date\", columns=\"traffic_type\", values=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the traffic_wide dataframe\n",
    "traffic_wide.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join with Delay Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Join the traffic_wide and delays dataframes together\n",
    "traffic_delays = pd.merge(traffic_wide, delays2, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the traffic_delays dataframe\n",
    "traffic_delays.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Null values in the traffic_delays dataframe\n",
    "traffic_delays.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Take only the rows where the wait_assessment column is not null\n",
    "traffic_delays = traffic_delays[traffic_delays[\"wait_assessment\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a time series graph of the traffic columns in the traffic_delays dataframe\n",
    "traffic_delays.plot(x=\"date\", y=[\"speed_traffic_speeds\", \"travel_time_traffic_speeds\",\"vehicle_count_automated_traffic_volume_counts\",\"vehicle_count_daily_traffic\", \"vehicle_count_hourly_traffic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Use interpolation to fill in the Null values in the traffic_delays dataframe\n",
    "traffic_delays = traffic_delays.interpolate(method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the vehicle_count_volume_count_small column and all rows after 2023-12-01\n",
    "traffic_delays = traffic_delays.drop(columns=[\"vehicle_count_volume_count_small\", \"travel_time_traffic_speeds\", \"speed_traffic_speeds\", \"vehicle_count_daily_traffic\"])\n",
    "traffic_delays = traffic_delays[traffic_delays[\"date\"] <= \"2023-12-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_delays.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of Null values in the traffic_delays dataframe\n",
    "traffic_delays.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA to understand which traffic data has the most impact on delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features (traffic type columns) from the target (wait assessment column)\n",
    "features = traffic_delays.drop(columns=['date', 'wait_assessment', 'year', 'month'])\n",
    "target = traffic_delays['wait_assessment']\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca.fit(features)\n",
    "\n",
    "# Get the explained variance ratio for each principal component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "pca_results = pd.DataFrame({'Traffic Type': features.columns, 'Explained Variance Ratio': explained_variance_ratio})\n",
    "\n",
    "# Sort the dataframe by the explained variance ratio in descending order, round the values to 2 decimal places\n",
    "pca_results = pca_results.round(2)\n",
    "pca_results = pca_results.sort_values(by='Explained Variance Ratio', ascending=False)\n",
    "\n",
    "# Print the results\n",
    "print(pca_results)\n",
    "\n",
    "# Print the Top 2 Traffic Types\n",
    "print(pca_results.iloc[0:2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Keep only the avg_perc and avg_temp columns\n",
    "traffic_features = traffic_delays[['date', 'vehicle_count_automated_traffic_volume_counts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficeda = traffic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime object\n",
    "trafficeda[\"date\"] = pd.to_datetime(trafficeda[\"date\"])\n",
    "\n",
    "# Move the date column to the index\n",
    "trafficeda = trafficeda.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the normal distribution of the vehicle_count_automated_traffic_volume_counts column\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.histplot(trafficeda['vehicle_count_automated_traffic_volume_counts'], kde=True).set(title='Vehicle Count Automated Traffic Volume Counts Distribution', xlabel='Vehicle Count Automated Traffic Volume Counts', ylabel='Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean and median values of the vehicle_count_automated_traffic_volume_counts column\n",
    "print(f\"The mean of the vehicle_count_automated_traffic_volume_counts column is {trafficeda['vehicle_count_automated_traffic_volume_counts'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The median of the vehicle_count_automated_traffic_volume_counts column is {trafficeda['vehicle_count_automated_traffic_volume_counts'].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the skewness and kurtosis of the vehicle_count_automated_traffic_volume_counts column\n",
    "print(f\"The skewness of the vehicle_count_automated_traffic_volume_counts column is {trafficeda['vehicle_count_automated_traffic_volume_counts'].skew()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The kurtosis of the vehicle_count_automated_traffic_volume_counts column is {trafficeda['vehicle_count_automated_traffic_volume_counts'].kurt()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the normality of the vehicle_count_automated_traffic_volume_counts column\n",
    "stat, p = shapiro(trafficeda['vehicle_count_automated_traffic_volume_counts'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Sample looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('Sample does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series plot for the vehicle_count_automated_traffic_volume_counts data\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(trafficeda.index, trafficeda[\"vehicle_count_automated_traffic_volume_counts\"], color=\"red\")\n",
    "plt.title(\"Vehicle Count Automated Traffic Volume Counts Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Vehicle Count Automated Traffic Volume Counts\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use vehicle_count_automated_traffic_volume_counts as the traffic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data for the model, combining the delays, weather and traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the year and month columns\n",
    "delays2 = delays2.drop(columns=[\"year\", \"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays2.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_features.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_features.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Join the weather_features and traffic_features and delays2 dataframes together\n",
    "features = pd.merge(delays2, weather_features, on=\"date\", how=\"left\")\n",
    "features = pd.merge(features, traffic_features, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the features dataframe\n",
    "features.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompose the time series to understand the trend and seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the date column to a date data type\n",
    "features[\"date\"] = pd.to_datetime(features[\"date\"])\n",
    "\n",
    "# Have the date column as the index\n",
    "features = features.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# set the frequncey of the index to monthly\n",
    "features.index = pd.date_range(start='2015-01-01', periods=len(features), freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose_data = seasonal_decompose(features['wait_assessment'], model=\"additive\")\n",
    "decompose_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose_data = seasonal_decompose(features['wait_assessment'], model=\"multiplicative\")\n",
    "\n",
    "decompose_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonality=decompose_data.seasonal\n",
    "seasonality.plot(color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the stationarity of the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = adfuller(features.wait_assessment, autolag = 'AIC')\n",
    "print(\"1. ADF : \",dftest[0])\n",
    "print(\"2. P-Value : \", dftest[1])\n",
    "print(\"3. Num Of Lags : \", dftest[2])\n",
    "print(\"4. Num Of Observations Used For ADF Regression and Critical Values Calculation :\", dftest[3])\n",
    "print(\"5. Critical Values :\")\n",
    "for key, val in dftest[4].items():\n",
    "    print(\"\\t\",key, \": \", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Use a rolling mean to smooth out the data and make it stationary\n",
    "rolling_mean = features['wait_assessment'].rolling(window = 12).mean()\n",
    "\n",
    "# Create a column named rolling_mean in the features dataframe which is the rolling mean of the wait_assessment column with a window of 12 months minus the rolling mean of the wait_assessment column with a window of 12 months shifted by 1 month\n",
    "features['rolling_mean_diff'] = rolling_mean - rolling_mean.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['wait_assessment'].plot(title='Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['rolling_mean_diff'].plot(title='Post Rolling Mean & Differencing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the features dataframe\n",
    "features.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wait_assessment                                   0\n",
       "average_percipitation                             0\n",
       "avg_temp                                          0\n",
       "vehicle_count_automated_traffic_volume_counts     0\n",
       "rolling_mean_diff                                12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for Null values in the features dataframe\n",
    "features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Use interpolation to fill in the Null values in the features dataframe\n",
    "features = features.interpolate(method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2015-01-31', '2015-02-28', '2015-03-31', '2015-04-30',\n",
       "               '2015-05-31', '2015-06-30', '2015-07-31', '2015-08-31',\n",
       "               '2015-09-30', '2015-10-31', '2015-11-30', '2015-12-31'],\n",
       "              dtype='datetime64[ns]', freq='M')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the index for the rows of rolling_mean_diff where the value is null\n",
    "features[features['rolling_mean_diff'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Fill in the Null values in the rolling_mean_diff column With the mean of the rolling_mean_diff column\n",
    "features['rolling_mean_diff'] = features['rolling_mean_diff'].fillna(features['rolling_mean_diff'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = adfuller(features.rolling_mean_diff, autolag = 'AIC')\n",
    "print(\"1. ADF : \",dftest[0])\n",
    "print(\"2. P-Value : \", dftest[1])\n",
    "print(\"3. Num Of Lags : \", dftest[2])\n",
    "print(\"4. Num Of Observations Used For ADF Regression and Critical Values Calculation :\", dftest[3])\n",
    "print(\"5. Critical Values :\")\n",
    "for key, val in dftest[4].items():\n",
    "    print(\"\\t\",key, \": \", val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Sarimax model to predict the delays\n",
    "\n",
    "Use the weather and traffic data as exogenous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:      rolling_mean_diff   No. Observations:                   86\n",
      "Model:               SARIMAX(1, 0, 0)   Log Likelihood                 410.589\n",
      "Date:                Sun, 18 Feb 2024   AIC                           -809.178\n",
      "Time:                        21:07:02   BIC                           -794.452\n",
      "Sample:                    01-31-2015   HQIC                          -803.251\n",
      "                         - 02-28-2022                                         \n",
      "Covariance Type:                  opg                                         \n",
      "=================================================================================================================\n",
      "                                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "const                                             0.0011      0.001      0.811      0.417      -0.002       0.004\n",
      "average_percipitation                            -0.0089      0.000    -24.553      0.000      -0.010      -0.008\n",
      "avg_temp                                      -3.436e-06   2.77e-05     -0.124      0.901   -5.76e-05    5.08e-05\n",
      "vehicle_count_automated_traffic_volume_counts    3.2e-11   9.05e-11      0.353      0.724   -1.45e-10    2.09e-10\n",
      "ar.L1                                             0.5736    1.1e-05   5.23e+04      0.000       0.574       0.574\n",
      "sigma2                                         4.203e-06   4.23e-07      9.933      0.000    3.37e-06    5.03e-06\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.33   Jarque-Bera (JB):                40.55\n",
      "Prob(Q):                              0.56   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               1.86   Skew:                             0.51\n",
      "Prob(H) (two-sided):                  0.10   Kurtosis:                         6.20\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "[2] Covariance matrix is singular or near-singular, with condition number 4.98e+20. Standard errors may be unstable.\n",
      "Mean Absolute Error: 0.00\n",
      "Root Mean Squared Error: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "# Define the endogenous variable (target)\n",
    "endog = features['rolling_mean_diff']\n",
    "\n",
    "# Define the exogenous variables\n",
    "exog = features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']]\n",
    "\n",
    "# Add a constant to the exogenous variables\n",
    "exog = sm.add_constant(exog)\n",
    "\n",
    "# Perform test/train split\n",
    "train_size = 0.8  \n",
    "endog_train, endog_test, exog_train, exog_test = train_test_split(\n",
    "    endog, exog, train_size=train_size, shuffle=False\n",
    ")\n",
    "\n",
    "# Set the frequency to monthly\n",
    "freq = \"M\"\n",
    "\n",
    "# Create the SARIMAX model for training\n",
    "model = sm.tsa.SARIMAX(endog_train, exog=exog_train, order=(1, 0, 0), seasonal_order=(0, 0, 0, 12), freq=freq)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())\n",
    "\n",
    "# Predict on the test set\n",
    "forecast = results.get_forecast(steps=len(endog_test), exog=exog_test)\n",
    "predicted_values = forecast.predicted_mean\n",
    "\n",
    "# Evaluate the accuracy (you can use any appropriate metric depending on your task)\n",
    "mae = mean_absolute_error(endog_test, predicted_values)\n",
    "rmse = np.sqrt(mean_squared_error(endog_test, predicted_values))\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# Scale the numerical features in the features dataframe using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts', 'wait_assessment', 'rolling_mean_diff']] = scaler.fit_transform(features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts', 'wait_assessment', 'rolling_mean_diff']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:      rolling_mean_diff   No. Observations:                   86\n",
      "Model:               SARIMAX(1, 0, 0)   Log Likelihood                -106.065\n",
      "Date:                Sun, 18 Feb 2024   AIC                            224.130\n",
      "Time:                        21:11:59   BIC                            238.856\n",
      "Sample:                    01-31-2015   HQIC                           230.056\n",
      "                         - 02-28-2022                                         \n",
      "Covariance Type:                  opg                                         \n",
      "=================================================================================================================\n",
      "                                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "const                                            -0.0338      0.254     -0.133      0.894      -0.531       0.464\n",
      "average_percipitation                            -0.1484      0.131     -1.134      0.257      -0.405       0.108\n",
      "avg_temp                                          0.0245      0.193      0.127      0.899      -0.354       0.403\n",
      "vehicle_count_automated_traffic_volume_counts     0.0298      0.159      0.187      0.852      -0.283       0.342\n",
      "ar.L1                                             0.5884      0.058     10.213      0.000       0.475       0.701\n",
      "sigma2                                            0.6865      0.070      9.830      0.000       0.550       0.823\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.37   Jarque-Bera (JB):                51.53\n",
      "Prob(Q):                              0.54   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               2.04   Skew:                             0.51\n",
      "Prob(H) (two-sided):                  0.06   Kurtosis:                         6.65\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "Mean Absolute Error: 0.59\n",
      "Root Mean Squared Error: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Define the endogenous variable (target)\n",
    "endog = features['rolling_mean_diff']\n",
    "\n",
    "# Define the exogenous variables\n",
    "exog = features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']]\n",
    "\n",
    "# Add a constant to the exogenous variables\n",
    "exog = sm.add_constant(exog)\n",
    "\n",
    "# Perform test/train split\n",
    "train_size = 0.8  # You can adjust this ratio as needed\n",
    "endog_train, endog_test, exog_train, exog_test = train_test_split(\n",
    "    endog, exog, train_size=train_size, shuffle=False\n",
    ")\n",
    "\n",
    "# Set the frequency to monthly\n",
    "freq = \"M\"\n",
    "\n",
    "# Create the SARIMAX model for training\n",
    "model = sm.tsa.SARIMAX(endog_train, exog=exog_train, order=(1, 0, 0), seasonal_order=(0, 0, 0, 0), freq=freq)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())\n",
    "\n",
    "# Predict on the test set\n",
    "forecast = results.get_forecast(steps=len(endog_test), exog=exog_test)\n",
    "predicted_values = forecast.predicted_mean\n",
    "\n",
    "# Evaluate the accuracy (you can use any appropriate metric depending on your task)\n",
    "mae = mean_absolute_error(endog_test, predicted_values)\n",
    "rmse = np.sqrt(mean_squared_error(endog_test, predicted_values))\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the endogenous variable (target)\n",
    "endog = features['rolling_mean_diff']\n",
    "\n",
    "# Define the exogenous variables\n",
    "exog = features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']]\n",
    "\n",
    "# Add a constant to the exogenous variables\n",
    "exog = sm.add_constant(exog)\n",
    "\n",
    "# Perform test/train split\n",
    "train_size = 0.8\n",
    "endog_train, endog_test, exog_train, exog_test = train_test_split(\n",
    "    endog, exog, train_size=train_size, shuffle=False\n",
    ")\n",
    "\n",
    "# Define the range of parameters to search\n",
    "p_values = range(0, 3)  # Replace with your desired range\n",
    "d_values = range(0, 2)  # Replace with your desired range\n",
    "q_values = range(0, 3)  # Replace with your desired range\n",
    "P_values = range(0, 2)  # Replace with your desired range\n",
    "D_values = range(0, 2)  # Replace with your desired range\n",
    "Q_values = range(0, 2)  # Replace with your desired range\n",
    "\n",
    "# Create a list of all possible parameter combinations\n",
    "param_combinations = list(itertools.product(p_values, d_values, q_values, P_values, D_values, Q_values))\n",
    "\n",
    "best_mae = float('inf')\n",
    "best_params = None\n",
    "\n",
    "# Perform grid search\n",
    "for params in param_combinations:\n",
    "    order = (params[0], params[1], params[2])\n",
    "    seasonal_order = (params[3], params[4], params[5], 12)\n",
    "    \n",
    "    # Specify the frequency of the time series\n",
    "    freq = 'M'\n",
    "    \n",
    "    # Create a datetime index with the specified frequency\n",
    "    date_index = pd.date_range(start=features.index.min(), end=features.index.max(), freq=freq)\n",
    "    \n",
    "    # Reindex the endogenous and exogenous variables\n",
    "    #endog = endog.reindex(date_index)\n",
    "    exog = exog.reindex(date_index)\n",
    "\n",
    "    # Create the SARIMAX model for training\n",
    "    model = sm.tsa.SARIMAX(endog_train, exog=exog_train, order=order, seasonal_order=seasonal_order, freq=freq)\n",
    "\n",
    "    # Fit the model\n",
    "    results = model.fit(maxiter=5000, disp=True)\n",
    "\n",
    "    # Predict on the test set\n",
    "    forecast = results.get_forecast(steps=len(endog_test), exog=exog_test)\n",
    "    predicted_values = forecast.predicted_mean\n",
    "\n",
    "    # Evaluate the accuracy using Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(endog_test, predicted_values)\n",
    "\n",
    "    # Check if the current combination has a lower MAE\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_params = params\n",
    "\n",
    "# Print the best parameters and corresponding MAE\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Mean Absolute Error: {best_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      SARIMAX Results                                       \n",
      "============================================================================================\n",
      "Dep. Variable:                    rolling_mean_diff   No. Observations:                   86\n",
      "Model:             SARIMAX(1, 0, 0)x(0, 0, [1], 12)   Log Likelihood                 -95.752\n",
      "Date:                              Sun, 18 Feb 2024   AIC                            205.504\n",
      "Time:                                      21:14:56   BIC                            222.684\n",
      "Sample:                                  01-31-2015   HQIC                           212.418\n",
      "                                       - 02-28-2022                                         \n",
      "Covariance Type:                                opg                                         \n",
      "=================================================================================================================\n",
      "                                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "const                                             0.0337      0.109      0.309      0.758      -0.181       0.248\n",
      "average_percipitation                            -0.0822      0.105     -0.781      0.435      -0.289       0.124\n",
      "avg_temp                                         -0.0721      0.080     -0.905      0.365      -0.228       0.084\n",
      "vehicle_count_automated_traffic_volume_counts  8.277e-05      0.082      0.001      0.999      -0.160       0.160\n",
      "ar.L1                                             0.6280      0.061     10.233      0.000       0.508       0.748\n",
      "ma.S.L12                                         -0.6143      0.130     -4.742      0.000      -0.868      -0.360\n",
      "sigma2                                            0.5051      0.063      8.075      0.000       0.383       0.628\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.49   Jarque-Bera (JB):                62.69\n",
      "Prob(Q):                              0.48   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               1.88   Skew:                             0.42\n",
      "Prob(H) (two-sided):                  0.09   Kurtosis:                         7.10\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "Mean Absolute Error: 0.34\n",
      "Root Mean Squared Error: 0.41\n"
     ]
    }
   ],
   "source": [
    "# Define the endogenous variable (target)\n",
    "endog = features['rolling_mean_diff']\n",
    "\n",
    "# Define the exogenous variables\n",
    "exog = features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']]\n",
    "\n",
    "# Add a constant to the exogenous variables\n",
    "exog = sm.add_constant(exog)\n",
    "\n",
    "# Perform test/train split\n",
    "train_size = 0.8  # You can adjust this ratio as needed\n",
    "endog_train, endog_test, exog_train, exog_test = train_test_split(\n",
    "    endog, exog, train_size=train_size, shuffle=False\n",
    ")\n",
    "\n",
    "# Set the frequency of the time series to monthly\n",
    "freq = 'M'\n",
    "\n",
    "# Create the SARIMAX model for training\n",
    "model = sm.tsa.SARIMAX(endog_train, exog=exog_train, order=(1, 0, 0), seasonal_order=(0, 0, 1, 12), freq=freq)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())\n",
    "\n",
    "# Predict on the test set\n",
    "forecast = results.get_forecast(steps=len(endog_test), exog=exog_test)\n",
    "predicted_values = forecast.predicted_mean\n",
    "\n",
    "# Evaluate the accuracy (you can use any appropriate metric depending on your task)\n",
    "mae = mean_absolute_error(endog_test, predicted_values)\n",
    "rmse = np.sqrt(mean_squared_error(endog_test, predicted_values))\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model on the entire dataset to be used in the hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      SARIMAX Results                                       \n",
      "============================================================================================\n",
      "Dep. Variable:                      wait_assessment   No. Observations:                  108\n",
      "Model:             SARIMAX(0, 1, 0)x(0, 1, [1], 12)   Log Likelihood                -115.582\n",
      "Date:                              Mon, 19 Feb 2024   AIC                            243.164\n",
      "Time:                                      19:59:14   BIC                            258.488\n",
      "Sample:                                  01-31-2015   HQIC                           249.356\n",
      "                                       - 12-31-2023                                         \n",
      "Covariance Type:                                opg                                         \n",
      "=================================================================================================================\n",
      "                                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "const                                          2.297e-06   1.27e-08    180.645      0.000    2.27e-06    2.32e-06\n",
      "average_percipitation                            -0.0710      0.071     -0.995      0.320      -0.211       0.069\n",
      "avg_temp                                          0.8922      0.241      3.708      0.000       0.421       1.364\n",
      "vehicle_count_automated_traffic_volume_counts     0.0196      0.119      0.165      0.869      -0.214       0.253\n",
      "ma.S.L12                                         -0.9923      4.290     -0.231      0.817      -9.400       7.415\n",
      "sigma2                                            0.5101      2.171      0.235      0.814      -3.745       4.765\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                  16.14   Jarque-Bera (JB):                18.83\n",
      "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.75   Skew:                             0.33\n",
      "Prob(H) (two-sided):                  0.42   Kurtosis:                         5.08\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "[2] Covariance matrix is singular or near-singular, with condition number 3.11e+24. Standard errors may be unstable.\n"
     ]
    }
   ],
   "source": [
    "# Create a full model for training the hybrid model\n",
    "\n",
    "# Define the endogenous variable (target)\n",
    "endog1 = features['wait_assessment']\n",
    "\n",
    "# Define the exogenous variables\n",
    "exog1 = features[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']]\n",
    "\n",
    "# Add a constant to the exogenous variables\n",
    "exog1 = sm.add_constant(exog1)\n",
    "\n",
    "# Set the frequency of the time series to monthly\n",
    "freq = 'M'\n",
    "\n",
    "# Create the SARIMAX model for training\n",
    "model1 = sm.tsa.SARIMAX(endog1, exog=exog1, order=(0, 1, 0), seasonal_order=(0, 1, 1, 12), freq=freq)\n",
    "\n",
    "# Fit the model\n",
    "results1 = model1.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the endog_train, endog_test, exog_train, exog_test dataframe shapes\n",
    "print(endog_train.shape)\n",
    "print(endog_test.shape)\n",
    "print(exog_train.shape)\n",
    "print(exog_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Actual vs Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual values from the training set\n",
    "plt.plot(endog_train.index, endog_train, label='Actual (Training Set)', color='blue')\n",
    "\n",
    "# Plot the actual values from the test set\n",
    "plt.plot(endog_test.index, endog_test, label='Actual (Test Set)', color='blue', linestyle='--')\n",
    "\n",
    "# Plot the predicted values from the test set\n",
    "plt.plot(endog_test.index, predicted_values, label='Predicted (Test Set)', color='orange')\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Wait Assessment')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data for the Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data for the model, combining the delays, weather and traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Join the delays2 and features dataframes together\n",
    "features2 = pd.merge(delays2, traffic_features, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "features2 = pd.merge(features2, weather_features, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the data with a categorical variable showing the traffic and weather performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vehicle_count_automated_traffic_volume_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the wait_assessment column\n",
    "features2['vehicle_count_automated_traffic_volume_counts'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4614574.7 , 9317653.38])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Percentile Thresholds\n",
    "from numpy import array\n",
    "rating_pctile = np.percentile(features2['vehicle_count_automated_traffic_volume_counts'], [75, 90])\n",
    "# The percentile thresholds are\n",
    "rating_pctile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named w_rating in the features2 dataframe \n",
    "features2['vc_rating'] = 0\n",
    "features2['vc_rating'] = np.where(features2['vehicle_count_automated_traffic_volume_counts'] < rating_pctile[0], 1, features2['vc_rating'])\n",
    "features2['vc_rating'] = np.where((features2['vehicle_count_automated_traffic_volume_counts'] >= rating_pctile[0]) & (features2['vehicle_count_automated_traffic_volume_counts'] <= rating_pctile[1]), 2, features2['vc_rating'])\n",
    "features2['vc_rating'] = np.where(features2['vehicle_count_automated_traffic_volume_counts'] > rating_pctile[1], 3, features2['vc_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a histogram of the w_rating column\n",
    "features2['vc_rating'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average_percipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the wait_assessment column\n",
    "features2['average_percipitation'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17, 0.22])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Percentile Thresholds\n",
    "from numpy import array\n",
    "rating_pctile = np.percentile(features2['average_percipitation'], [75, 90])\n",
    "# The percentile thresholds are\n",
    "rating_pctile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named w_rating in the features2 dataframe \n",
    "features2['ap_rating'] = 0\n",
    "features2['ap_rating'] = np.where(features2['average_percipitation'] < rating_pctile[0], 1, features2['ap_rating'])\n",
    "features2['ap_rating'] = np.where((features2['average_percipitation'] >= rating_pctile[0]) & (features2['average_percipitation'] <= rating_pctile[1]), 2, features2['ap_rating'])\n",
    "features2['ap_rating'] = np.where(features2['average_percipitation'] > rating_pctile[1], 3, features2['ap_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a histogram of the w_rating column\n",
    "features2['ap_rating'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avg_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the wait_assessment column\n",
    "features2['avg_temp'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71.25, 77.53])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Percentile Thresholds\n",
    "from numpy import array\n",
    "rating_pctile = np.percentile(features2['avg_temp'], [75, 90])\n",
    "# The percentile thresholds are\n",
    "rating_pctile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named w_rating in the features2 dataframe \n",
    "features2['at_rating'] = 0\n",
    "features2['at_rating'] = np.where(features2['avg_temp'] < rating_pctile[0], 1, features2['at_rating'])\n",
    "features2['at_rating'] = np.where((features2['avg_temp'] >= rating_pctile[0]) & (features2['avg_temp'] <= rating_pctile[1]), 2, features2['at_rating'])\n",
    "features2['at_rating'] = np.where(features2['avg_temp'] > rating_pctile[1], 3, features2['at_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a histogram of the w_rating column\n",
    "features2['at_rating'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the data with time based variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datepart(df, fldname, drop=True):\n",
    "    fld = df[fldname]\n",
    "    if not np.issubdtype(fld.dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, \n",
    "                                     infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    for n in ('Year', 'Month', 'Week', 'Day', 'Dayofweek', \n",
    "            'Dayofyear', 'Is_month_end', 'Is_month_start', \n",
    "            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', \n",
    "            'Is_year_start'):\n",
    "        df[targ_pre+n] = getattr(fld.dt,n.lower())        \n",
    "    df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to a date data type\n",
    "features2[\"date\"] = pd.to_datetime(features2[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_10744\\2443702962.py:11: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  df[targ_pre+n] = getattr(fld.dt,n.lower())\n"
     ]
    }
   ],
   "source": [
    "add_datepart(features2, 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that are not needed: Week, Day, Dayofweek, Dayofyear, Is_month_end, Is_month_start, Is_quarter_end, Is_year_end\n",
    "features2 = features2.drop(columns=[\"Week\", \"Day\", \"Dayofweek\", \"Dayofyear\", \"Is_month_end\", \"Is_month_start\", \"Is_quarter_end\", \"Is_year_end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the is quarter start and is year start columns to int\n",
    "features2[\"Is_quarter_start\"] = features2[\"Is_quarter_start\"].astype(int)\n",
    "features2[\"Is_year_start\"] = features2[\"Is_year_start\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wait_assessment</th>\n",
       "      <th>vehicle_count_automated_traffic_volume_counts</th>\n",
       "      <th>average_percipitation</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>vc_rating</th>\n",
       "      <th>ap_rating</th>\n",
       "      <th>at_rating</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Is_quarter_start</th>\n",
       "      <th>Is_year_start</th>\n",
       "      <th>Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.00000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>1.080000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.788890</td>\n",
       "      <td>3.479085e+06</td>\n",
       "      <td>0.139259</td>\n",
       "      <td>56.667593</td>\n",
       "      <td>1.351852</td>\n",
       "      <td>1.37037</td>\n",
       "      <td>1.351852</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.560712e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.025109</td>\n",
       "      <td>4.168301e+06</td>\n",
       "      <td>0.073468</td>\n",
       "      <td>15.485536</td>\n",
       "      <td>0.660145</td>\n",
       "      <td>0.64984</td>\n",
       "      <td>0.660145</td>\n",
       "      <td>2.594026</td>\n",
       "      <td>3.468146</td>\n",
       "      <td>0.473602</td>\n",
       "      <td>0.277674</td>\n",
       "      <td>8.236522e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.716483</td>\n",
       "      <td>4.020500e+04</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.420070e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.776817</td>\n",
       "      <td>4.442467e+05</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>43.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.490335e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.790146</td>\n",
       "      <td>2.337810e+06</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>57.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.560643e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.807209</td>\n",
       "      <td>4.614575e+06</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>71.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.631102e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.845291</td>\n",
       "      <td>1.968032e+07</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.701389e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wait_assessment  vehicle_count_automated_traffic_volume_counts  \\\n",
       "count       108.000000                                   1.080000e+02   \n",
       "mean          0.788890                                   3.479085e+06   \n",
       "std           0.025109                                   4.168301e+06   \n",
       "min           0.716483                                   4.020500e+04   \n",
       "25%           0.776817                                   4.442467e+05   \n",
       "50%           0.790146                                   2.337810e+06   \n",
       "75%           0.807209                                   4.614575e+06   \n",
       "max           0.845291                                   1.968032e+07   \n",
       "\n",
       "       average_percipitation    avg_temp   vc_rating  ap_rating   at_rating  \\\n",
       "count             108.000000  108.000000  108.000000  108.00000  108.000000   \n",
       "mean                0.139259   56.667593    1.351852    1.37037    1.351852   \n",
       "std                 0.073468   15.485536    0.660145    0.64984    0.660145   \n",
       "min                 0.030000   23.900000    1.000000    1.00000    1.000000   \n",
       "25%                 0.090000   43.125000    1.000000    1.00000    1.000000   \n",
       "50%                 0.130000   57.400000    1.000000    1.00000    1.000000   \n",
       "75%                 0.170000   71.250000    1.250000    2.00000    1.250000   \n",
       "max                 0.480000   80.000000    3.000000    3.00000    3.000000   \n",
       "\n",
       "              Year       Month  Is_quarter_start  Is_year_start       Elapsed  \n",
       "count   108.000000  108.000000        108.000000     108.000000  1.080000e+02  \n",
       "mean   2019.000000    6.500000          0.333333       0.083333  1.560712e+09  \n",
       "std       2.594026    3.468146          0.473602       0.277674  8.236522e+07  \n",
       "min    2015.000000    1.000000          0.000000       0.000000  1.420070e+09  \n",
       "25%    2017.000000    3.750000          0.000000       0.000000  1.490335e+09  \n",
       "50%    2019.000000    6.500000          0.000000       0.000000  1.560643e+09  \n",
       "75%    2021.000000    9.250000          1.000000       0.000000  1.631102e+09  \n",
       "max    2023.000000   12.000000          1.000000       1.000000  1.701389e+09  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features2.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sliding window to shift the data and create samples for a supervised learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "features3 = features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns except for wait_assessment\n",
    "features4 = features3.drop(columns=[\"average_percipitation\", \"avg_temp\", \"vehicle_count_automated_traffic_volume_counts\", \"vc_rating\", \"ap_rating\", \"at_rating\", \"Year\", \"Month\", \"Elapsed\", \"Is_quarter_start\", \"Is_year_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wait_assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.788890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.025109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.716483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.776817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.790146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.807209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.845291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wait_assessment\n",
       "count       108.000000\n",
       "mean          0.788890\n",
       "std           0.025109\n",
       "min           0.716483\n",
       "25%           0.776817\n",
       "50%           0.790146\n",
       "75%           0.807209\n",
       "max           0.845291"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features4.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the values from features4 into an array\n",
    "features_array = features4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">expected=0.8060, predicted=0.7646\n",
      ">expected=0.8057, predicted=0.7884\n",
      ">expected=0.7901, predicted=0.7871\n",
      ">expected=0.7873, predicted=0.7868\n",
      ">expected=0.7581, predicted=0.7933\n",
      ">expected=0.7547, predicted=0.7680\n",
      ">expected=0.7638, predicted=0.7620\n",
      ">expected=0.7707, predicted=0.7754\n",
      ">expected=0.7480, predicted=0.7708\n",
      ">expected=0.7522, predicted=0.7621\n",
      ">expected=0.7582, predicted=0.7607\n",
      ">expected=0.7455, predicted=0.7625\n",
      "MAE: 0.014\n",
      "RMSE: 0.017\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB15klEQVR4nO3deVhUZfvA8e/MAMMOIrIJIu4LrrjvK2q2WL1mm2ZpZdmbZvUr0956bfFtMy3T0lza07I9tdByX8Eld0RRUEFElH2dOb8/DqCoKODAmRnuz3XNxXA4c+aesZib57mf+9EpiqIghBBCCGHF9FoHIIQQQghxI5KwCCGEEMLqScIihBBCCKsnCYsQQgghrJ4kLEIIIYSwepKwCCGEEMLqScIihBBCCKsnCYsQQgghrJ6D1gFYitls5syZM3h4eKDT6bQORwghhBAVoCgKmZmZBAUFodeXP45iNwnLmTNnCAkJ0ToMIYQQQlRBYmIiwcHB5f7cbhIWDw8PQH3Bnp6eGkcjhBBCiIrIyMggJCSk9HO8PHaTsJRMA3l6ekrCIoQQQtiYG5VzSNGtEEIIIayeJCxCCCGEsHqSsAghhBDC6tlNDYsQQgj7oygKRUVFmEwmrUMRVWQwGHBwcLjpliOSsAghhLBKBQUFJCUlkZOTo3Uo4ia5uroSGBiIk5NTla8hCYsQQgirYzabiY+Px2AwEBQUhJOTkzQFtUGKolBQUMC5c+eIj4+nadOm120Odz2SsAghhLA6BQUFmM1mQkJCcHV11ToccRNcXFxwdHTk5MmTFBQU4OzsXKXrSNGtEEIIq1XVv8aFdbHEv6P8lyCEEEIIqycJixBCCCGsniQsQgghhKiyfv36MXny5Gp/HklYhBBCCAsaO3YsOp3uqtvQoUO1Dq1UTSUZliSrhG7g043HOX0xF2dHA84OBpwd9er94q/GMseK7zsYrjhHL8vxhBCiFhk6dChLliwpc8xoNGoUjX2QhOUGft+XxO6Eizd9HaND2USnJPkxliQ6V/68+JjxOomQs6O+OGEyUM/diJer482/YCGEsFKKopBbqE3HWxdHQ6X+8DQajQQEBFx1fN26dURGRrJ27Vp69+4NwHvvvcfMmTPZt28fgYGB9OvXj/DwcAC+/PJLDAYDTzzxBK+99lppDAUFBUyfPp2vvvqKixcvEh4ezltvvUW/fv1Kn2vz5s289NJL7Ny5E6PRSJcuXfj222955plnWL9+PevXr2fOnDkAxMfH07BhQw4ePMhzzz3Hhg0bcHNzIzIykvfffx9fX18AsrOzeeKJJ/jhhx/w8PDgueeeq9L7WRWSsNzAyIgQujWqS16hibxCM/mFJvKK1PvqseL7RSbyLz9WZMZkVkqvk19kJr/ITHpu9cTpZNDzw5M9CK/vVT1PIIQQGsstNNHqP39o8twHZwzB1enmPzJLpmJGjx7N3r17OXHiBNOmTeObb74hMDCw9LzPPvuMcePGsX37dqKjo3nssccIDQ3l0UcfBeDhhx/mxIkTfPvttwQFBfHjjz8ydOhQ9u3bR9OmTdmzZw8DBw7kkUce4YMPPsDBwYG///4bk8nEnDlziI2NJTw8nBkzZgBQr149kpKS6Nu3L48++iizZs0iNzeXF154gXvuuYe//voLgOeff56///6bH3/8kYCAAF566SViYmJo3779Tb83NyIJyw3c37VBlR9baDJfSmgKTeQXlXy9POEp/nrZsfzihKdMQnTZsfzLkqS8QhOZeUXkFJiYs/YoC8d0suCrF0IIURW//fYb7u7uZY698MILvPzyy7z++uusWbOGxx57jAMHDjB69GjuvPPOMueGhITw/vvvo9PpaN68Ofv27eP999/n0Ucf5dixY3zzzTecOnWKoKAgAJ577jlWr17NkiVLePPNN3n77bfp1KkT8+bNK71m69atS+87OTnh6upaZhRo/vz5dOzYkTfffLP02OLFiwkJCSE2NpagoCAWLVrE559/zuDBgwE1sQoODrbcG3cdkrBUI0eDHkeDHo+qNfWrsGPnshg0az1RB88SezaTZv4e1fuEQgihARdHAwdnDNHsuSujf//+zJ8/v8wxHx8fQE0WvvzyS9q2bUtoaCizZ8++6vHdunUrMwXVvXt33nvvPUwmE7t27UJRFJo1a1bmMfn5+dStWxeAPXv2MHLkyErFHBMTw99//31VogVw7NgxcnNzKSgooHv37mVeU/PmzSv1PFUlCYsdaFzPnaGtA1i1P5mP1x1j1qj2WockhBAWp9PpLDItUxPc3Nxo0qRJuT/fsmULAGlpaaSlpeHm5lbha5vNZgwGAzExMRgMZROpkmTDxcWl0jGbzWZuu+023nrrrat+FhgYyNGjRyt9TUuSZc124sl+6v8YP+89Q2Ka7GwqhBDW6tixYzzzzDMsXLiQbt26MWbMGMxmc5lztm3bdtX3TZs2xWAw0KFDB0wmEykpKTRp0qTMrWSKp23btqxdu7bcGJycnDCZyhYwd+zYkQMHDtCwYcOrrluSgDk6OpaJ7cKFC8TGxt7sW1IhkrDYiTbBXvRu6ovJrLBw43GtwxFCiFotPz+f5OTkMrfU1FRMJhOjR48mMjKShx9+mCVLlrB//37ee++9Mo9PTExkypQpHDlyhG+++YYPP/yQSZMmAdCsWTMeeOABxowZww8//EB8fDw7d+7krbfeYuXKlQBMnTqVnTt38uSTT/LPP/9w+PBh5s+fT2pqKgANGzZk+/btnDhxgtTUVMxmMxMnTiQtLY377ruPHTt2cPz4cf78808eeeQRTCYT7u7ujBs3jueff561a9eyf/9+xo4dW2P7PUnCYkee6NcYgGU7EzmXma9xNEIIUXutXr2awMDAMrdevXrxxhtvcOLECRYsWABAQEAAn376KdOnT2fPnj2ljx8zZgy5ubl06dKFiRMn8u9//5vHHnus9OdLlixhzJgxPPvsszRv3pzbb7+d7du3ExISAqhJzZ9//snevXvp0qUL3bt35+eff8bBQZ1Se+655zAYDLRq1Yp69eqRkJBAUFAQmzdvxmQyMWTIEMLDw5k0aRJeXl6lSck777xDnz59uP322xk0aBC9evUiIiKiRt5TnaIoyo1Ps34ZGRl4eXmRnp6Op6en1uFoQlEU7py3hT2JF3myX2P+b2gLrUMSQogqycvLIz4+nrCwMJydq3nlgpXp168f7du3v2Yxrq263r9nRT+/ZYTFjuh0Op4sHmX5YutJMvIKNY5ICCGEsAxJWOzMoJb+NPVzJzO/iC+3ndQ6HCGEEMIiJGGxM3q9rrSWZfGmePI0amMthBCiatatW2dX00GWIgmLHbqtXRD1vV1IzSrgu+hErcMRQgghbpokLHbI0aDn8b6NAPhkw3GKTOYbPEIIIYSwbpKw2Kl7OoXg6+7EqQu5/PrPGa3DEUIIIW6KJCx2ytnRwMM9wwCYv+4YZrNdrF4XQghRS0nCYsdGdw/Fw+hA7Nks1h5O0TocIYQQosokYbFjns6OPNg9FIB56+Kwkx6BQgghgFdffZX27duXfj927FhGjBhR43GcOHECnU5XplNvdZCExc490jMMo4Oe3QkX2XY8TetwhBDC7o0dOxadTodOp8PR0ZFGjRrx3HPPkZ2dXa3PO2fOHJYuXVqhc2sqybAkSVjsXD0PI/d0UveWmLcuTuNohBCidhg6dChJSUkcP36c119/nXnz5vHcc89ddV5hoeU6knt5eeHt7W2x61kbSVhqgcf6NMKg17HxaCr7TqVrHY4QQtg9o9FIQEAAISEh3H///TzwwAP89NNPpdM4ixcvplGjRhiNRhRFIT09ncceeww/Pz88PT0ZMGAAe/fuLXPN//3vf/j7++Ph4cG4cePIy8sr8/Mrp4TMZjNvvfUWTZo0wWg00qBBA9544w0AwsLURRkdOnRAp9PRr1+/0sctWbKEli1b4uzsTIsWLZg3b16Z59mxYwcdOnTA2dmZTp06sXv3bgu+c+VzqJFnEZoK8XHl9nZB/Lj7NPPXxzHvgZrZWVMIISxKUaAwR5vndnQFna7KD3dxcSkdTYmLi2P58uWsWLECg8EAwPDhw/Hx8WHlypV4eXnxySefMHDgQGJjY/Hx8WH58uW88sorfPTRR/Tu3ZsvvviCDz74gEaNGpX7nFOnTmXhwoW8//779OrVi6SkJA4fPgyoSUeXLl1Ys2YNrVu3xsnJCYCFCxfyyiuvMHfuXDp06MDu3bt59NFHcXNz46GHHiI7O5tbb72VAQMG8OWXXxIfH8+kSZOq/L5UhiQstcQT/Rrz4+7TrNqfzLFzWTSu5651SEIIUTmFOfBmkDbP/dIZcHKr0kN37NjB119/zcCBAwEoKCjgiy++oF69egD89ddf7Nu3j5SUFIxGIwDvvvsuP/30E99//z2PPfYYs2fP5pFHHmH8+PEAvP7666xZs+aqUZYSmZmZzJkzh7lz5/LQQw8B0LhxY3r16gVQ+tx169YlICCg9HGvvfYa7733HnfddRegjsQcPHiQTz75hIceeoivvvoKk8nE4sWLcXV1pXXr1pw6dYonnniiSu9NZciUUC3RzN+DQS39URT4ZP0xrcMRQgi79ttvv+Hu7o6zszPdu3enT58+fPjhhwCEhoaWJgwAMTExZGVlUbduXdzd3Utv8fHxHDum/r4+dOgQ3bt3L/McV35/uUOHDpGfn1+aJFXEuXPnSExMZNy4cWXieP3118vE0a5dO1xdXSsUhyXJCEst8mT/xqw5dJYfd5/mmcHNCPRy0TokIYSoOEdXdaRDq+euhP79+zN//nwcHR0JCgrC0dGx9GdubmVHasxmM4GBgaxbt+6q61S1iNbFpfK/381mdRuXhQsX0rVr1zI/K5m60rI9hiQstUjHBnXo1siHbcfTWLghnv/c1krrkIQQouJ0uipPy9Q0Nzc3mjRpUqFzO3bsSHJyMg4ODjRs2PCa57Rs2ZJt27YxZsyY0mPbtm0r95pNmzbFxcWFtWvXlk4jXa6kZsVkMpUe8/f3p379+hw/fpwHHnjgmtdt1aoVX3zxBbm5uaVJ0fXisCSZEqplnuyn/g/0zY4E0rILNI5GCCHEoEGD6N69OyNGjOCPP/7gxIkTbNmyhenTpxMdHQ3ApEmTWLx4MYsXLyY2NpZXXnmFAwcOlHtNZ2dnXnjhBf7v//6Pzz//nGPHjrFt2zYWLVoEgJ+fHy4uLqxevZqzZ8+Snq6uIH311VeZOXMmc+bMITY2ln379rFkyRJmzZoFwP33349er2fcuHEcPHiQlStX8u6771bzO6SShKWW6d3Ul/D6nuQWmli65YTW4QghRK2n0+lYuXIlffr04ZFHHqFZs2bce++9nDhxAn9/fwBGjRrFf/7zH1544QUiIiI4efLkDQtdX375ZZ599ln+85//0LJlS0aNGkVKirpNi4ODAx988AGffPIJQUFB3HHHHQCMHz+eTz/9lKVLl9KmTRv69u3L0qVLS5dBu7u78+uvv3Lw4EE6dOjAtGnTeOutt6rx3blEp9hJv/aMjAy8vLxIT0/H09NT63Cs2sp9STz51S68XBzZ/OIA3I0yMyiEsC55eXnEx8cTFhaGs7Oz1uGIm3S9f8+Kfn5XaYRl3rx5pU8aERHBxo0br3v+V199VVpVHBgYyMMPP8z58+fLnLNixQpatWqF0WikVatW/Pjjj1UJTVTAkNYBNPJ1Iz23kG+2J2gdjhBCCHFDlU5Yli1bxuTJk5k2bRq7d++md+/eDBs2jISEa3/wbdq0iTFjxjBu3DgOHDjAd999x86dO8sUAW3dupVRo0YxevRo9u7dy+jRo7nnnnvYvn171V+ZKJdBr2NC38YAfLrpOPlFphs8QgghhNBWpROWWbNmMW7cOMaPH0/Lli2ZPXs2ISEhzJ8//5rnb9u2jYYNG/L0008TFhZGr169ePzxx0sLiQBmz57N4MGDmTp1Ki1atGDq1KkMHDiQ2bNnV/mFiesb0aE+gV7OnM3I54ddp7UORwghhLiuSiUsBQUFxMTEEBkZWeZ4ZGQkW7ZsueZjevTowalTp1i5ciWKonD27Fm+//57hg8fXnrO1q1br7rmkCFDyr2muHlODnrG91ZbOn+y/hgms12UMgkhhLBTlUpYUlNTMZlMpVXLJfz9/UlOTr7mY3r06MFXX33FqFGjcHJyIiAgAG9v79KOfwDJycmVuiZAfn4+GRkZZW6icu7rEkIdV0dOnM9h5b4krcMRQgghylWlolvdFRtAKYpy1bESBw8e5Omnn+Y///kPMTExrF69mvj4eCZMmFDlawLMnDkTLy+v0ltISEhVXkqt5urkwNge6lK1eeuOadrBUAghrkV+L9kHS/w7Viph8fX1xWAwXDXykZKSctUISYmZM2fSs2dPnn/+edq2bcuQIUOYN28eixcvJilJ/as+ICCgUtcEdRfK9PT00ltiYmJlXooo9lCPUNycDBxKymBd7DmtwxFCCIDSVvY5ORrtziwsquTf8fItCiqrUg04nJyciIiIICoqijvvvLP0eFRUVGnTmWsF6eBQ9mmu3JOge/fuREVF8cwzz5Se8+eff9KjR49yYzEajaW7Woqq83Z14v6uDVi4MZ75fx+jf3M/rUMSQggMBgPe3t6ljc5cXV2vO+ourJOiKOTk5JCSkoK3t3fp539VVLpj2JQpUxg9ejSdOnWie/fuLFiwgISEhNIpnqlTp3L69Gk+//xzAG677TYeffRR5s+fz5AhQ0hKSmLy5Ml06dKFoCB1m/BJkybRp08f3nrrLe644w5+/vln1qxZw6ZNm6r8wkTFje/diM+2nGTHiTSiT6TRqaGP1iEJIQQBAQEApUmLsF3e3t6l/55VVemEZdSoUZw/f54ZM2aQlJREeHg4K1euJDQ0FICkpKQyPVnGjh1LZmYmc+fO5dlnn8Xb25sBAwaUaeXbo0cPvv32W6ZPn87LL79M48aNWbZs2VW7RYrq4e/pzN0R9flmRyLz1h1j8VhJWIQQ2tPpdAQGBuLn50dhYaHW4YgqcnR0vKmRlRLSml8AcCI1mwHvrcOswKpJvWkZKO+hEEKI6letrfmF/Wno68YtbQIBmL/umMbRCCGEEGVJwiJKPdFPbdf/2z9nOHk+W+NohBBCiEskYRGlWgd50a95PcwKfLLhuNbhCCGEEKUkYRFlPNmvCQDfR58iJSNP42iEEEIIlSQsoowuYT50Cq1DgcnMok3xWocjhBBCAJKwiGt4sr9ay/LltpOk58hSQiGEENqThEVcpX9zP1oEeJBdYOKzrSe0DkcIIYSQhEVcTafTla4YWrI5npyCIo0jEkIIUdtJwiKuaXibQBr4uHIhp5Bvd8jGkkIIIbQlCYu4JgeDnsf7NgJg4cbjFBSZNY5ICCFEbSYJiyjX3R2DqedhJCk9j5/2nNY6HCGEELWYJCyiXM6OBsb3CgPg4/XHMJntYtspIYQQNkgSFnFdD3QLxdPZgePnsvnzQLLW4QghhKilJGER1+VudOChHg0BmLfuGHayubcQQggbIwmLuKGxPRri7Khn3+l0NsWlah2OEEKIWkgSFnFDdd2N3Nu5AQDz/j6mcTRCCCFqI0lYRIU82qcRDnodW4+fZ3fCBa3DEUIIUctIwiIqpL63CyM61AfUWhYhhBCiJknCIipsQt/G6HQQdfAssWcztQ5HCCFELSIJi6iwJn7uDGkVAMDHMsoihBCiBknCIirlyf7qpog/7z1DYlqOxtEIIYSoLSRhEZXSNtibXk18MZkVFm48rnU4QgghaglJWESlPdlPHWVZtjORc5n5GkcjhBCiNpCERVRa98Z1aRfiTX6RmSWb47UORwghRC0gCYuoNJ1OVzrK8sXWk2TkFWockRBCCHsnCYuoksEt/Wnq505mfhFfbjupdThCCCHsnCQsokr0eh0T+qqjLIs3xZNXaNI4IiGEEPZMEhZRZbe3D6K+twupWQV8F52odThCCCHsmCQsosocDXoe69MIgE82HKfIZNY4IiGEEPZKEhZxU+7pFEJdNydOXcjl13/OaB2OEEIIOyUJi7gpLk4GHukVBsD8dccwmxWNI7JjRfnwy9PwUVfIPKt1NEIIUaMkYRE37cFuobgbHYg9m8Xawylah2OfctLgizth12dw7jDsX6F1REIIUaMkYRE3zcvFkQe7hQIwb10ciiKjLBZ14QQsHgInN186dvQPzcIRQggtSMIiLOKRXg1xctCzO+Ei246naR2O/TgdA58OgtRY8KwPIz9Tj5/YDPlZ2sYmhBA1SBIWYRF+Hs7c0ykYUEdZhAUcXglLb4Xsc+DfBsavgVZ3QJ0wMBfC8XVaRyiEEDVGEhZhMY/3aYxBr2Pj0VT2nUrXOhzbtmMhLHsACnOgySB4ZBV4BoFOB82GqOfItJAQohaRhEVYTIiPK7e1DQRg/noZZakSsxn+nA4rnwPFDB3HwH3fgtHj0jlNB6tfj0aB1AsJIWoJSViERT3RrwkAq/Ync+yc1FhUSmEefP8wbPlQ/X7Ay3DbB2BwLHteaC9wdIXMJEjeV/NxCiGEBiRhERbVPMCDQS39UBT4ZP0xrcOxHdnn4fPb4eBPoHeEuxZCn+fUKaArOTpDo37qfZkWEkLUEpKwCIsrGWX5cfdpktJzNY7GBqQdh0WDIXE7OHvB6B+h7T3Xf0zJtFDsn9UfnxBCWAFJWITFRYTWoWuYD4UmhYUb4rUOx7ol7lSXLacdA68G8MifENb7xo9rGql+PbVTHZ0RQgg7JwmLqBZP9ldHWb7ZkUBadoHG0VipQ7/CZ7dCznkIbK8uW/ZrUbHHegWDfzigwLG11RmlEEJYBUlYRLXo09SX1kGe5BaaWLrlhNbhWJ+t82DZaCjKg2ZDYezv4OFfuWuUTgtJHYsQwv5JwiKqhU6n48niWpbPtpwgK79I44ishNkEq16AP6YCCnQaB6O+AqN75a/VtLgfS9wa9bpCCGHHJGER1WZoeACNfN1Izy3km+0JWoejvYIcWD4Gtn+sfj94Bgx/DwwOVbtecGdw9oa8i2otixBC2LEqJSzz5s0jLCwMZ2dnIiIi2LhxY7nnjh07Fp1Od9WtdevWpecUFhYyY8YMGjdujLOzM+3atWP16tVVCU1YEYNex+N9GwHw6abj5BfV4lGArHPw2W1w+DcwGOFfS6DnpGsvW64og4PaBRdkWkgIYfcqnbAsW7aMyZMnM23aNHbv3k3v3r0ZNmwYCQnX/gt6zpw5JCUlld4SExPx8fFh5MiRpedMnz6dTz75hA8//JCDBw8yYcIE7rzzTnbv3l31Vyaswp0dggnwdOZsRj4/7DqtdTjaSD0KiwbB6WhwqQNjfobwuyxz7ZLVQkejLHM9IYSwUjpFqVxv765du9KxY0fmz59feqxly5aMGDGCmTNn3vDxP/30E3fddRfx8fGEhoYCEBQUxLRp05g4cWLpeSNGjMDd3Z0vv/yyQnFlZGTg5eVFeno6np6elXlJopp9uvE4r/9+iNC6rvz+dG/cjVWcArFFJ7fCt/dB7gWo0xAe+B58m1ru+tnn4Z3GgALPHASv+pa7thBC1ICKfn5XaoSloKCAmJgYIiMjyxyPjIxky5YtFbrGokWLGDRoUGmyApCfn4+zs3OZ81xcXNi0aVO518nPzycjI6PMTVin+7o0wNvVkZPnc+jyxhqe/24vO0+kUclc2fbs/wE+v0NNVup3gnFrLJusALjVVWtZAI5KEzkhhP2qVMKSmpqKyWTC37/s8kt/f3+Sk5Nv+PikpCRWrVrF+PHjyxwfMmQIs2bN4ujRo5jNZqKiovj5559JSkoq91ozZ87Ey8ur9BYSElKZlyJqkJvRgTn3dqCRrxs5BSa+iznFyI+3MvC99cxfd4yUzDytQ7QsRYHNc9R9gUz50OJWeOhXcK9XPc9XOi0kCYsQwn5VqehWd0WhoKIoVx27lqVLl+Lt7c2IESPKHJ8zZw5NmzalRYsWODk58dRTT/Hwww9jMBjKvdbUqVNJT08vvSUmJlblpYga0rdZPdY+25fvJ3RnZEQwrk4Gjqdm89bqw3Sf+RfjP4vmzwPJFJrMWod6c0xF8PuzEPUf9fuuE+Cez8HJtfqes1lxwnJ8HRTlV9/zCCGEhipVTODr64vBYLhqNCUlJeWqUZcrKYrC4sWLGT16NE5OTmV+Vq9ePX766Sfy8vI4f/48QUFBvPjii4SFhZV7PaPRiNForEz4QmM6nY5ODX3o1NCHV25vze//nGF59CliTl5gzaGzrDl0Fl93I3d3rM/ITiE08atCbxItFWTD949A7GpAB0PehO5PVv/zBrQF9wDISoYTm6DJwOp/TiGEqGGVGmFxcnIiIiKCqKiyKxKioqLo0aPHdR+7fv164uLiGDduXLnnODs7U79+fYqKilixYgV33HFHZcITNsTd6MCozg1Y8UQP1kzpw2N9GuHr7kRqVj6fbDjOoFnruXv+FpbvTCTbFprOZZ6FJbeoyYqDszqqUhPJCqhLo0u63sq0kBDCTlV6ldCyZcsYPXo0H3/8Md27d2fBggUsXLiQAwcOEBoaytSpUzl9+jSff/55mceNHj2ao0ePsm3btquuuX37dk6fPk379u05ffo0r776KvHx8ezatQtvb+8KxSWrhGxfocnMX4dT+C46kb+PnMNkVv/TdHUycGvbQEZ1DqFjgzoVmn6sUeeOwJf/gvQEcK0L9y2DkM41G8OhX2HZg+DTCJ6WdgBCCNtR0c/vSq8vHTVqFOfPn2fGjBkkJSURHh7OypUrS1f9JCUlXdWTJT09nRUrVjBnzpxrXjMvL4/p06dz/Phx3N3dueWWW/jiiy8qnKwI++Bo0DOkdQBDWgdwNiOPH3adZnl0IvGp2SyPPsXy6FM0rufGPZ1CuKtjMPU8rGBK8MQm+PZ+yEsHn8bwwHdQt3HNx9GoH+gdIe04pMaBb5Oaj0EIIapRpUdYrJWMsNgnRVHYeeICy6MT+f2fJHIL1W65Br2OAS38GNUphH7N6+Fg0GCXiX+Ww09PgrkQQrrCvd+oy4y18tntEL++uHZm4o3PF0IIK1DRz29JWOyF2Qx6+94aKjOvkN//SWJZdCK7Ey6WHq/nYeTujsGM7BRM43o1UKirKLDxPfjrNfX7VnfAnZ+Ao0v1P/f1bP0I/nhJHW0Z87O2sQghRAVJwlKbrJ4K2z9R6xcCwiGgDfi3Ue97BN7cfjVW6ujZTJZHJ/LDrtOczy4oPd65YR1GdgpheJtA3Kqjo66pEH6fAruKa7R6/BsGzbCOZDE1DuZGqFNDL8SD0UPriIQQ4oYkYaktCnPh7UZQmHPtn7v4qAlMQBvwL05mfJuBg9O1z7cxBUVqoe7y6ETWHUmhuE4XNycDt7YN4p7OIXRs4G2ZQt38TFj+EBxbCzo9DHsbujx689e1FEWBDzrAhXgY9SW0vE3riIQQ4oYkYaktjqyCb+4Fz2C4fQ4k74Pk/XB2P6TGgnKNRmx6R6jX4rLRmOKvrj41H78Fnc3I4/uYU3wXnciJ85cSuCZ+7tzTKZg7O9xEoW5GEnw9Un1/HV3hX4uh+TALRW5Bq16A7R9DxzFw+4daRyOEEDckCUtt8fNE2P0ldHkcbnm77M8KcyHlkJq8XJ7I5Jez75Jn/eLk5bJpJZ8w0JffcdgaKYrCjvg0lkUnsnJfEnmFatLmUFKo2zmEvs0qUah79gB8NRIyToNbPbh/OdTvWI2v4CbErYUv71KnAqccssvpQCGEfZGEpTYwm+DdZpCTqhZZNup348coClxMUBOYkkTm7H64cOLa5zu6gl+r4mmlcDWJ8W8NRtvoQpuZV8ive5NYHp3InsSLpcf9PIzcHRHMyIhgGl2vUPf4Olg2Wk3yfJupy5brNKzusKuuKB/eaqhOET6+AQLbaR2REEJclyQstUHCNlg8BJy94PljYHCs+rXyMtSRhNLRmH2QchCKrrUxoU4defEPV9vCB4Sr972Crfov+iPJmXwXncgPu0+TdlmhbpeGPtzTOYRb2gTg6nRZoe6er+GXf4O5CEJ7qnUhtjBt9s19cGQlDJgOfZ7XOhohhLguSVhqgz9fhi0fQJuRcPenlr++2QTnj0HyP8WJTPGUUmY5u2g7e19WE1M8rVSvBThYQYO3yxQUmVl76CzLoxNZH3uutFDX3ejAXR3rM+2WFhg3vwvrZqo/CP8XjJhnda+jXNFL4LfJENwFxkfd8HQhhNCSJCz2TlHgwwhIOwYjl0LrO2vuubNTy04pJe+H1CPqSMSV9A7qVIp/uPrVyVX94HdwLr4Zr/HV5drHq2H0Jik9t7Sj7snzOThSxF/NfiQk4Uf1hF5TYMDL1rFsuaLST8P7rQCdOvKmZTM7IYS4gWprzS+sRGqsmqwYnKDJoJp9bjdfaNxfvZUoylf31CmTyOyDvIvq1FLKwZt/XsMVSYyjcwWSH+fr/jzQwZmJIUaeaGjk400ZtImdS0jCftAZYPh70Onhm4+7pnkVF0+f3Q9xa6DdKK0jEkKImyYJi606/Lv6NayPdTQIczBCYFv1VkJR1JU1yfvh7D64cFJNbIryrvE17+rjhbnAZQOApnz1lm/58PXAkwAGyMUZl/u/vLQDsi1qGqkmLEf/lIRFCGEXJGGxVSUJS4vh2sZxPTqdWojrFQzNh1b+8YqiTjNdnsgUXpnYXCv5yYei3OskR/nXvKa5MI99Fx15qXAci/1742/5d6TmNBsCm2apIyymIjDI/+pCCNsmv8VsUWYynI5W7zezwuZllqLTqSufDI41MoqkB176YCMHzmSw7fh57mhfv9qfs9rU76QWQeddhFM7IbS71hEJIcRNsaFKQlHqyCr1a/0I8AzUNhY7072RWqC67fh5jSO5SQaHS7VNR//UNhYhhLAASVhskS1MB9mo7o3VhGXrMRtPWECdFgJJWIQQdkESFluTnwnx69X7zSVhsbTOYT7odXDifA5J6blah3NzGg8EdGrxbfopraMRQoibIgmLrYlbC6YC8GkE9ZprHY3d8XR2JLy+F2AHoyxudSG4s3r/qDSQE0LYNklYbM2RlerXFsOtug2+LbObOhaAZpHqV5kWEkLYOElYbImpEGJXq/dlOqjadCtOWLbaQ8LStLiO5fg6dfm2EELYKElYbMnJLZCXDq6+ENJF62jsVucwHwx6HYlpuZy6kKN1ODcnoA14BKq7N5/crHU0QghRZZKw2JKS6aDmQ0Fv0DYWO+ZudKCNvdSx6HSXOvbKtJAQwoZJwmIrFOXScmaZDqp2Jcubtx1P0zgSCyiZFor9Q/3vSAghbJAkLLYieR+kJ6o7GTfqp3U0dq/bZYW3Nr+heaO+oHeEC/FwPk7raIQQokokYbEVJdNBjQeAk6u2sdQCnULr4KDXcfpiLolpNt6PxegBDXuq92VaSAhhoyRhsRWHf1O/SnfbGuFmdKBdiDdgJ8ubL58WEkIIGyQJiy24mKBOCen00KwKux6LKuluV8ubi/uxnNyidksWQggbIwmLLSjZ7DCkm9q9VNSI0n4sx+ygjsW3idod2Vyo9mQRQggbIwmLLZDpIE1EhNbB0aAjOSOPE+dtvB8LyLSQEMKmScJi7XIvwInihl8tbtE2llrGxclAh5A6gL3UsZT0Y4mS5c1CCJsjCYu1OxoFignqtVSH9EWN6tbIB7CDBnIADXuBoxtkJUPyP1pHI4QQlSIJi7UraRYn00Ga6Nb4UuGtzdexOBgv9fCJleXNQgjbIgmLNSvKh7g16n2ZDtJExwZ1cHLQcy4zn2PnsrUO5+aVTgtJHYsQwrZIwmLN4jdAQZa6eV1gB62jqZWcHQ10bOAN2EsdS/Hy5lPRkG0Hr0cIUWtIwmLNSvcOugX08k+llW721I/Fqz74twGUS6N3QghhA+RT0FqZzZfa8ct0kKZKGshtt4c6FoBmxaMsMi0khLAhkrBYqzO7IOssOHlAw95aR1OrtW/gjdFBT2pWAXEpWVqHc/NKpoXi1oCpSNtYhBCigiRhsVYl00FNB6mrO4RmjA4GOjVU+7HYxbRQcGdwqQN56XBqp9bRCCFEhUjCYq1KlzPfqm0cAoBuYZfa9Ns8vQGaDFLvy7SQEMJGSMJijc4fg9QjoHe49MEiNNW9uB/LtuPnMZvtoI6lZFpI+rEIIWyEJCzWqGR0pWEvcPHWNBShahvsjYujgQs5hcSm2MFux00Gqbt/pxyA9FNaRyOEEDckCYs1kukgq+PkoL9Ux2IP00KuPmotC8BRGWURQlg/SVisTdY5SNyu3m8+TNtYRBml/VjsIWGBS11vZVpICGEDJGGxNrGrAQUC24FXsNbRiMuU1LFsj0+zkzqWIerX+PVQmKdtLEIIcQOSsFib0mZxMh1kbdrU98LNyUB6biGHkjO0DufmBbRRt30ozIGTm7SORgghrksSFmtSkA3H/lLvN5futtbG0aCnU0MfwE6mhXQ6mRYSQtiMKiUs8+bNIywsDGdnZyIiIti4cWO5544dOxadTnfVrXXr1mXOmz17Ns2bN8fFxYWQkBCeeeYZ8vJq2TD1sb+hKA+8G4B/6xufL2rc5cub7ULJtNDRP8Aeth0QQtitSicsy5YtY/LkyUybNo3du3fTu3dvhg0bRkJCwjXPnzNnDklJSaW3xMREfHx8GDlyZOk5X331FS+++CKvvPIKhw4dYtGiRSxbtoypU6dW/ZXZosung3Q6bWMR11S6r1B8GiZ7qGNp1A/0jnDhBJyP0zoaIYQoV6UTllmzZjFu3DjGjx9Py5YtmT17NiEhIcyfP/+a53t5eREQEFB6i46O5sKFCzz88MOl52zdupWePXty//3307BhQyIjI7nvvvuIjo6u+iuzNaYiOLJKvS/TQVardZAnHkYHMvOKOHjGDupYjO7QsKd6P1a63gohrFelEpaCggJiYmKIjIwsczwyMpItW7ZU6BqLFi1i0KBBhIaGlh7r1asXMTEx7NixA4Djx4+zcuVKhg8fXu518vPzycjIKHOzaYnbITdN3eOlQXetoxHlcDDo6RxWXMdyPFXjaCykdFpI6liEENarUglLamoqJpMJf3//Msf9/f1JTk6+4eOTkpJYtWoV48ePL3P83nvv5bXXXqNXr144OjrSuHFj+vfvz4svvljutWbOnImXl1fpLSQkpDIvxfqUTAc1GwoGB21jEdfV3d76sTQrTlhOboF8O+jiK4SwS1UqutVdUV+hKMpVx65l6dKleHt7M2LEiDLH161bxxtvvMG8efPYtWsXP/zwA7/99huvvfZaudeaOnUq6enppbfExMSqvBTroChw+Df1vkwHWb2SwtudJy5QZDJrHI0F1G0MPo3BXKgWfgshhBWq1J/yvr6+GAyGq0ZTUlJSrhp1uZKiKCxevJjRo0fj5ORU5mcvv/wyo0ePLh15adOmDdnZ2Tz22GNMmzYNvf7qvMpoNGI0GisTvvVKOaQWPRqM0HiA1tGIG2gZ6ImnswMZeUXsP5NB+xBvrUO6eU0jYft8dbVQq9u1jkYIIa5SqREWJycnIiIiiIqKKnM8KiqKHj16XPex69evJy4ujnHjxl31s5ycnKuSEoPBgKIoKLVhqeWR4r2DGvVTiyCFVTPodXQJs7dpoeK6tKNRsrxZCGGVKj0lNGXKFD799FMWL17MoUOHeOaZZ0hISGDChAmAOlUzZsyYqx63aNEiunbtSnh4+FU/u+2225g/fz7ffvst8fHxREVF8fLLL3P77bdjMBiq8LJszOGS5czlFxkL62J3/VhCe4KjG2SdhaS9WkcjhBBXqXR156hRozh//jwzZswgKSmJ8PBwVq5cWbrqJykp6aqeLOnp6axYsYI5c+Zc85rTp09Hp9Mxffp0Tp8+Tb169bjtttt44403qvCSbEzGGTizC9DJZoc2pKTwdueJNApNZhwNNt402sGojvAd+V1dLRTUXuuIhBCiDJ1iJ3MuGRkZeHl5kZ6ejqenp9bhVNzOT+H3ZyG4C4yPuvH5wiqYzQodX4/iYk4hK57oQURoHa1DunkxS+HXSRDcGcav0ToaIUQtUdHPbxv/s9AOyHSQTdLrdXQt7sdiN9NCTYvrWE5FQ7ad9JgRQtgNSVi0lJcO8RvU+5Kw2JySaSG7SVg8g8C/DaBAnIywCCGsiyQsWopbo/a+qNsUfJtqHY2opO6NfQGIPnGBgiI76McCl60Wkq63QgjrIgmLlmQ6yKY19XPHx82J3EITe09d1Docyyhp0x+3Rt3fSgghrIQkLFopKrj0V6wkLDZJr9fRrVHxvkL20o8luJO6n1VeOpzaoXU0QghRShIWrZzcBPkZ4OYH9TtpHY2oIrurY9EboMkg9b5MCwkhrIgkLFopmQ5qPgyusfWAsA0lDeRiTl4gv8ikcTQWUjItFCsJixDCesgnpRYU5dLuzDIdZNMa13PH191IfpGZ3QkXtQ7HMpoMBJ0eUg7ARRveVFQIYVckYdFC0h7IOK22Qg/rq3U04ibodJfqWOxmWsjVR20eBzItJISwGpKwaKFkOqjJAHB01jYWcdNKpoXspvAWLjWROyrdl4UQ1kESFi2UTgfdqm0cwiJKCm93J1wkr9BO6liaFdexxK+HwjxtYxFCCCRhqXkXTsDZ/aAzXPorVti0MF83/DyMFJjM7Dp5QetwLMM/HDyCoDAHTmzSOhohhJCEpcaVTAeF9lBrBYTN0+l0pdNCdlPHotNB08HqfaljEUJYAUlYapqsDrJLJdNCW+0lYYFL00JH/1BXtgkhhIYkYalJOWlwcrN6v/kt2sYiLKpbccKyJ/EiuQV2UscS1hcMTuo0ZupRraMRQtRykrDUpNg/QDGr9QF1QrWORlhQaF1XAr2cKTQpRJ9M0zocyzC6Q2hP9b5MCwkhNCYJS0068rv6VaaD7I5Op7O/Nv1QdlpICCE0JAlLTSnMhbi16n2ZDrJL3ey5H8vJLZCXoW0stU3acTj4C5gKtY5ECKsgCUtNOb5eXSLqGQyB7bSORlSDkhGWf06lk51fpHE0FlK3Mfg0BnMRHF+ndTS1R0E2LLkFlo+GBf0gcafWEQmhOUlYakrpdNAt6pJRYXdCfFyp7+1CkVkh2l76sYBMC2lh60eQmaTeP7sfFg2G35+FvHRt4xJCQ5Kw1ASzCY6sUu/LdJBds882/SX9WKLAbNY2ltogKwU2z1HvD3sH2t0PKLDzU5jbGQ78KMvMRa0kCUtNOBUN2efA6AUNe2kdjahGdtmPJbSnulFn1llI3qt1NPZv3UwoyIKgjtB5PNw5H8b8ok7NZZ2F78bCVyPV5eZC1CKSsNSEkumgZpFgcNQ2FlGtSgpv959OJzPPToolHYzQuL96XzZDrF7nYiHmM/V+5OugL/4V3agvPLEF+r6o9saJi4KPusGm2VKUK2oNSVhqQkk7fpkOsnv1vV1o4OOKyawQfcKO6lhKpoVipY6lWq15BRST+ruiYc+yP3N0hv5TYcJmCO0FRbnq+Z/0hcQd2sQrRA2ShKW6nYuF80dB7whNBmkdjagBdjktVLK8+XQMZKdqG4u9OrFJ3bpDZ4BB/y3/vHrNYOxvcMc8cPGBlAOwKBJ+mwK5F2ssXCFqmiQs1a1kOiisDzh7ahuLqBF2WXjrGQQBbQAF4tZoHY39MZvhz+nq/YiH1KTkenQ66PAAPBUN7R8AFIheBB91gf0rpChX2CVJWKrbYdnssLYp2VfowJl00nPtqL6gafHyZpkWsrwDP8CZ3eDkDv2mVvxxbnVhxDx46Feo20Qtyv3+EfjqX1KUK+yOJCzVKfMsnCpu+CT1K7VGgJczYb5umBXYGW8n+wrBpWmhY2vBZCeN8axBUT6sLZ4C6jkZ3P0qf42wPmpRbr+pxUW5a4qLct+XolxhNyRhqU6xqwBFXZ7oGah1NKIGdbPHOpbgTmrNRF46nJIiT4vZsQAuJoBHIHSfWPXrOBih34tq4tKwd3FR7qvwSR8pyhV2QRKW6iTTQbVWt0Y+gJ3VsegNlwrHZVrIMnLSYMM76v3+08DJ9eav6dtUnSIaMb+4KPdgcVHuM1KUK2yaJCzVJT/r0t4rkrDUOiUrhQ4lZ3Axp0DjaCyoZFro6J/axmEvNryrjlj5tYb291vuujqder0yRbmL1U65UpQrbJQkLNXl2Fow5UOdMKjXQutoRA3z83SmcT03FAW221MdS5OBoNOrf7VfTNQ6GtuWFq9OBwFEzlBHsCyttCj3N6jbFLJT1KLcL+9Wn18IGyIJS3W5fDpINjuslexyebOrDwR3Ue/LKMvNWTsDzIXQqH/192gK6w1PbIZ+L6lFucfWwrxusHGWFOUKmyEJS3UwFUHsavW+TAfVWiWFt9vsqfAWLtsMURKWKjsVrS5lRgeRr9XMczoYod8LlxXl5qmrkz7pAwnbayYGIW6CJCzVIWEL5F0E17oQ0lXraIRGShKWw8mZpGXbUR1Ls+J+LMfXQ2GutrHYIkW51CSu3X3FDflqUGlR7seXinIXR8KvkyHXjraTEHZHEpbqUDId1GxY9cxLC5vg626kmb87ANvtaZTFPxw8gtRlsyc2ax2N7Tn8OyRsBQdnGDBdmxh0Omh/X3FR7oPqsZglMLcL7PteinKFVZKExdIU5VI7/hbSLK62s8t9hXS6y6aFZHlzpZgK1Q0LQe254lVf23jc6sKIj2Ds7+DbTC3KXTEOvrwL0o5rG5sQV5CExdLO7lebQDm4qMV0olYrbSBnT4W3cGlaKPYP+Wu8MmKWwvk4cPVVu9pai4a9YMImtReMwQmO/QXzusPG96DIjqYzhU2ThMXSSqaDGve3TBMoYdO6FicsR1OySM3K1zgaCwrrq36wXTwJqUe1jsY25GXAuv+p9/u9aH2boToYoe//wRNb1Vb/RXnqSqZP+kDCNq2jE0ISFosrnQ6S1UECfNycaBHgAdjZaiGju/pXOci0UEVtng05qeomhRFjtY6mfL5NYMwvcOcn6sKBc4dg8RD4dZIU5QpNScJiSRcTIWmv2lir2VCtoxFWwi77scClrrfSpv/G0k/D1o/U+4P+CwZHbeO5EZ0O2t2rFuV2KCnKXap2ypWiXKERSVgs6cgq9WtIV3Dz1TYWYTXstx9LccKSsFWd7hDl+/sNdYqlQXfbGn119YE7Li/KPSdFuUIzkrBYkkwHiWvoFlYXnQ6OncsmJSNP63Asp25jdXrDXATH/9Y6GuuVvA/2fK3ej3zdNjtflxblTgeD8VJR7oZ3pShX1BhJWCwl9yKc2KTeby7LmcUlXq6OtApUCyztankzXDYtJF1vy/Xny4ACre+E4E4VflhiWg7rY89VX1yV5WCEvs/Dk1vVouuiPPjrNVjQFzKTtY5O1AJVSljmzZtHWFgYzs7OREREsHHjxnLPHTt2LDqd7qpb69atS8/p16/fNc8ZPtyGRiqORql/adZrof7lKcRl7H5aKC4KzGZtY7FGcWvU0Se9Iwx8pcIPiz6Rxi0fbOShxTvYYW2bZ9ZtDGN+hjsXqMuzUw7C16OgIFvryISdq3TCsmzZMiZPnsy0adPYvXs3vXv3ZtiwYSQkJFzz/Dlz5pCUlFR6S0xMxMfHh5EjR5ae88MPP5Q5Z//+/RgMhjLnWD2ZDhLX0b00YbGyD5+bFdoDnNwh6ywk79U6GutiNsGf/1Hvd3kMfMIq9LD1sed4cNF2MvOKAPh175nqirDqdDpoNwrG/am290/aAz88JkmrqFaVTlhmzZrFuHHjGD9+PC1btmT27NmEhIQwf/78a57v5eVFQEBA6S06OpoLFy7w8MMPl57j4+NT5pyoqChcXV1tJ2Epyoeja9T7zSVhEVfr0sgHvQ7iU7NJTrejOhYHIzTqp96XaaGy9n4DKQfA2Qv6PFehh6zal8T4z3aSV2imUT03AFYfSMZsttJVOXUbw71fqz15Dv92qYuvENWgUglLQUEBMTExREZGljkeGRnJli1bKnSNRYsWMWjQIEJDQ697zr333oubm1u55+Tn55ORkVHmppn4jVCQCe4BENRBuziE1fJ0diS8vhcAW4+nahyNhZVMC8nuzZcU5MBfr6v3ez+nrra5ge9jTjHx610UmhSGtwnk16d64eHswLnMfGISrLj/SWh3dSURwJYP1OXPQlSDSiUsqampmEwm/P39yxz39/cnOfnGRVdJSUmsWrWK8ePHl3vOjh072L9//3XPAZg5cyZeXl6lt5CQkIq9iOpw+d5BeqljFtdWWsdyzM6mhUoSltMxkG1nyVhVbf0IMpPAq4E6HXQDSzfH89x3ezErcE+nYD64rwNuRgcGt1R/167aZ+VFrW3vgb4vqvd/fxaOyaoxYXlV+nTVXbEsT1GUq45dy9KlS/H29mbEiBHlnrNo0SLCw8Pp0qXLda81depU0tPTS2+JiYkVit3izOZL/VdkOkhch11uhAjgGQgBbQBFLT6v7bJS1K62AINeAUfnck9VFIUP1x7l1V8PAvBIzzD+d1dbDHr19+nQ8AAA/jiQjGLtzdr6vQjh/1IXHyx/CM4d0ToiYWcqlbD4+vpiMBiuGk1JSUm5atTlSoqisHjxYkaPHo2Tk9M1z8nJyeHbb7+94egKgNFoxNPTs8xNE2d2q39JOXlAWG9tYhA2oXOYDwa9joS0HE5fzNU6HMtqWrwZorTpV/cLKshSp4db31XuaYqiMHPVYd6LigVg0sCmvHxrS/T6S3/89WlWD1cnA6cv5vLPqfRqD/2m6HTq1FBIN8hPh69GQpYVLcsWNq9SCYuTkxMRERFERZX9KyoqKooePXpc97Hr168nLi6OcePGlXvO8uXLyc/P58EHH6xMWNoqmQ5qMlAtQBSiHO5GB9qU1LHYW5v+kt2b4/4CU5G2sWjpXOylGo7I18udIjaZFV76cT8LNqjdYqcPb8kzg5tdNVLt7Gigfws/AFbuT6q2sC3G0Rnu/QrqNFQ3xvz2fii0oyJzoalKTwlNmTKFTz/9lMWLF3Po0CGeeeYZEhISmDBhAqBO1YwZM+aqxy1atIiuXbsSHh5e7rUXLVrEiBEjqFu3bmXD0k7J7swtbtU2DmET7LYfS/0IdXlrfjokbtc6Gu2seRUUEzQbdmlzyCsUmsxMXraHb3YkoNfB23e3ZXzvRuVecljxtNDq/TYwLQTqtiT3fwdGLzi1A35+UvYeEhZR6YRl1KhRzJ49mxkzZtC+fXs2bNjAypUrS1f9JCUlXdWTJT09nRUrVlx3dCU2NpZNmzZd9xyrc/6YupOp3gGaDtY6GmED7HYjRL0BmgxS79fWaaETm9URV50BBv/3mqfkFZp4/IsYft17BkeDjg/v68g9na+/YKB/cz+MDnpOns/hUFJmdURuefWawajP1d+N+1fAuplaRyTsgENVHvTkk0/y5JNPXvNnS5cuveqYl5cXOTk5171ms2bNbOOvh8sdKR5dCe0JLt6ahiJsQ6fQOjjodZy+mEtiWg4hPq5ah2Q5zYbAvuVq4e3gGVpHU7PMZvhzuno/4iGo1/yqU7Lyixj/2U62HU/D6KDn49ER9G/ud8NLuxkd6NusHn8ePMvq/Um0CtKoXq+yGvWD4bPg16dh/Vvg01htNidEFcka3Jsh00GiktyMDrQNttM6lsYDQKdXW7Vf1GjVnlYO/ABndqldf/tNverHF7ILeGDhNrYdT8Pd6MDnj3SpULJSYlgbdVpo1X4rX958pYiHoOck9f4vT8HJivXrEuJaJGGpquxUSNym3m8+TNtYhE0pmRayuzoWVx8ILm5HUJumhYryYW3xFFDPSeBeNhFJychj1IKt7D2VTh1XR75+tCtdG1WuTm9AC38cDTqOpmQRl2Ij00IlBr4KLW8DUwF8+4A6lS5EFUjCUlWxq0ExQ0Bb8NawaZ2wOd0b+QJqPxabmwa9kWYlXW9rUT+WHQvhYoLa6br7xDI/SkzL4V8fbyX2bBZ+HkaWP96dtsHelX4KLxdHejVR/7ux+iZyV9Lr1Y0SgzpAbhp8fQ/k2FnzRFEjJGGpKpkOElUUEVoHR4OOpPQ8Tp6/fm2XzSnpx3J8PRTaWa+Za8lJgw1vq/cHTAOnS9uJxKVkMvLjrSSk5RDi48L3E3rQ1N+jyk81LDwQsMFpIQAnV7jvW/AMhvNxsHwMFBVoHZWwMZKwVEVBDhz7S73f4hZtYxE2x8XJQPsQb8AOp4X8W4NnfSjKVT+U8qy82dnN2vie+hr9WkH7B0oP7z+dzj2fbCM5I4+mfu5893gPGtS9uQLrwa38Meh1HEzK4OT57JuNvOZ5BMD9y9Qmmyc2wm/PyHJnUSmSsFTF8b/VX8heDcC//L4yQpTHbtv063Rwy7vg4KxuhrhwIKQe1Tqq6nHhBOxYoN4f/Jq6tBvYeSKN+xZsIy27gDb1vVj2eHcCvMpvz19Rddyc6NZI3UTRJkdZAALCYeQStTh7z5ew6X2tIxI2RBKWqiidDhqu/oIWopK6XdaPxe7qWFrcAo+sVkdazh9VkxZ7rGlZO0MtJG3UT+10DayPPcfoRdvJzC+iS5gPXz/aFR+3a29FUhVDbXlaqETTwTCseBpt7X/hwI/axiNshiQslWU2QWzxZocyHSSqqGODOjg56EnJzOd4qg0O799IUAd4bB006H5pX5lNs+1nCuBUjNoQDZ06uqLTsWpfEuM/20leoZl+zevx2cNd8HB2tOjTDmntj04HexMvcsaW96Pq8ih0Vbuj8+MEOBWtbTzCJkjCUlmJ2yHnPDh7Q4Pr758kRHmcHQ10sNc6lhLufjDmF4gYCyiw5hVYMV6tAbNlinKpSVy7eyGwLd9FJzLx610UmhSGtwlkwehOuDgZLP7Ufh7OdA5Vp4VW2/IoC8CQN9Ui7aI8+OZeuHBS64iElZOEpbIOF2922GwoGKrUKFgIwI7b9F/OwQlum6N2PNU7wP7vYclQ224sd2QlJGxR63QGTGfxpnie//4fzAqM6hTCB/d1wMmh+n61Dr1sbyGbpjfAvxaBfxvIPgdfj7L/Im1xUyRhqQxFuZSwyHSQuEndSzdCTLO/OpYrdR6njra41oWkvbCwP5zcqnVUlWcqhKhXAFC6PcmcnbnM+O0gAON6hfG/u9tg0FdvXVtJwrLzZBopmTa+E7LRA+7/Vu1hc+4QfPdw7d7tW1yXJCyVce4wXIgHgxEaD9Q6GmHj2jfwxuigJzUrn7iULK3DqX4Ne6p1LQHFf1F/dhtEL9E6qsrZ9RmcP4riWpd3s4bx/ppYAJ4Z1Izpw1uiq4Ei/CBvF9qFeKMo8MeBs9X+fNXOK1hNWhxd4dhaWPV/9lPrJCxKEpbKKBldadQXjO7axiJsntHBQERoHcCO61iu5N0AHvkDWt8J5kL4bTL8NsU2mojlZcC6/wHwi9doPtp2DoD/3NqKSYOa1kiyUuKW0mmhpBp7zmoV1AHuWgjoIHoRbJuvdUTCCknCUhlHLlvOLIQF2G0/lutxcoN/LYGB/6H0A+qLEZB1TuvIrm/zHMg+R4pjMM/Gd0Svg7fvbssjvcJqPJSSrrfbjqdxIdsGkr2KaHnrpV2+/3gJjqzSNh5hdSRhqaiMJDgdA+igmWx2KCzj0kaIaZjNtWgYXKeD3s+q7dqdPODkZrWuJWmv1pFdW8YZlK0fAfBy9kh0Bkc+vK8j93TWZh+xBnVdaRXoicmsEHXQDqaFSvT496VVZd+Ps97/HoQmJGGpqJLRleBO4OGvbSzCbrQN9sbF0UBadgFHa0Mdy5WaD4VH14JPY0hPhEVDivubWJfCqNfQFeWy09yM9YYuLBzTieFtAzWNaVjxtNBKe5kWgkudkhv1g8Js+PpeyDijdVTCSkjCUlEyHSSqgZODnk4N1TqWrcdSNY5GI/Waw6N/QZNB6pYX3z8Ca/6rNmm0AhnxuzHs+waA93Vj+PyRbvRr7qdxVDCsjZowbY5LJT23UONoLMjgCCM/A9/mkHlGXe6cXwuTeXEVSVgqIi8D4jeo95tLwiIsq1ttrGO5kos33L8cek5Sv980C765T/O+HGcz8jjy5TPoUfiT7kx9dAxdwnw0jalEEz93mvq5U2hS+OuwHU0LgfrfwwPLwdUXkv+BHx61mgRWaEcSloqIW6PuGVK3CdRrpnU0ws6U1LFsj69ldSxX0hvUosu7Pi3ePPGP4s0T4zQJJzEth7c/mkdn024KcaDZ/e/QJthLk1jKUzIttGqfjTeRu5Y6DeG+b9Q2EkdWQtR/tI5IaEwSloqQ6SBRjdrU98LVycDFnEIOJ2dqHY722o68YvPEATW+eeLRs5ncM38j43PVPjF57R+mYbM2NRpDRZRshrg+9hzZ+XbYcC2kC9xZvMR561zYuUjbeISmJGG5EVMhxP6p3pfpIFENHA16OjdUpxlq9bTQ5Uo2TwzpVuObJ+47lc49n2ylZ85aWuoTMBs98Yh8qdqftypaBnoQWteV/CIzfx9J0Tqc6hF+N/Qv3rtp5fMQt1bbeIRmJGG5kROb1F+YbvXUFUJCVINasa9QZbn7wUO/QseHKN088YdHobD6dinefvw89y3cRm5OFi8avwdA3+c5cLWOupUr6XS60p4sq2x9b6Hr6fMctL0XFBN8NxZSDmkdkdCAJCw3UjId1HyYOscuRDUoaSC3Pf48ptpcx3Kl0s0T31M3T9z3HSweAumnLP5Ufx9JYcziHWTlF/FKvfX4ms+DVwPo8rjFn8uSSupY/j6cQl6hnRam6nRw+wcQ2hPyM+CreyDLTkeURLkkYbkeRYHDJQmLTAeJ6tM6yBN3owOZeUUcSsrQOhzrotNB5/Ew5udLmycu6GfRzRN//yeJxz6PJr/IzO1NHLg3Xx1dYeB/wNHZYs9THdoGe1Hf24WcAhMbYq28W/DNcDDCqC/BpxGkJ6iryKpxtE1YH0lYbuTBFTDwFXX/ICGqiYNBX7pcVqaFytGwl1rX4n/Z5okxS2/6sst3JvLvb3ZRaFK4tW0g7/v/ga4gCwLbq/UTVk6n0zGkdfFqIXueFgJ1au7+78DZG05Hw48TwGzWOipRQyRhuR6dDvxaQO8p4OiidTTCztXKfYUqy7sBjLts88RfJ8Hvz6rF8VWwaFM8/7fiH8wK3Ns5hDmD3DHsWqr+MPJ10NvGr8hb2qgJy5pDZykosvMPcN8mcO9XoHeEgz/B329oHZGoIbbxf6MQtUBJ4e3O+DSKTHb+oXMzrtw8ceen8PkdkF3xTsGKojB7TSyv/XYQgEd7hzHzrjYY/vqvWtjZbCiE9a6mF2B5HRvUwc/DSGZeEZtrQ8fkhr3UmhaAje/Cnq+1jUfUCElYhLASLQM98XR2IDO/iANnpI7luq61eeKCfpD0T4Ue/s4fR5i95igAUwY346VbWqJL2AqHfwOdHgb9txqDtzy9/tK00Gp7bCJ3Le3vh97Pqfd/eRriN2obj6h2krAIYSUMeh1dwmRaqFKu2jwxEvb/cN2HfB9zinnrjgHwn1tb8fTApugA/izu9dHxIXUq2MaUrBb682By7Rmh6z/t0vTgsgc164osaoYkLEJYEenHUgX1mqtJS+OBxZsnPgxrZ1yzGHN3wgVe+nEfAE8PaMIjvcLUHxz4AU7HgKMb9Jtak9FbTJcwH+q4OnIhp5Dt8Wlah1Mz9HoYMR/qd4K8i/D1SMipJa+9FpKERQgr0q2RulIo+kQahbXlr2RLcKkDD3wHPZ5Wv9/4HnxbdvPEsxl5PP5FDAVFZga19GfyoOJ9wYry1d2hQd180cO/hoO3DAeD/rLVQkkaR1ODHF3UPYe8GkDacfj2AfXfVNgdSViEsCItAzzxdnUku8DEvtPa7lRsc/QGiHwN7lqobp4Yuxo+HQSpceQVmnj8ixhSMvNp6ufO+6Paodfr1Mft/BQungT3AOjxlLav4SYNLZ4W+uPA2dq1kaa7n7q7s9ETEraoq8dqYBsHUbMkYRHCiuj1OrpKP5ab0/YeeHiVunliaizKwv588cUi9iRexNPZgYVjOuHh7Kiem3sB1r+t3h8wTV2BZMN6NPbFw9mBc5n5xCRc0DqcmuXXEkYuBZ0B9n6jrh4SdkUSFiGsTEk/lm1SeFt19TvCo39DSFd0+Rk8cvL/eNzhV+be14GGvpclJRveVWsf/FpB+wc0C9dSnBz0DG6pTmmtqi2rhS7XZCAML05U/nod9q/QNh57U4nWAdVBEhYhrEy34sLb6BMX7L8JWHXy8GdLryUsM/XHoFOY6vANffa/dKmd+4UTsGOBen/wDLvZK6xkWmj1/iSU2jgt0ukR6F48tffjE5C4Q9t4bFlmMuz7Hn57BuZ2hncaQ/ppzcJx0OyZhRDX1MzPAx83J9KyC/jn1EU6NbTOnYKtXcL5HJ5cdoCLheMxBLXj7nNz0e37DlKPqp1S174GpgII6wtNBmkdrsX0aVYPNycDZ9Lz2HsqnfYh3lqHVPMGz1ALcI+sVPccenQt1GmodVTWL/202tPoxCb16/lrLBNP2gte9Ws+NiRhEcLq6PU6ujXyYeW+ZLYeOy8JSxVk5xfx6OfRXMwppF2wN7eO/w+6U4Pgu4cgaQ983Bty0wCdWqir02kdssU4Oxro38KP3/5JYtX+pNqZsOgNcPensHgoJP8Dn90O4XdBYDv1VifMrv7Nq+xiYnGCshFObIYL8VecoIOANmpn4dCeENpD3c9JI5KwCGGFujeqy8p9yWyLP8+/aap1ODbFbFaYsnwPR85mUs/DyCejO+HsaFBb7T/6t7rs9azai4V296ofYHZmWHggv/2TxOr9ybw4tAW62vjh7OQG9y+DhQPVVWCb3r/0M6MnBLSFwLbqv39AW/BtBgY7/0i8cPLS6MmJTer7cjmdXn0vGvZSbw26qS0DrISd/+sIYZu6NbpUx5JfZMLoYB/1FTXhw7/i+OPAWZwMej5+MIIAL+dLP6wTqm6euOr/IOVQ8X5E9qdf83oYHfScPJ/DwaQMWgd5aR2SNjyD4PENcOgXdaQlaS+cPQj5GXByk3or4eAM/q0vjcIEtFWLsR2dy7++NVMUdcTkxOZLCUp6YtlzdAYIaq+OnpQkKM7W+9+KJCxCWKEmfu74uhtJzcpnT8JFuhYnMOL6/jiQzPtrYgF4fUQ4EaHX+OvQyQ3u+KiGI6tZbkYH+jWvxx8HzrJ6f3LtTVgA3OtB53GXvjcVwrkjavJSksQk74OCLLXb8emYS+fqHaBei0sJTGA7CAgHo0fNv44bURS1bqdkeufkZsi4okBW7wBBHYqneHpBg67W+VrKIQmLEFZIp1PrWH77J4mtx89LwlIBR5IzmbJsDwBjezTkns4h2gaksWHhgfxx4Cyr9ifzbGRzrcOxHgZHNekICAeKl7KbzeqHffJeNYFJKk5kctPg7H71xlfFF9BB3caXEpiSW03XdiiKWkB+cpOaoJzYBFlXLGXXO0L9CGhYPIIS3AWM7jUbpwVJwiKElerWqC6//ZMk/Vgq4GJOAY9+Hk12gYnujeoybXhLrUPS3ICWfjgadMSlZBGXkkkTP9v5S7rG6fXg20S9hd+tHlMUdYTi8gQmaS9knlFXz5yPU/egKuEVclkSU/zVI9Byxb2Koo4MndhYPMWzGbJTyp5jcFL3VWrYS01SgruAk6tlnt8KSMIihJUq2QhxV8JF8gpNauGouEqRycxTX+8mIS2H4DoufPRARxwN0mLK09mRXk18+fvIOVbtS+bfAyVhqRSdDryC1VuL4ZeOZ50rHon559K0UtpxtT4kPRGO/H7pXFffsglMZVYomc1w7lDx9E7xKErOFY3bDEYI6XKpBiW4k7q3kp2ShEUIK9XI1w0/DyMpmfnsSrhAj8a+WodklWauOsymuFRcHA0sHNMJHzcnrUOyGsPCA/n7yDlW7k/m3wNltZlFuNdT+/Zc3rsnLx2S95etizl3RE0wjq1VbyXKW6Gk00PKgeLpnY1wckvx0vvLOLhASGdo2FtNUupH2G5RcBVIwiKEldLpdHRvXJef95xh2/E0SViu4fuYUyzapPaOmHVPO1oGemockXUZ3Mofw486DiVlcPJ8NqF1bXuvJKvl7FVcJ9Lz0rHCXHVFUtKeiq1QcjCW2V0cAEdXCOlafO3eENQRHGpvQl6lcdN58+YRFhaGs7MzERERbNy4sdxzx44di06nu+rWunXrMuddvHiRiRMnEhgYiLOzMy1btmTlypVVCU8Iu1GyvHmbbIR4ld0JF3jpR7WfytMDmjCsTaDGEVmfOm5OpXtTrdpfC/cW0pKjCwRHqCuUbpsDj62Dl07DhM1wxzzoOgEadAcndyjKU5MVJ3doPBAGvgLjouCFkzDmJ+jzvLrkuBYnK1CFEZZly5YxefJk5s2bR8+ePfnkk08YNmwYBw8epEGDBledP2fOHP73v/+Vfl9UVES7du0YOXJk6bGCggIGDx6Mn58f33//PcHBwSQmJuLhIXOuonYr+bDZnXiB3AITLk5SxwJwNiOPx7+IoaDIzKCW/kwe1EzrkKzW0PAANsWlsmp/MhP6NtY6nNrteiuUCrLUPjAGR01DtGaVHmGZNWsW48aNY/z48bRs2ZLZs2cTEhLC/Pnzr3m+l5cXAQEBpbfo6GguXLjAww8/XHrO4sWLSUtL46effqJnz56EhobSq1cv2rWzvw6UQlRGaF1XAr2cKTQpxJy8oHU4ViGv0MTjX8SQkplPUz933h/VDr2+FnZyraDI1v7odLA38SKnL+ZqHY64UskKpaD2kqzcQKUSloKCAmJiYoiMjCxzPDIyki1btlToGosWLWLQoEGEhoaWHvvll1/o3r07EydOxN/fn/DwcN58801MJlO518nPzycjI6PMTQh7o9PpSkdZZHkzKIrC9J/2syfxIp7ODiwc0wkPZ/klfz1+Hs50DlV7hKyWaSFhwyqVsKSmpmIymfD39y9z3N/fn+TkG/+PkJSUxKpVqxg/fnyZ48ePH+f777/HZDKxcuVKpk+fznvvvccbb7xR7rVmzpyJl5dX6S0kpHY3iRL2q6SOZaskLCzdcoLvY06h18Hc+zvS0FeKSCtiWJsAAFbvT9I4EiGqrkpFt1dupKUoSoU211q6dCne3t6MGDGizHGz2Yyfnx8LFiwgIiKCe++9l2nTppU7zQQwdepU0tPTS2+JiYnlniuELSvpx7I38SLZ+UUaR6OdzXGpvP77IQBeuqUlfZrV0zgi2zE0XE1Yok9eICUzT+NohKiaSiUsvr6+GAyGq0ZTUlJSrhp1uZKiKCxevJjRo0fj5FS20jkwMJBmzZphMFwqKGzZsiXJyckUFBRc83pGoxFPT88yNyHsUYiPK/W9XSgyK0TX0jqWhPM5TPx6Fyazwl0d6jOuV5jWIdmUQC8X2od4oyjwx4GzWocjRJVUKmFxcnIiIiKCqKioMsejoqLo0aPHdR+7fv164uLiGDdu3FU/69mzJ3FxcZjN5tJjsbGxBAYGXpXcCFEblYyy1MY6luz8Ih79PJqLOYW0C/bizbvaVGhEV5Q1rHiUZdU+mRYStqnSU0JTpkzh008/ZfHixRw6dIhnnnmGhIQEJkyYAKhTNWPGjLnqcYsWLaJr166Eh4df9bMnnniC8+fPM2nSJGJjY/n999958803mThxYhVekhD2p7SOpZb1YzGbFaYs38ORs5nU8zDyyehOskVBFQ0LV/vUbI9PIy372iPXQlizSvdhGTVqFOfPn2fGjBkkJSURHh7OypUrS1f9JCUlkZCQUOYx6enprFixgjlz5lzzmiEhIfz5558888wztG3blvr16zNp0iReeOGFKrwkIexPyQjLvtPpZOUX4W6sHU2qP/wrjj8OnMXJoOfjByMI8Ko9bcgtrUFdV1oHeXLgTAZRB5MZ1fnqvllCWDOdoiiK1kFYQkZGBl5eXqSnp0s9i7BLfd7+m4S0HJY83Jn+zf20Dqfa/XEgmce/iAHg7bvbck9nWQl4s+b+dZR3/4ylX/N6LH24i9bhCAFU/PNbtjQVwkZ0a6T20qgNbfqPJGcyZdkeAMb2aCjJioUMLZ4W2hyXSnpuocbRCFE5krAIYSNKpoXsvR/LxZwCHv08muwCEz0a12Xa8JZah2Q3mvi509TPnUKTwtpDslrIWiiKQk5B7W1ZUFGSsAhhI7o3Undr3n863W57aRSZzDz19W4S0nII8XHho/s74miQX1OWVLJJpGyGaB3iU7MZMnsD3d5cy5HkTK3DsWrym0AIGxHg5Uzjem6YFej/zjpe/+0gSen2tTfMmysPsykuFVcnAwvHdKKOm7Q1sLSS5c0bYs/V6kaE1mDT0VRGfLSZ2LNZZOQV8eovB7CTstJqIQmLEDbkvXva0yLAg+wCE59uiqfP23/z/Hd7iUux/b/MvotOZPHmeADeG9mOFgFSPF8dWgR40LCuK/lFZv4+kqJ1OLWSoigs3RzPQ0t2kJ5bSNtgL5wc9Gw9fp4/DsjIV3kkYRHChrQP8WbVpN4sebgzXcN8KDQpfBdzikGzNvDY59HsSrDNTri7Ey4w7cf9ADw9sGnptIWwPJ1OV1p8K9NCNa+gyMxLP+7j1V8Pqp2bO9Zn+ePdebxPIwBe//0QeYXlb/xbm0nCIoSN0el09G/ux7LHu/PDkz2IbKVui/HnwbPcNW8L93yylb8Pp9jM0PLZjDwe/yKGApOZwa38mTywqdYh2b1bijdD/Ptwinw41qDzWfk8+Ol2vtmRiE4HL93SgvdGtsPZ0cAT/RoT4OnMqQu5LNxwXOtQrZIkLELYsI4N6rBgTCfWTOnLPZ2CcTTo2BGfxsNLdzJszkZ+2n2aIpP5xhfSSF6hice/iCElM59m/u68P6o9er203a9ubep7Ud/bhZwCE+tjz2kdTq1wKCmD2+duZseJNDyMDix+qDOP9Wlcus2Eq5MDU29pAcC8dcfsrj7NEiRhEcIONPFz5+1/tWPD//Xn0d5huDkZOJycyeRle+j37jo+23KC3ALr+ktaURSm/bifPYkX8XJxZOGYTrWmg6/W1GkhdZRltUwLVbvV+5O5e/4WTl/MpWFdV36c2IP+La5u/nh7uyA6hdYht9DE/1Yd1iBS6yYJixB2JNDLhWnDW7HlxYE8F9mMum5OnLqQyyu/HKDnW38xZ81RLljJPjJLNp9gxa5T6HUw9/4OhNZ10zqkWqVktdCaQ2cpKLLeUThbpigKH649yoQvY8gpMNGriS8/TexJEz+Pa56v0+l45bbW6HTw854zRJ9Iq+GIrZskLELYIS9XR54a0JTNLw7gtTtaE+LjQlp2Ae+viaXnW38x49eDnLmo3ZDzpqOpvLHyEAAv3dKS3k3raRZLbdWxQR38PIxk5hWx+Viq1uHYndwCE099s5v3omIBtWPz0oc74+16/aX6bYK9uCdC7ez86q8HMJttoxatJkjCIoQdc3Y0MLp7Q/5+th8f3NeBloGe5BSYWLxZXRL97PK9HD1bs0uiT57PZuLXu0pXSIzrFVajzy9Uev2laaFV+5I0jsa+nLmYy8hPtvD7P0k4GnTMvKsNr97eGocKNkF8fmhzPIwO7D+dwXcxidUcre2QhEWIWsDBoOf2dkGsfLoXnz3She6N6lJkVlix6xSD39/A+M921sjwc1Z+EY9+Hk16biHtgr148842pUWHouaVJCxRB89adXG2LYk5eYHb525m/+kMfNyc+Gp8N+7rUrmdsX3djUwapK6We+ePI2Tkyb5PIAmLELWKTqejb7N6fPNYN36a2JOhrQPQ6WDNoRT+9fFWRn68hbWHzlbLMLTZrPDs8j3Ens2inoeRT0Z3wtnRYPHnERXXpaEPPm5OXMgpZHu81EvcrO9jTnHfgm2kZuXTIsCDnyf2pEuYT5WuNaZ7QxrVcyM1q4AP1x61cKS2SRIWIWqp9iHefDw6gjVT+jKqUwiOBh07T1xg3GfRDJ2zgR92naLQgn91f/DXUf44cBYng56PH4wgwMvZYtcWVeNg0Jf28Vm1X6aFqspkVnjj94M8991eCkxmhrT2Z8UTPQjxca3yNZ0c9Lx8aytALVA/di7LUuHaLElYhKjlGtdz561/tWXTCwN4vE8j3I0OxJ7NYsryvfR7Zx1LNsff9E6yq/cnM3uN+lfi63eGExFaxxKhCwu4tLz5LCYp8Ky0jLxCHlm6k4Ub1W0lnh7QhPkPROBmgSX6/Zv7MaCFH0Vmhdd+O3jT17N1krAIIQDw93Rm6i0t2fziAJ4f0hxfdydOX8zlv78epOf//uL9qFjSqrAk+nByBlOW7wHUlRL3dAqxcOTiZvRo7IunswOpWfnEnLTNrR20Ep+azYiPNrM+9hzOjnrm3t+BKZHNLdr8cPrwljgadKw7co6/D9fuvZ8kYRFClOHl4sjE/k3Y9MIAXh8RTmhdVy7kFDJn7VF6/u8vXv3lAKcu5FToWheyC3j082hyCkz0aFyXacNbVnP0orKcHPQMkmmhStt49Bx3zN3E8XPZBHo58/2EHtzaNsjiz9OonjsP91RX0r3228Fa3TNHEhYhxDU5Oxp4sFsofz3bj7n3dyC8vie5hSaWbjlB33fW8cyyPRxOzij38UUmM099s4vEtFxCfFz46P6OOFZwWaeoWcOKN0P8Y3+yzexBpRVFUViyOZ6xS3aSkVdExwbe/PxUT8Lre1Xbc/57QBN83Z04nprN0i3x1fY81k5+ewghrsug13Fr2yB+faoXX4zrQs8mdTGZFX7cfZqhszfyyNKd7IhPu+qD7s2Vh9kcdx5XJwMLx3Sijtv1G2YJ7fRu6oubk4Ez6XnsPZWudThWq6DIzIsr9vHf4p2W7+4YzDePdcPPo3oLyD2cHfm/Ieo+Qx+sjeNcZn61Pp+1koRFCFEhOp2O3k3r8dX4bvzyVE9uaaMuif7rcAr3fLKVu+dvIeqguiT6u+hEFm9W/xJ8b2Q7WgR4ahy9uB5nRwMDWhZPC0kTuWtKzcrngU+3sSw6Eb1OrS15d2RbjA41szT/XxHBtA32Iiu/iHf+qJ37DOkUOxn/y8jIwMvLi/T0dDw95ZejEDXh+LksFm48zoqY0xQUL4Fu4udOwvkcCkxmnh7YlCmDm2kcpaiIlfuSePKrXTTwcWX98/2kod9lDp7J4NHPozl9MRcPowMf3N+B/s2v3rywusWcvMDd87eoew1N7EnbYO8aj6E6VPTzW0ZYhBBV1qieOzPvasumF/ozoW9jPIwOxKVkUWAyM7iVP5MHNtU6RFFB/ZrXw9lRT0JaDgeTyq9Nqm1W70+6YqflnpokKwARoXUY0T4IRYFXfzlQ6+qNJGERQtw0P09nXhzWgs1TBzB1WAvG9mjI+6PaW3R5p6herk4O9G2mbkK5en+yxtFoT1EU5qw5yoQvd5FbqO60/PPEXjTxc9c0rheHtcTVycCuhIv8vOeMprHUNElYhBAW4+nsyON9G/Pq7a1xt0DjLFGzSlYLrarlCUtOQRFPfb2b99eU3WnZy9VR48ggwMuZif2bADBz1SGy82+uqaMtkYRFCCEEAANa+uFk0BOXklXju3hbi9MXcxn58VZ+36futPy/Su60XBPG9QojxMeFsxn5zFsXp3U4NcZ6/gWEEEJoytPZkV5NfYHaOcoSczKNO+Zu4sCZDOoW77R8byV3Wq4Jzo4Gpt2i7jO0cGM8Cecr1sjR1knCIoQQolTJ3kK1LWH5LjqR+xZsJzWrQN1p+amq77RcE4a09qdnk7oUFJl5Y2Xt2GdIEhYhhBClBrf0x6DXcSgpg5Pns7UOp9oVmcy89ttBnv/+nzI7LQfXqfpOyzVBp9Pxn1tbY9Dr+OPAWTbHpWodUrWThEUIIUSpOm5OdG9UF7D/UZb03EIe+SyaRZuKd1oe2NRiOy3XhOYBHjzYVZ2y+u+vBygy2fc+Q5KwCCGEKGNYm+JpITvuenv8XBZ3ztvMhuKdlj+6vyNTBjezuaX4zwxuRh1XR2LPZvHV9gStw6lWkrAIIYQoI7KVuu3C3lPpnL6Yq3U4Frch9hx3fLS5zE7Lw9sGah1WlXi7OjElsjkAs6JiuZBdoHFE1UcSFiGEEGXU8zDSuaFacGpPTeQURWHRpnjGLtlBZvFOy7881atad1quCfd1DqFFgAfpuYXMiorVOpxqIwmLEEKIqwwrXi20er99TAvlF5l4YcU/vPbbQcyKupngN491o56HUevQbpqDQc8rt7UG4KvtJzlkp1srSMIihBDiKiXLm6NPXiAlI0/jaG7Oucx8Hli4neXRp0p3Wn7nXzW303JN6N64Lre0CcCsqAW49rjPkCQsQgghrhLo5UKHBt4oCvxxwHanhfadSueOuZuIPnkBD2cHFo/tzPjejexyN+qpw1pidNCz7XiaXU3llZCERQghxDUNs+EmcimZeby44h9u/2gTZ9LzCPN146eJPemn0U7LNSHEx5XH+zQC4PXfD5FXaNI4IsuShEUIIcQ1lWyGuD0+jTQbWX2SV2jio7/j6P/OOr7dmYiiwK1tA/npyZ40rqftTss1YUK/xgR6OXP6Yi4LNhzXOhyLkoRFCCHENYX4uNI6yBOTWSHqoHWPsiiKws97TjPg3XW888cRsgtMtAv24vsJ3Zl7f0er2Gm5Jrg6OTD1lpYAzFsXxxk7WpYuCYsQQohy3dJGHWVZuc96E5aYk2ncOW8Lk77dw5n0PIK8nJlzb3t+fLInnRpa735A1eW2toF0bliHvEIz/1t1WOtwLEYSFiGEEOUqWS205Vgq6bmFGkdTVmJaDhO/3sXd87eyJ/Eirk4Gnotsxtpn+3FH+/o217XWUnQ6Ha/c1hqdDn7Ze4adJ9K0DskiJGERQghRrsb13Gnm706hSWHtobNahwNARl4h/1t1mIGz1vP7P0nodDCqUwjrnuvHUwOa4uJkP8uVqyq8vhf3dg4B4NVfDmAy2/4yZ0lYhBBCXNfQ4uJbrVcLFZnMfLntJP3fWcfH649RUGSmR+O6/P7v3rz1r7b4eTprGp+1eTayOR7ODhw4k8F30Ylah3PTJGERQghxXbcUb4a4PvYcWflFmsSwPvYct3ywkek/7ed8dgGN6rmx6KFOfDW+K62CPDWJydr5uhuZNLApAO/8ccTqpvQqSxIWIYQQ19Xc34MwXzcKisz8fTilRp/76NlMHlq8g4cW7yD2bBbero68elsr/pjch4Et/e2yAZwlPdSjIY3ruXE+u4AP1x7VOpybUqWEZd68eYSFheHs7ExERAQbN24s99yxY8ei0+muurVu3br0nKVLl17znLw8224HLYQQ9kCn05UW39ZUB9XzWflM/2kfQ+dsZH3sORwNOsb1CmP9c/0Z2zMMR4P8vV0RjgY9L9/aCoClW04Ql5KlcURVV+l/8WXLljF58mSmTZvG7t276d27N8OGDSMhIeGa58+ZM4ekpKTSW2JiIj4+PowcObLMeZ6enmXOS0pKwtlZ5iOFEMIalHS9/ftISrV2UM0vMvHJ+mP0e2cdX25LwGRWGNLanz+f6cvLt7aqNf1ULKlfcz8GtvCjyKzw2m8HbXafoUonLLNmzWLcuHGMHz+eli1bMnv2bEJCQpg/f/41z/fy8iIgIKD0Fh0dzYULF3j44YfLnKfT6cqcFxAQULVXJIQQwuLa1PeivrcLOQUm1sees/j1FUXh93+SGDRrPTNXHSYzv4jWQZ5882g3PhndiTBfN4s/Z20y/dZWOBp0rI89x99HanZaz1IqlbAUFBQQExNDZGRkmeORkZFs2bKlQtdYtGgRgwYNIjQ0tMzxrKwsQkNDCQ4O5tZbb2X37t3XvU5+fj4ZGRllbkIIIaqHTqe7tLfQviSLXntP4kVGfryViV/vIjEtF39PI++ObMevT/Wie+O6Fn2u2irM141HeoYB8NpvhygoMmscUeVVKmFJTU3FZDLh7+9f5ri/vz/JyTee10xKSmLVqlWMHz++zPEWLVqwdOlSfvnlF7755hucnZ3p2bMnR4+WXyA0c+ZMvLy8Sm8hISGVeSlCCCEqaVjxaqG1h1LIL7r5aaHTF3OZ/O1uRny0meiTF3B21DNpYFP+fq4f/4oIrrWN36rLUwOa4OtuJD41myWb47UOp9KqVLV0ZVW2oigVqtReunQp3t7ejBgxoszxbt268eCDD9KuXTt69+7N8uXLadasGR9++GG515o6dSrp6emlt8RE219jLoQQ1qxDSB38PY1k5hexJe58la+TnV/Ee38eYcC76/hpzxkA7u4YzLrn+vPM4Ga4OjlYKmRxGQ9nR14Y2hyAD/+KIyXTtha2VCph8fX1xWAwXDWakpKSctWoy5UURWHx4sWMHj0aJyen6wel19O5c+frjrAYjUY8PT3L3IQQQlQfvV7HkNbF00L7Kz8tZDIrLNuZQL931/HhX3HkF5npEubDr0/14r172hHgJQstqtvdHYNpF+xFVn4R76w+onU4lVKphMXJyYmIiAiioqLKHI+KiqJHjx7Xfez69euJi4tj3LhxN3weRVHYs2cPgYGBlQlPCCFENStZ3vznwbMUmipeB7ElLpVbP9zECyv2cS4zn9C6rnz8YATLHutGm2Cv6gpXXEGv1/HK7Wpbke9iTrE38aK2AVVCpcfdpkyZwujRo+nUqRPdu3dnwYIFJCQkMGHCBECdqjl9+jSff/55mcctWrSIrl27Eh4eftU1//vf/9KtWzeaNm1KRkYGH3zwAXv27OGjjz6q4ssSQghRHbo09KGumxPnswvYfjyNXk19r3v+sXNZzFx5iDWH1JUpHs4OTBrYlDHdG+LkIL1UtNCxQR3u6lCfH3af5tVfD/DDEz1sogFfpROWUaNGcf78eWbMmEFSUhLh4eGsXLmydNVPUlLSVT1Z0tPTWbFiBXPmzLnmNS9evMhjjz1GcnIyXl5edOjQgQ0bNtClS5cqvCQhhBDVxcGgJ7K1P9/sSGTV/qRyE5YL2QXMWXuUL7edpMisYNDrGN0tlKcHNsXH7fplAaL6vTCsBasPJLM74SI/7TnNnR2CtQ7phnSKrXaQuUJGRgZeXl6kp6dLPYsQQlSj9bHneGjxDnzdjWx/aSCGy1bzFBSZ+WLbST5Ye7R075qBLfyYektLmvi5axWyuIaP/o7jnT+O4O9p5K9n++Fm1KbYuaKf3zIeJ4QQolK6N6qLp7MDqVn5xJy8AKi1h38cSCby/fW89ttB0nMLaRHgwZfjurJobGdJVqzQuF5hNPBx5WxGPvPWxWkdzg1JwiKEEKJSnBz0DG51abXQ/tPp3LdwG49/EcOJ8zn4uht56+42/P507xvWuAjtODsamD68JQALN8aTcD5H44iuTxIWIYQQlVbS9fabHQncNncT246nYXTQ81T/Jqx7vh+jOjcoM1UkrNPgVv70auJLQZGZ138/qHU41yUJixBCiErr1dQXNycDeYVmFAXuaB/EX8/147khzXHXqBZCVJ5Op+OV21ph0Ov48+BZNh1N1TqkcknCIoQQotKcHQ3MuCOc29sF8eOTPZhzbwfqe7toHZaogqb+Hozupq70/e+vByiqRH+dmiQJixBCiCq5OyKYD+7rQIcGdbQORdykZwY1o46rI0dTsvhy20mtw7kmSViEEEKIWs7L1ZFnI9V9hmZFxZKWXaBxRFeThEUIIYQQ3NelAS0CPMjIK2JWlPXtMyQJixBCCCEw6HW8WrzP0NfbEzh4JkPjiMqShEUIIYQQAHRrVJfhbQIxK2oBrjU1w5eERQghhBClpt7SAqODnu3xaazan6x1OKUkYRFCCCFEqeA6rkzo2xiAN34/RF6hSeOIVJKwCCGEEKKMCX0bE+TlzOmLuXyy/rjW4QCSsAghhBDiCi5OBqbeou4zNH99HGcu5mockSQsQgghhLiGW9sG0qWhD3mFZmauOqx1OJKwCCGEEOJqOp2O/9zWCp0Oft17hh3xaZrGIwmLEEIIIa4pvL4X93ZuAKjLnE1m7ZY5S8IihBBCiHI9F9kMD2cHDpzJ4MfdpzWLQ/YAF0IIIUS56robeWFoC1Kz8hneJlCzOCRhEUIIIcR1PdgtVOsQZEpICCGEENZPEhYhhBBCWD1JWIQQQghh9SRhEUIIIYTVk4RFCCGEEFZPEhYhhBBCWD1JWIQQQghh9SRhEUIIIYTVk4RFCCGEEFZPEhYhhBBCWD1JWIQQQghh9SRhEUIIIYTVk4RFCCGEEFbPbnZrVhQFgIyMDI0jEUIIIURFlXxul3yOl8duEpbMzEwAQkJCNI5ECCGEEJWVmZmJl5dXuT/XKTdKaWyE2WzmzJkzeHh4oNPpLHbdjIwMQkJCSExMxNPT02LXrW3kfbQMeR8tQ95Hy5D30TJq+/uoKAqZmZkEBQWh15dfqWI3Iyx6vZ7g4OBqu76np2et/A/J0uR9tAx5Hy1D3kfLkPfRMmrz+3i9kZUSUnQrhBBCCKsnCYsQQgghrJ4kLDdgNBp55ZVXMBqNWodi0+R9tAx5Hy1D3kfLkPfRMuR9rBi7KboVQgghhP2SERYhhBBCWD1JWIQQQghh9SRhEUIIIYTVk4RFCCGEEFZPEpYbmDdvHmFhYTg7OxMREcHGjRu1DsmmzJw5k86dO+Ph4YGfnx8jRozgyJEjWodl02bOnIlOp2Py5Mlah2KTTp8+zYMPPkjdunVxdXWlffv2xMTEaB2WTSkqKmL69OmEhYXh4uJCo0aNmDFjBmazWevQrNqGDRu47bbbCAoKQqfT8dNPP5X5uaIovPrqqwQFBeHi4kK/fv04cOCANsFaIUlYrmPZsmVMnjyZadOmsXv3bnr37s2wYcNISEjQOjSbsX79eiZOnMi2bduIioqiqKiIyMhIsrOztQ7NJu3cuZMFCxbQtm1brUOxSRcuXKBnz544OjqyatUqDh48yHvvvYe3t7fWodmUt956i48//pi5c+dy6NAh3n77bd555x0+/PBDrUOzatnZ2bRr1465c+de8+dvv/02s2bNYu7cuezcuZOAgAAGDx5culderaeIcnXp0kWZMGFCmWMtWrRQXnzxRY0isn0pKSkKoKxfv17rUGxOZmam0rRpUyUqKkrp27evMmnSJK1DsjkvvPCC0qtXL63DsHnDhw9XHnnkkTLH7rrrLuXBBx/UKCLbAyg//vhj6fdms1kJCAhQ/ve//5Uey8vLU7y8vJSPP/5Ygwitj4ywlKOgoICYmBgiIyPLHI+MjGTLli0aRWX70tPTAfDx8dE4EtszceJEhg8fzqBBg7QOxWb98ssvdOrUiZEjR+Ln50eHDh1YuHCh1mHZnF69erF27VpiY2MB2Lt3L5s2beKWW27RODLbFR8fT3JycpnPHKPRSN++feUzp5jdbH5oaampqZhMJvz9/csc9/f3Jzk5WaOobJuiKEyZMoVevXoRHh6udTg25dtvv2XXrl3s3LlT61Bs2vHjx5k/fz5TpkzhpZdeYseOHTz99NMYjUbGjBmjdXg244UXXiA9PZ0WLVpgMBgwmUy88cYb3HfffVqHZrNKPleu9Zlz8uRJLUKyOpKw3IBOpyvzvaIoVx0TFfPUU0/xzz//sGnTJq1DsSmJiYlMmjSJP//8E2dnZ63DsWlms5lOnTrx5ptvAtChQwcOHDjA/PnzJWGphGXLlvHll1/y9ddf07p1a/bs2cPkyZMJCgrioYce0jo8myafOeWThKUcvr6+GAyGq0ZTUlJSrsqAxY39+9//5pdffmHDhg0EBwdrHY5NiYmJISUlhYiIiNJjJpOJDRs2MHfuXPLz8zEYDBpGaDsCAwNp1apVmWMtW7ZkxYoVGkVkm55//nlefPFF7r33XgDatGnDyZMnmTlzpiQsVRQQEACoIy2BgYGlx+Uz5xKpYSmHk5MTERERREVFlTkeFRVFjx49NIrK9iiKwlNPPcUPP/zAX3/9RVhYmNYh2ZyBAweyb98+9uzZU3rr1KkTDzzwAHv27JFkpRJ69ux51bL62NhYQkNDNYrINuXk5KDXl/34MBgMsqz5JoSFhREQEFDmM6egoID169fLZ04xGWG5jilTpjB69Gg6depE9+7dWbBgAQkJCUyYMEHr0GzGxIkT+frrr/n555/x8PAoHbHy8vLCxcVF4+hsg4eHx1U1P25ubtStW1dqgSrpmWeeoUePHrz55pvcc8897NixgwULFrBgwQKtQ7Mpt912G2+88QYNGjSgdevW7N69m1mzZvHII49oHZpVy8rKIi4urvT7+Ph49uzZg4+PDw0aNGDy5Mm8+eabNG3alKZNm/Lmm2/i6urK/fffr2HUVkTbRUrW76OPPlJCQ0MVJycnpWPHjrIct5KAa96WLFmidWg2TZY1V92vv/6qhIeHK0ajUWnRooWyYMECrUOyORkZGcqkSZOUBg0aKM7OzkqjRo2UadOmKfn5+VqHZtX+/vvva/4+fOihhxRFUZc2v/LKK0pAQIBiNBqVPn36KPv27dM2aCuiUxRF0ShXEkIIIYSoEKlhEUIIIYTVk4RFCCGEEFZPEhYhhBBCWD1JWIQQQghh9SRhEUIIIYTVk4RFCCGEEFZPEhYhhBBCWD1JWIQQQghh9SRhEUIIIYTVk4RFCCGEEFZPEhYhhBBCWD1JWIQQQghh9f4fFtXFYYcmbwoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# writing a function to transform the time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "   n_vars = 1 if isinstance(data, list) else data.shape[1]\n",
    "   df = DataFrame(data)\n",
    "   cols = list()\n",
    "   for i in range(n_in, 0, -1):\n",
    "       cols.append(df.shift(i))\n",
    "   for i in range(0, n_out):\n",
    "       cols.append(df.shift(-i))\n",
    "   agg = concat(cols, axis=1)\n",
    "   if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "   return agg.values\n",
    "\n",
    "# This function will split a dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "   return data[:-n_test, :], data[-n_test:, :]\n",
    "\n",
    "# This function will fit a random forest model and make a one-step prediction\n",
    "def random_forest_forecast(train, testX):\n",
    "   train = np.array(train)\n",
    "   trainX, trainy = train[:, :-1], train[:, -1]\n",
    "   model = RandomForestRegressor(n_estimators=100)\n",
    "   model.fit(trainX, trainy)\n",
    "   yhat = model.predict([testX])\n",
    "   return yhat[0]\n",
    "\n",
    "\n",
    "# This funtion we will use for walk forward validation\n",
    "def walk_forward_validation(data, n_test):\n",
    "   predictions = list()\n",
    "   train, test = train_test_split(data, n_test)\n",
    "   history = [x for x in train]\n",
    "   for i in range(len(test)):\n",
    "       testX, testy = test[i, :-1], test[i, -1]\n",
    "       yhat = random_forest_forecast(history, testX)\n",
    "       predictions.append(yhat)\n",
    "       history.append(test[i])\n",
    "       print('>expected=%.4f, predicted=%.4f' % (testy, yhat))\n",
    "   error = mean_absolute_error(test[:, -1], predictions)\n",
    "   return error, test[:, -1], predictions\n",
    "\n",
    "# Now, we will transform the time series data into supervised learning\n",
    "values = features_array.reshape(-1, 1)\n",
    "features_array = series_to_supervised(values, n_in=12)\n",
    "\n",
    "# Lets evaluate the model using walk-forward validation\n",
    "mae, y, yhat = walk_forward_validation(features_array, 12)\n",
    "print('MAE: %.3f' % mae)\n",
    "print('RMSE: %.3f' % rmse)\n",
    "# Finally visualize the expected vs predicted values\n",
    "pyplot.plot(y, label='Expected')\n",
    "pyplot.plot(yhat, label='Predicted')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a Random Forest Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the features3 data into target and features\n",
    "X = features3[['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed']]\n",
    "y = features3['wait_assessment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the train_test_split function\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.014\n",
      "Root Mean Squared Error: 0.017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the random forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Mean Absolute Error: {mae:.3f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Assuming X_train is a DataFrame\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Get the unique feature names and their corresponding importances\n",
    "unique_feature_names, unique_importances = [], []\n",
    "\n",
    "for name in set(feature_names):\n",
    "    indices = [i for i, x in enumerate(feature_names) if x == name]\n",
    "    unique_feature_names.append(name)\n",
    "    unique_importances.append(sum(feature_importances[indices]))\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "unique_feature_names = np.array(unique_feature_names)\n",
    "unique_importances = np.array(unique_importances)\n",
    "\n",
    "# Get the top ten indices\n",
    "top_ten_idx = np.argsort(unique_importances)[-10:]\n",
    "\n",
    "# Create a bar plot of the top ten feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Top 10 Feature Importances (Aggregated)')\n",
    "plt.barh(range(len(top_ten_idx)), unique_importances[top_ten_idx], align='center')\n",
    "plt.yticks(range(len(top_ten_idx)), unique_feature_names[top_ten_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the variables in the features2 dataframe\n",
    "features3_scaled = scaler.fit_transform(features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   wait_assessment  vehicle_count_automated_traffic_volume_counts  \\\n",
      "0        -0.503568                                      -0.266022   \n",
      "1        -2.897123                                      -0.577774   \n",
      "2        -2.596466                                       0.665941   \n",
      "3        -0.175238                                       0.780707   \n",
      "4        -0.115008                                       1.440517   \n",
      "\n",
      "   average_percipitation  avg_temp  vc_rating  ap_rating  at_rating      Year  \\\n",
      "0               0.420373 -1.736613  -0.535477   0.973417  -0.535477 -1.549193   \n",
      "1              -0.947106 -2.125878  -0.535477  -0.572598  -0.535477 -1.549193   \n",
      "2               0.146877 -1.204618   0.986405  -0.572598  -0.535477 -1.549193   \n",
      "3              -0.947106 -0.153603   0.986405  -0.572598  -0.535477 -1.549193   \n",
      "4              -1.083853  0.767656   2.508287  -0.572598  -0.535477 -1.549193   \n",
      "\n",
      "      Month  Is_quarter_start  Is_year_start   Elapsed  \n",
      "0 -1.593255          1.414214       3.316625 -1.715497  \n",
      "1 -1.303572         -0.707107      -0.301511 -1.682827  \n",
      "2 -1.013890         -0.707107      -0.301511 -1.653318  \n",
      "3 -0.724207          1.414214      -0.301511 -1.620648  \n",
      "4 -0.434524         -0.707107      -0.301511 -1.589032  \n"
     ]
    }
   ],
   "source": [
    "# Create a new dataframe with the standardized variables\n",
    "features3_standardized = pd.DataFrame(features3_scaled, columns = features3.columns)\n",
    "\n",
    "# Print the first few rows of the standardized dataframe\n",
    "print(features3_standardized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features3_standardized.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the features3 data into target and features\n",
    "X = features3_standardized[['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed']]\n",
    "y = features3_standardized['wait_assessment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.56\n",
      "Root Mean Squared Error: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the random forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Assuming X_train is a DataFrame\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Get the unique feature names and their corresponding importances\n",
    "unique_feature_names, unique_importances = [], []\n",
    "\n",
    "for name in set(feature_names):\n",
    "    indices = [i for i, x in enumerate(feature_names) if x == name]\n",
    "    unique_feature_names.append(name)\n",
    "    unique_importances.append(sum(feature_importances[indices]))\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "unique_feature_names = np.array(unique_feature_names)\n",
    "unique_importances = np.array(unique_importances)\n",
    "\n",
    "# Get the top ten indices\n",
    "top_ten_idx = np.argsort(unique_importances)[-10:]\n",
    "\n",
    "# Create a bar plot of the top ten feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Top 10 Feature Importances (Aggregated)')\n",
    "plt.barh(range(len(top_ten_idx)), unique_importances[top_ten_idx], align='center')\n",
    "plt.yticks(range(len(top_ten_idx)), unique_feature_names[top_ten_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the features3 data into target and features\n",
    "X = features3_standardized[['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed']]\n",
    "y = features3_standardized['wait_assessment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Mean Absolute Error: 0.57\n",
      "Root Mean Squared Error: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:542: FitFailedWarning: \n",
      "1665 fits failed out of a total of 2880.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_leaf' parameter of RandomForestRegressor must be an int in the range [1, inf) or a float in the range (0.0, 1.0). Got None instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "405 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got None instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.60791902 -0.60150411 -0.60376616\n",
      " -0.60537928 -0.59954191 -0.59887002 -0.59856487 -0.59803824 -0.59602921\n",
      "         nan         nan         nan -0.58851434 -0.58828676 -0.589167\n",
      " -0.58900804 -0.58902042 -0.58996193 -0.58919913 -0.59340379 -0.593632\n",
      "         nan         nan         nan -0.60942908 -0.61170278 -0.60949921\n",
      " -0.60942908 -0.61170278 -0.60949921 -0.60983802 -0.61117847 -0.61005312\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.58842835 -0.58597635 -0.58760716\n",
      " -0.57533808 -0.57773937 -0.58263034 -0.58679236 -0.58735512 -0.58952918\n",
      "         nan         nan         nan -0.5964329  -0.5973283  -0.59521494\n",
      " -0.59438875 -0.59396956 -0.5950892  -0.59947778 -0.60376536 -0.60397484\n",
      "         nan         nan         nan -0.61578977 -0.61905281 -0.62274889\n",
      " -0.61578977 -0.61905281 -0.62274889 -0.61762694 -0.62290885 -0.6250457\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.58842835 -0.58597635 -0.58760716\n",
      " -0.57533808 -0.57773937 -0.58263034 -0.58679236 -0.58735512 -0.58952918\n",
      "         nan         nan         nan -0.5964329  -0.5973283  -0.59521494\n",
      " -0.59438875 -0.59396956 -0.5950892  -0.59947778 -0.60376536 -0.60397484\n",
      "         nan         nan         nan -0.61578977 -0.61905281 -0.62274889\n",
      " -0.61578977 -0.61905281 -0.62274889 -0.61762694 -0.62290885 -0.6250457\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.60136774 -0.59692843 -0.59658731\n",
      " -0.59799198 -0.59636945 -0.59535303 -0.59680009 -0.59874632 -0.59581834\n",
      "         nan         nan         nan -0.58491982 -0.58797451 -0.58859109\n",
      " -0.58375792 -0.58872471 -0.58968933 -0.59058222 -0.59587574 -0.59586978\n",
      "         nan         nan         nan -0.61056676 -0.6126856  -0.61066466\n",
      " -0.61056676 -0.6126856  -0.61066466 -0.60991053 -0.6118685  -0.6107306\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.59652342 -0.59200999 -0.59891294\n",
      " -0.59203088 -0.59511634 -0.59455279 -0.59357536 -0.59540818 -0.59608256\n",
      "         nan         nan         nan -0.60597346 -0.60385328 -0.60465792\n",
      " -0.60259893 -0.6043114  -0.6073945  -0.60601106 -0.60961753 -0.60967312\n",
      "         nan         nan         nan -0.61491518 -0.61706983 -0.62185929\n",
      " -0.61491518 -0.61706983 -0.62185929 -0.61710843 -0.62232614 -0.62473595\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.59652342 -0.59200999 -0.59891294\n",
      " -0.59203088 -0.59511634 -0.59455279 -0.59357536 -0.59540818 -0.59608256\n",
      "         nan         nan         nan -0.60597346 -0.60385328 -0.60465792\n",
      " -0.60259893 -0.6043114  -0.6073945  -0.60601106 -0.60961753 -0.60967312\n",
      "         nan         nan         nan -0.61491518 -0.61706983 -0.62185929\n",
      " -0.61491518 -0.61706983 -0.62185929 -0.61710843 -0.62232614 -0.62473595\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.60870156 -0.60228172 -0.60330454\n",
      " -0.60621957 -0.5999716  -0.59944517 -0.59880992 -0.5982225  -0.59615286\n",
      "         nan         nan         nan -0.58836472 -0.58807986 -0.58892991\n",
      " -0.589117   -0.58899521 -0.58993257 -0.58919913 -0.59340379 -0.593632\n",
      "         nan         nan         nan -0.60942908 -0.61170278 -0.60949921\n",
      " -0.60942908 -0.61170278 -0.60949921 -0.60983802 -0.61117847 -0.61005312\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.59056728 -0.58772113 -0.5924102\n",
      " -0.57683535 -0.57871046 -0.58319389 -0.58620187 -0.58704271 -0.58924754\n",
      "         nan         nan         nan -0.59692439 -0.59754601 -0.59501127\n",
      " -0.59474838 -0.59440432 -0.59543225 -0.599457   -0.60375498 -0.60398134\n",
      "         nan         nan         nan -0.61578977 -0.61905281 -0.62274889\n",
      " -0.61578977 -0.61905281 -0.62274889 -0.61762694 -0.62290885 -0.6250457\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.59056728 -0.58772113 -0.5924102\n",
      " -0.57683535 -0.57871046 -0.58319389 -0.58620187 -0.58704271 -0.58924754\n",
      "         nan         nan         nan -0.59692439 -0.59754601 -0.59501127\n",
      " -0.59474838 -0.59440432 -0.59543225 -0.599457   -0.60375498 -0.60398134\n",
      "         nan         nan         nan -0.61578977 -0.61905281 -0.62274889\n",
      " -0.61578977 -0.61905281 -0.62274889 -0.61762694 -0.62290885 -0.6250457 ]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [None,2, 5, 10],\n",
    "    'min_samples_leaf': [None,1, 2, 4],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create the random forest model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the features3 data into target and features\n",
    "X = features3_standardized[['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed']]\n",
    "y = features3_standardized['wait_assessment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.57\n",
      "Root Mean Squared Error: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the random forest model with specified hyperparameters\n",
    "model = RandomForestRegressor(\n",
    "    max_depth=None,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Assuming X_train is a DataFrame\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Get the unique feature names and their corresponding importances\n",
    "unique_feature_names, unique_importances = [], []\n",
    "\n",
    "for name in set(feature_names):\n",
    "    indices = [i for i, x in enumerate(feature_names) if x == name]\n",
    "    unique_feature_names.append(name)\n",
    "    unique_importances.append(sum(feature_importances[indices]))\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "unique_feature_names = np.array(unique_feature_names)\n",
    "unique_importances = np.array(unique_importances)\n",
    "\n",
    "# Get the top ten indices\n",
    "top_ten_idx = np.argsort(unique_importances)[-10:]\n",
    "\n",
    "# Create a bar plot of the top ten feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Top 10 Feature Importances (Aggregated)')\n",
    "plt.barh(range(len(top_ten_idx)), unique_importances[top_ten_idx], align='center')\n",
    "plt.yticks(range(len(top_ten_idx)), unique_feature_names[top_ten_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Hybrid Model using the Random Forest and Sarimax Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the Residuals and append to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features3_standardized.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = results1.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the residuals\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(residuals, color=\"blue\")\n",
    "plt.title(\"Residuals Plot\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the indices\n",
    "print(residuals.index)\n",
    "print(features3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the index to a datetime index starting from 2015-01-01\n",
    "features3.index = pd.date_range(start='2015-01-01', freq='M', periods=len(features3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add residuals to the DataFrame\n",
    "features3['sarimax_residuals'] = residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features3.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the numerical features in the features3 dataframe using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the variables in the features2 dataframe\n",
    "features3_scaled = scaler.fit_transform(features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   wait_assessment  vehicle_count_automated_traffic_volume_counts  \\\n",
      "0        -0.503568                                      -0.266022   \n",
      "1        -2.897123                                      -0.577774   \n",
      "2        -2.596466                                       0.665941   \n",
      "3        -0.175238                                       0.780707   \n",
      "4        -0.115008                                       1.440517   \n",
      "\n",
      "   average_percipitation  avg_temp  vc_rating  ap_rating  at_rating      Year  \\\n",
      "0               0.420373 -1.736613  -0.535477   0.973417  -0.535477 -1.549193   \n",
      "1              -0.947106 -2.125878  -0.535477  -0.572598  -0.535477 -1.549193   \n",
      "2               0.146877 -1.204618   0.986405  -0.572598  -0.535477 -1.549193   \n",
      "3              -0.947106 -0.153603   0.986405  -0.572598  -0.535477 -1.549193   \n",
      "4              -1.083853  0.767656   2.508287  -0.572598  -0.535477 -1.549193   \n",
      "\n",
      "      Month  Is_quarter_start  Is_year_start   Elapsed  sarimax_residuals  \n",
      "0 -1.593255          1.414214       3.316625 -1.715497           1.312555  \n",
      "1 -1.303572         -0.707107      -0.301511 -1.682827          -2.514065  \n",
      "2 -1.013890         -0.707107      -0.301511 -1.653318          -0.529146  \n",
      "3 -0.724207          1.414214      -0.301511 -1.620648           1.696312  \n",
      "4 -0.434524         -0.707107      -0.301511 -1.589032          -0.905341  \n"
     ]
    }
   ],
   "source": [
    "# Create a new dataframe with the standardized variables\n",
    "features3_standardized = pd.DataFrame(features3_scaled, columns = features3.columns)\n",
    "\n",
    "# Print the first few rows of the standardized dataframe\n",
    "print(features3_standardized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wait_assessment</th>\n",
       "      <th>vehicle_count_automated_traffic_volume_counts</th>\n",
       "      <th>average_percipitation</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>vc_rating</th>\n",
       "      <th>ap_rating</th>\n",
       "      <th>at_rating</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Is_quarter_start</th>\n",
       "      <th>Is_year_start</th>\n",
       "      <th>Elapsed</th>\n",
       "      <th>sarimax_residuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.080000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-7.923703e-15</td>\n",
       "      <td>-1.089663e-16</td>\n",
       "      <td>-2.055969e-16</td>\n",
       "      <td>9.046262e-17</td>\n",
       "      <td>-4.934325e-17</td>\n",
       "      <td>-1.161622e-16</td>\n",
       "      <td>-7.401487e-17</td>\n",
       "      <td>-1.644775e-17</td>\n",
       "      <td>1.439178e-17</td>\n",
       "      <td>7.401487e-17</td>\n",
       "      <td>-1.027984e-18</td>\n",
       "      <td>2.672759e-17</td>\n",
       "      <td>-2.775558e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.004662e+00</td>\n",
       "      <td>1.004662e+00</td>\n",
       "      <td>1.004662e+00</td>\n",
       "      <td>1.004662e+00</td>\n",
       "      <td>1.004662e+00</td>\n",
       "      <td>1.004662e+00</td>\n",
       "      <td>1.004662e+00</td>\n",
       "      <td>1.004662e+00</td>\n",
       "      <td>1.004662e+00</td>\n",
       "      <td>1.004662e+00</td>\n",
       "      <td>1.004662e+00</td>\n",
       "      <td>1.004662e+00</td>\n",
       "      <td>1.004662e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.897123e+00</td>\n",
       "      <td>-8.288539e-01</td>\n",
       "      <td>-1.494097e+00</td>\n",
       "      <td>-2.125878e+00</td>\n",
       "      <td>-5.354769e-01</td>\n",
       "      <td>-5.725983e-01</td>\n",
       "      <td>-5.354769e-01</td>\n",
       "      <td>-1.549193e+00</td>\n",
       "      <td>-1.593255e+00</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-3.015113e-01</td>\n",
       "      <td>-1.715497e+00</td>\n",
       "      <td>-2.883059e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.830801e-01</td>\n",
       "      <td>-7.314700e-01</td>\n",
       "      <td>-6.736099e-01</td>\n",
       "      <td>-8.786088e-01</td>\n",
       "      <td>-5.354769e-01</td>\n",
       "      <td>-5.725983e-01</td>\n",
       "      <td>-5.354769e-01</td>\n",
       "      <td>-7.745967e-01</td>\n",
       "      <td>-7.966275e-01</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-3.015113e-01</td>\n",
       "      <td>-8.584315e-01</td>\n",
       "      <td>-5.586267e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.025821e-02</td>\n",
       "      <td>-2.750752e-01</td>\n",
       "      <td>-1.266184e-01</td>\n",
       "      <td>4.751672e-02</td>\n",
       "      <td>-5.354769e-01</td>\n",
       "      <td>-5.725983e-01</td>\n",
       "      <td>-5.354769e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-3.015113e-01</td>\n",
       "      <td>-8.391982e-04</td>\n",
       "      <td>-7.718029e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.329667e-01</td>\n",
       "      <td>2.736806e-01</td>\n",
       "      <td>4.203731e-01</td>\n",
       "      <td>9.460693e-01</td>\n",
       "      <td>-1.550065e-01</td>\n",
       "      <td>9.734172e-01</td>\n",
       "      <td>-1.550065e-01</td>\n",
       "      <td>7.745967e-01</td>\n",
       "      <td>7.966275e-01</td>\n",
       "      <td>1.414214e+00</td>\n",
       "      <td>-3.015113e-01</td>\n",
       "      <td>8.585974e-01</td>\n",
       "      <td>5.289874e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.256682e+00</td>\n",
       "      <td>3.904892e+00</td>\n",
       "      <td>4.659557e+00</td>\n",
       "      <td>1.513747e+00</td>\n",
       "      <td>2.508287e+00</td>\n",
       "      <td>2.519433e+00</td>\n",
       "      <td>2.508287e+00</td>\n",
       "      <td>1.549193e+00</td>\n",
       "      <td>1.593255e+00</td>\n",
       "      <td>1.414214e+00</td>\n",
       "      <td>3.316625e+00</td>\n",
       "      <td>1.715926e+00</td>\n",
       "      <td>3.722251e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wait_assessment  vehicle_count_automated_traffic_volume_counts  \\\n",
       "count     1.080000e+02                                   1.080000e+02   \n",
       "mean     -7.923703e-15                                  -1.089663e-16   \n",
       "std       1.004662e+00                                   1.004662e+00   \n",
       "min      -2.897123e+00                                  -8.288539e-01   \n",
       "25%      -4.830801e-01                                  -7.314700e-01   \n",
       "50%       5.025821e-02                                  -2.750752e-01   \n",
       "75%       7.329667e-01                                   2.736806e-01   \n",
       "max       2.256682e+00                                   3.904892e+00   \n",
       "\n",
       "       average_percipitation      avg_temp     vc_rating     ap_rating  \\\n",
       "count           1.080000e+02  1.080000e+02  1.080000e+02  1.080000e+02   \n",
       "mean           -2.055969e-16  9.046262e-17 -4.934325e-17 -1.161622e-16   \n",
       "std             1.004662e+00  1.004662e+00  1.004662e+00  1.004662e+00   \n",
       "min            -1.494097e+00 -2.125878e+00 -5.354769e-01 -5.725983e-01   \n",
       "25%            -6.736099e-01 -8.786088e-01 -5.354769e-01 -5.725983e-01   \n",
       "50%            -1.266184e-01  4.751672e-02 -5.354769e-01 -5.725983e-01   \n",
       "75%             4.203731e-01  9.460693e-01 -1.550065e-01  9.734172e-01   \n",
       "max             4.659557e+00  1.513747e+00  2.508287e+00  2.519433e+00   \n",
       "\n",
       "          at_rating          Year         Month  Is_quarter_start  \\\n",
       "count  1.080000e+02  1.080000e+02  1.080000e+02      1.080000e+02   \n",
       "mean  -7.401487e-17 -1.644775e-17  1.439178e-17      7.401487e-17   \n",
       "std    1.004662e+00  1.004662e+00  1.004662e+00      1.004662e+00   \n",
       "min   -5.354769e-01 -1.549193e+00 -1.593255e+00     -7.071068e-01   \n",
       "25%   -5.354769e-01 -7.745967e-01 -7.966275e-01     -7.071068e-01   \n",
       "50%   -5.354769e-01  0.000000e+00  0.000000e+00     -7.071068e-01   \n",
       "75%   -1.550065e-01  7.745967e-01  7.966275e-01      1.414214e+00   \n",
       "max    2.508287e+00  1.549193e+00  1.593255e+00      1.414214e+00   \n",
       "\n",
       "       Is_year_start       Elapsed  sarimax_residuals  \n",
       "count   1.080000e+02  1.080000e+02       1.080000e+02  \n",
       "mean   -1.027984e-18  2.672759e-17      -2.775558e-17  \n",
       "std     1.004662e+00  1.004662e+00       1.004662e+00  \n",
       "min    -3.015113e-01 -1.715497e+00      -2.883059e+00  \n",
       "25%    -3.015113e-01 -8.584315e-01      -5.586267e-01  \n",
       "50%    -3.015113e-01 -8.391982e-04      -7.718029e-02  \n",
       "75%    -3.015113e-01  8.585974e-01       5.289874e-01  \n",
       "max     3.316625e+00  1.715926e+00       3.722251e+00  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the index to a datetime index starting from 2015-01-01\n",
    "features3_standardized.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a Random Forest Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the features3 data into target and features\n",
    "X = features3_standardized[['vehicle_count_automated_traffic_volume_counts','average_percipitation','avg_temp','vc_rating', 'ap_rating', 'at_rating','Year','Month','Is_quarter_start','Is_year_start','Elapsed', 'sarimax_residuals']]\n",
    "y = features3_standardized['wait_assessment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.50\n",
      "Root Mean Squared Error: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the random forest model with specified hyperparameters\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual vs. predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the residuals\n",
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Get the top ten indices\n",
    "top_ten_idx = np.argsort(feature_importances)[-10:]\n",
    "\n",
    "# Create a bar plot of the top ten feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.barh(range(len(top_ten_idx)), feature_importances[top_ten_idx], align='center')\n",
    "plt.yticks(range(len(top_ten_idx)), feature_names[top_ten_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'max_depth': None, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Mean Absolute Error: 0.49\n",
      "Root Mean Squared Error: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:542: FitFailedWarning: \n",
      "1665 fits failed out of a total of 2880.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_leaf' parameter of RandomForestRegressor must be an int in the range [1, inf) or a float in the range (0.0, 1.0). Got None instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "405 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got None instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.55105209 -0.56126255 -0.56166389\n",
      " -0.55727004 -0.56545178 -0.56670236 -0.57133386 -0.57944748 -0.57840875\n",
      "         nan         nan         nan -0.53984498 -0.54856627 -0.5517359\n",
      " -0.54070828 -0.54930447 -0.55292311 -0.55762105 -0.56905752 -0.57095813\n",
      "         nan         nan         nan -0.57406856 -0.58117962 -0.58191887\n",
      " -0.57406856 -0.58117962 -0.58191887 -0.58226709 -0.5880177  -0.58805208\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.55420605 -0.55861931 -0.56284532\n",
      " -0.55082958 -0.55732918 -0.56357662 -0.56691483 -0.5719189  -0.57617855\n",
      "         nan         nan         nan -0.5755222  -0.58209993 -0.58476252\n",
      " -0.57335351 -0.57825762 -0.58467512 -0.58840577 -0.5887619  -0.59216841\n",
      "         nan         nan         nan -0.60944634 -0.6158303  -0.61577515\n",
      " -0.60944634 -0.6158303  -0.61577515 -0.61470372 -0.61901038 -0.6177476\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.55420605 -0.55861931 -0.56284532\n",
      " -0.55082958 -0.55732918 -0.56357662 -0.56691483 -0.5719189  -0.57617855\n",
      "         nan         nan         nan -0.5755222  -0.58209993 -0.58476252\n",
      " -0.57335351 -0.57825762 -0.58467512 -0.58840577 -0.5887619  -0.59216841\n",
      "         nan         nan         nan -0.60944634 -0.6158303  -0.61577515\n",
      " -0.60944634 -0.6158303  -0.61577515 -0.61470372 -0.61901038 -0.6177476\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.55834127 -0.56805574 -0.5677736\n",
      " -0.56431071 -0.57267346 -0.57281404 -0.57541562 -0.58424823 -0.58201923\n",
      "         nan         nan         nan -0.54899501 -0.55731507 -0.56100316\n",
      " -0.54913827 -0.55876041 -0.56242037 -0.56316911 -0.5756564  -0.57685785\n",
      "         nan         nan         nan -0.57556538 -0.58266467 -0.58415683\n",
      " -0.57556538 -0.58266467 -0.58415683 -0.58260136 -0.58904637 -0.58943586\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.56874767 -0.57780736 -0.57797422\n",
      " -0.57284863 -0.57372673 -0.57863142 -0.58800188 -0.58849368 -0.58961698\n",
      "         nan         nan         nan -0.59086849 -0.59494378 -0.5987768\n",
      " -0.59099872 -0.5929768  -0.59727222 -0.60139635 -0.59926389 -0.60100389\n",
      "         nan         nan         nan -0.6134853  -0.61999942 -0.61877412\n",
      " -0.6134853  -0.61999942 -0.61877412 -0.61609416 -0.62014679 -0.61920306\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.56874767 -0.57780736 -0.57797422\n",
      " -0.57284863 -0.57372673 -0.57863142 -0.58800188 -0.58849368 -0.58961698\n",
      "         nan         nan         nan -0.59086849 -0.59494378 -0.5987768\n",
      " -0.59099872 -0.5929768  -0.59727222 -0.60139635 -0.59926389 -0.60100389\n",
      "         nan         nan         nan -0.6134853  -0.61999942 -0.61877412\n",
      " -0.6134853  -0.61999942 -0.61877412 -0.61609416 -0.62014679 -0.61920306\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.55038547 -0.56204732 -0.5618952\n",
      " -0.55820293 -0.56611803 -0.56718159 -0.57130158 -0.57947596 -0.57841469\n",
      "         nan         nan         nan -0.54041904 -0.54876527 -0.55192692\n",
      " -0.54061694 -0.54913509 -0.55282883 -0.55764549 -0.56906974 -0.57096628\n",
      "         nan         nan         nan -0.57406856 -0.58117962 -0.58191887\n",
      " -0.57406856 -0.58117962 -0.58191887 -0.58226709 -0.5880177  -0.58805208\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.55739424 -0.55932213 -0.56318198\n",
      " -0.55057308 -0.55907131 -0.56479018 -0.5665387  -0.57210016 -0.57619934\n",
      "         nan         nan         nan -0.57299017 -0.58081427 -0.58387524\n",
      " -0.57292414 -0.57793829 -0.58401859 -0.58836908 -0.58863694 -0.59208511\n",
      "         nan         nan         nan -0.60944634 -0.6158303  -0.61577515\n",
      " -0.60944634 -0.6158303  -0.61577515 -0.61470372 -0.61901038 -0.6177476\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.55739424 -0.55932213 -0.56318198\n",
      " -0.55057308 -0.55907131 -0.56479018 -0.5665387  -0.57210016 -0.57619934\n",
      "         nan         nan         nan -0.57299017 -0.58081427 -0.58387524\n",
      " -0.57292414 -0.57793829 -0.58401859 -0.58836908 -0.58863694 -0.59208511\n",
      "         nan         nan         nan -0.60944634 -0.6158303  -0.61577515\n",
      " -0.60944634 -0.6158303  -0.61577515 -0.61470372 -0.61901038 -0.6177476 ]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [None, 2, 5, 10],\n",
    "    'min_samples_leaf': [None, 1, 2, 4],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create the random forest model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.49\n",
      "Root Mean Squared Error: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the random forest model with specified hyperparameters\n",
    "model = RandomForestRegressor(\n",
    "    max_depth= None,\n",
    "    max_features= None,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual vs. predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the residuals\n",
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Get the top ten indices\n",
    "top_ten_idx = np.argsort(feature_importances)[-10:]\n",
    "\n",
    "# Create a bar plot of the top ten feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.barh(range(len(top_ten_idx)), feature_importances[top_ten_idx], align='center')\n",
    "plt.yticks(range(len(top_ten_idx)), feature_names[top_ten_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Multiple Route Models and Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the Delay Data needed for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the delays dataframe\n",
    "delays.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Join the weather_features and traffic_features dataframes together\n",
    "weather_traffic_features = pd.merge(weather_features, traffic_features, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime data type\n",
    "delays['date'] = pd.to_datetime(delays['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime format\n",
    "weather_traffic_features['date'] = pd.to_datetime(weather_traffic_features['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Join the delays and weather_traffic_features dataframes together\n",
    "delays_features = pd.merge(delays, weather_traffic_features, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the weather_traffic_features dataframe\n",
    "print(delays_features.shape)\n",
    "\n",
    "# Describe the weather_traffic_features dataframe\n",
    "delays_features.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BX1', 'Q104', 'M8', 'M9', 'M96', 'SBS15', 'SBS60', 'Q1', 'Q10', 'Q100',\n",
       "       ...\n",
       "       'B49', 'BX24', 'BX26', 'B52', 'B54', 'B57', 'B6', 'B60', 'B61', 'BX23'],\n",
       "      dtype='object', length=201)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a value count of the route_id column\n",
    "delays_features[\"route_id\"].value_counts()\n",
    "\n",
    "# List the route_id values that have 432 rows\n",
    "delays_features[\"route_id\"].value_counts().index[delays_features[\"route_id\"].value_counts() == 432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a route specific dataframe for the BX26 route\n",
    "delays_bx26 = delays_features[delays_features[\"route_id\"] == \"BX26\"]\n",
    "\n",
    "delays_bx26.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of the route_id values that have 432 rows\n",
    "route_ids = delays_features[\"route_id\"].value_counts().index[delays_features[\"route_id\"].value_counts() == 432].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Valid Combinations of Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with only the route_id values that have 432 rows based on the route_ids list\n",
    "delays_features_432 = delays_features[delays_features[\"route_id\"].isin(route_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_10744\\1018092786.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  delays_features_432[\"date\"] = pd.to_datetime(delays_features_432[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "# Convert the date column to a datetime data type\n",
    "delays_features_432[\"date\"] = pd.to_datetime(delays_features_432[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Group the data by the route_id and date columns and take the mean of the wait_assessment column\n",
    "delays_features_432 = delays_features_432.groupby([\"route_id\", \"date\"]).agg({\"wait_assessment\": \"mean\", \"average_percipitation\": \"mean\", \"avg_temp\": \"mean\",\"vehicle_count_automated_traffic_volume_counts\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of the route_id values that don't have 108 rows\n",
    "route_ids2 = delays_features_432[\"route_id\"].value_counts().index[delays_features_432[\"route_id\"].value_counts() != 108].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X27']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_ids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the route_id values that don't have 108 rows\n",
    "delays_features_432 = delays_features_432[~delays_features_432[\"route_id\"].isin(route_ids2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime data type\n",
    "delays_features_432[\"date\"] = pd.to_datetime(delays_features_432[\"date\"])\n",
    "\n",
    "# Set the date column as the index\n",
    "delays_features_432 = delays_features_432.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "filtered_df = delays_features_432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the size of each group\n",
    "group_sizes = filtered_df.groupby(['route_id']).size().reset_index(name='group_size')\n",
    "\n",
    "# Filter groupings with 108 rows\n",
    "valid_groups = group_sizes[group_sizes['group_size'] == 108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Merge with the original DataFrame to get the rows from valid groups\n",
    "filtered_df = pd.merge(filtered_df, valid_groups[['route_id']], on=['route_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Get a list of every route id\n",
    "route_ids = filtered_df['route_id'].unique()\n",
    "\n",
    "# Create a rolling mean diff column for each route id to ensure the time series is stationary\n",
    "for route_id in route_ids:\n",
    "    data = filtered_df[filtered_df['route_id'] == route_id].copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "    rolling_mean = data['wait_assessment'].rolling(window=12, min_periods=1).mean()  # Calculate rolling mean with min_periods=1 to handle NaNs\n",
    "    data['rolling_mean_diff'] = rolling_mean.diff()  # Calculate the difference between consecutive rolling mean values\n",
    "    data['rolling_mean_diff'] = data['rolling_mean_diff'].fillna(data['rolling_mean_diff'].mean())\n",
    "    filtered_df.loc[filtered_df['route_id'] == route_id, 'rolling_mean_diff'] = data['rolling_mean_diff']  # Assign the result back to the original DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_10744\\97953279.py:4: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  filtered_df.describe(include=\"all\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>date</th>\n",
       "      <th>wait_assessment</th>\n",
       "      <th>average_percipitation</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>vehicle_count_automated_traffic_volume_counts</th>\n",
       "      <th>rolling_mean_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21600</td>\n",
       "      <td>21600</td>\n",
       "      <td>2.160000e+04</td>\n",
       "      <td>2.160000e+04</td>\n",
       "      <td>2.160000e+04</td>\n",
       "      <td>2.160000e+04</td>\n",
       "      <td>2.160000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>200</td>\n",
       "      <td>108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>B1</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>108</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.631617e-16</td>\n",
       "      <td>1.553490e-16</td>\n",
       "      <td>1.049366e-16</td>\n",
       "      <td>1.672736e-16</td>\n",
       "      <td>2.631640e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000023e+00</td>\n",
       "      <td>1.000023e+00</td>\n",
       "      <td>1.000023e+00</td>\n",
       "      <td>1.000023e+00</td>\n",
       "      <td>1.000023e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.898618e+00</td>\n",
       "      <td>-1.494097e+00</td>\n",
       "      <td>-2.125878e+00</td>\n",
       "      <td>-8.288539e-01</td>\n",
       "      <td>-1.366984e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.662382e-01</td>\n",
       "      <td>-6.736099e-01</td>\n",
       "      <td>-8.786088e-01</td>\n",
       "      <td>-7.314700e-01</td>\n",
       "      <td>-3.924767e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.704971e-02</td>\n",
       "      <td>-1.266184e-01</td>\n",
       "      <td>4.751672e-02</td>\n",
       "      <td>-2.750752e-01</td>\n",
       "      <td>-3.576084e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.089713e-01</td>\n",
       "      <td>4.203731e-01</td>\n",
       "      <td>9.460693e-01</td>\n",
       "      <td>2.736806e-01</td>\n",
       "      <td>4.154175e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.871343e+00</td>\n",
       "      <td>4.659557e+00</td>\n",
       "      <td>1.513747e+00</td>\n",
       "      <td>3.904892e+00</td>\n",
       "      <td>6.658835e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       route_id                 date  wait_assessment  average_percipitation  \\\n",
       "count     21600                21600     2.160000e+04           2.160000e+04   \n",
       "unique      200                  108              NaN                    NaN   \n",
       "top          B1  2015-01-01 00:00:00              NaN                    NaN   \n",
       "freq        108                  200              NaN                    NaN   \n",
       "first       NaN  2015-01-01 00:00:00              NaN                    NaN   \n",
       "last        NaN  2023-12-01 00:00:00              NaN                    NaN   \n",
       "mean        NaN                  NaN    -1.631617e-16           1.553490e-16   \n",
       "std         NaN                  NaN     1.000023e+00           1.000023e+00   \n",
       "min         NaN                  NaN    -5.898618e+00          -1.494097e+00   \n",
       "25%         NaN                  NaN    -6.662382e-01          -6.736099e-01   \n",
       "50%         NaN                  NaN     3.704971e-02          -1.266184e-01   \n",
       "75%         NaN                  NaN     7.089713e-01           4.203731e-01   \n",
       "max         NaN                  NaN     2.871343e+00           4.659557e+00   \n",
       "\n",
       "            avg_temp  vehicle_count_automated_traffic_volume_counts  \\\n",
       "count   2.160000e+04                                   2.160000e+04   \n",
       "unique           NaN                                            NaN   \n",
       "top              NaN                                            NaN   \n",
       "freq             NaN                                            NaN   \n",
       "first            NaN                                            NaN   \n",
       "last             NaN                                            NaN   \n",
       "mean    1.049366e-16                                   1.672736e-16   \n",
       "std     1.000023e+00                                   1.000023e+00   \n",
       "min    -2.125878e+00                                  -8.288539e-01   \n",
       "25%    -8.786088e-01                                  -7.314700e-01   \n",
       "50%     4.751672e-02                                  -2.750752e-01   \n",
       "75%     9.460693e-01                                   2.736806e-01   \n",
       "max     1.513747e+00                                   3.904892e+00   \n",
       "\n",
       "        rolling_mean_diff  \n",
       "count        2.160000e+04  \n",
       "unique                NaN  \n",
       "top                   NaN  \n",
       "freq                  NaN  \n",
       "first                 NaN  \n",
       "last                  NaN  \n",
       "mean         2.631640e-18  \n",
       "std          1.000023e+00  \n",
       "min         -1.366984e+01  \n",
       "25%         -3.924767e-01  \n",
       "50%         -3.576084e-03  \n",
       "75%          4.154175e-01  \n",
       "max          6.658835e+00  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the numerical columns in the filtered_df dataframe\n",
    "scaler = StandardScaler()\n",
    "filtered_df[['wait_assessment', 'average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts', 'rolling_mean_diff']] = scaler.fit_transform(filtered_df[['wait_assessment', 'average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts', 'rolling_mean_diff']])\n",
    "filtered_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime data type\n",
    "filtered_df[\"date\"] = pd.to_datetime(filtered_df[\"date\"])\n",
    "\n",
    "# Set the date column as the index\n",
    "filtered_df = filtered_df.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Model Looping through the Valid Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "c:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B1': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CC915660>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CC9156F0>, 'route_id': 'B1'}, 'B100': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CC9143D0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CC7B0190>, 'route_id': 'B100'}, 'B103': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CC915150>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CC7B0A00>, 'route_id': 'B103'}, 'B11': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CC7B0910>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CC7B18A0>, 'route_id': 'B11'}, 'B12': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CC7B1F00>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CD058220>, 'route_id': 'B12'}, 'B13': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CC7B1A50>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CD059B10>, 'route_id': 'B13'}, 'B14': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CD058D00>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CD05A500>, 'route_id': 'B14'}, 'B15': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CD05A380>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CD0E8700>, 'route_id': 'B15'}, 'B16': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CD059ED0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CD0E9F90>, 'route_id': 'B16'}, 'B17': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CD0EAA40>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CD0EB610>, 'route_id': 'B17'}, 'B2': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CD0E8BB0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CCFB0F70>, 'route_id': 'B2'}, 'B20': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CCFB17E0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CCFB2530>, 'route_id': 'B20'}, 'B24': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CCFB1510>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CCFB3A00>, 'route_id': 'B24'}, 'B25': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CCFB2770>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CCF31210>, 'route_id': 'B25'}, 'B26': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CCF31510>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CCF32860>, 'route_id': 'B26'}, 'B3': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CCF31840>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268CCF315A0>, 'route_id': 'B3'}, 'B31': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268CCF32B60>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268E1D75600>, 'route_id': 'B31'}, 'B32': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268E1D742B0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268E1D76B00>, 'route_id': 'B32'}, 'B35': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268E1D77610>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268E1DEC460>, 'route_id': 'B35'}, 'B36': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268E1D75780>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268E1DED9C0>, 'route_id': 'B36'}, 'B37': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268E1DEC970>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268E1DEEEC0>, 'route_id': 'B37'}, 'B38': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268E1DEC220>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268E9E5C850>, 'route_id': 'B38'}, 'B4': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268E1DEF2E0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268E9E5DDB0>, 'route_id': 'B4'}, 'B41': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268E9E5CDF0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268E9E5F2B0>, 'route_id': 'B41'}, 'B43': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268E9E5FE50>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268E9ED0C40>, 'route_id': 'B43'}, 'B44': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268E9E5DF30>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268E9ED2170>, 'route_id': 'B44'}, 'B45': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268E9ED1120>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268E9ED36A0>, 'route_id': 'B45'}, 'B46': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268E9ED09A0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FD350EE0>, 'route_id': 'B46'}, 'B47': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268E9ED2320>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FD3523E0>, 'route_id': 'B47'}, 'B48': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FD352F20>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FD353A60>, 'route_id': 'B48'}, 'B49': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FD352830>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FD3C1360>, 'route_id': 'B49'}, 'B52': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FD3C1C60>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FD3C29E0>, 'route_id': 'B52'}, 'B54': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FD3C3310>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FD3C3E50>, 'route_id': 'B54'}, 'B57': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FD3C1150>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FD3C2D40>, 'route_id': 'B57'}, 'B6': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF3DC370>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF3DEB90>, 'route_id': 'B6'}, 'B60': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF3DD9C0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF44C250>, 'route_id': 'B60'}, 'B61': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF3DC7C0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF44D900>, 'route_id': 'B61'}, 'B62': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF44C6A0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF44EF80>, 'route_id': 'B62'}, 'B63': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF44F970>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF4C8640>, 'route_id': 'B63'}, 'B64': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF44DD80>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF4C9CC0>, 'route_id': 'B64'}, 'B65': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF4CA6B0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF4CB340>, 'route_id': 'B65'}, 'B67': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF4CA4D0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF550A00>, 'route_id': 'B67'}, 'B68': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF4CBA00>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF5520E0>, 'route_id': 'B68'}, 'B69': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF550EB0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF553760>, 'route_id': 'B69'}, 'B7': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF5523E0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF5B0E20>, 'route_id': 'B7'}, 'B70': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF5B01C0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF5B24A0>, 'route_id': 'B70'}, 'B74': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF5B1240>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF5B3B20>, 'route_id': 'B74'}, 'B8': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF5B1630>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF6291E0>, 'route_id': 'B8'}, 'B82': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF629CF0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF62A860>, 'route_id': 'B82'}, 'B83': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF62B370>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF6A81C0>, 'route_id': 'B83'}, 'B84': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF62AEF0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF6A92D0>, 'route_id': 'B84'}, 'B9': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF6A9FC0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF6AAC50>, 'route_id': 'B9'}, 'BX1': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF6AB760>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF7182E0>, 'route_id': 'BX1'}, 'BX10': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF6A9A50>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF719990>, 'route_id': 'BX10'}, 'BX11': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF718640>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF71B010>, 'route_id': 'BX11'}, 'BX12': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF71BB20>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF7946D0>, 'route_id': 'BX12'}, 'BX13': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF71B6A0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF795D50>, 'route_id': 'BX13'}, 'BX15': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF796860>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF7973D0>, 'route_id': 'BX15'}, 'BX16': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF797F10>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF810AC0>, 'route_id': 'BX16'}, 'BX17': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF7961D0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF812140>, 'route_id': 'BX17'}, 'BX19': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF812C80>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF813820>, 'route_id': 'BX19'}, 'BX2': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF8125F0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF874EE0>, 'route_id': 'BX2'}, 'BX21': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF875A20>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF876590>, 'route_id': 'BX21'}, 'BX22': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF875210>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF877C10>, 'route_id': 'BX22'}, 'BX23': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF876B90>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF8ED2D0>, 'route_id': 'BX23'}, 'BX24': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF8EDDE0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF8EE950>, 'route_id': 'BX24'}, 'BX26': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF8ED870>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF95C160>, 'route_id': 'BX26'}, 'BX27': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF8EEF50>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF95D6C0>, 'route_id': 'BX27'}, 'BX28': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF95C3A0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF95ED40>, 'route_id': 'BX28'}, 'BX29': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF95F8B0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF9D8430>, 'route_id': 'BX29'}, 'BX3': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF95F400>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF9D9AB0>, 'route_id': 'BX3'}, 'BX30': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF9D8880>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FF9DB130>, 'route_id': 'BX30'}, 'BX31': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF9DA350>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFA607F0>, 'route_id': 'BX31'}, 'BX32': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FF9D9F30>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFA61E70>, 'route_id': 'BX32'}, 'BX33': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFA62980>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFA634F0>, 'route_id': 'BX33'}, 'BX34': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFA62710>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFAD0BB0>, 'route_id': 'BX34'}, 'BX35': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFA622F0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFAD2230>, 'route_id': 'BX35'}, 'BX36': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFAD2D70>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFAD38B0>, 'route_id': 'BX36'}, 'BX38': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFAD0FA0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFB44F70>, 'route_id': 'BX38'}, 'BX39': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFB45A80>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFB465F0>, 'route_id': 'BX39'}, 'BX4': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFB452A0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFB47C70>, 'route_id': 'BX4'}, 'BX40': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFB453F0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFBB5330>, 'route_id': 'BX40'}, 'BX41': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFBB5EA0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFBB69B0>, 'route_id': 'BX41'}, 'BX42': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFBB74C0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFC2C070>, 'route_id': 'BX42'}, 'BX46': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFBB57B0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFC2D6F0>, 'route_id': 'BX46'}, 'BX4A': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFC2E200>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFC2ED70>, 'route_id': 'BX4A'}, 'BX5': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFC2DC90>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFCA4400>, 'route_id': 'BX5'}, 'BX6': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFC2DB70>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFCA5AB0>, 'route_id': 'BX6'}, 'BX7': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFCA64A0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFCA7130>, 'route_id': 'BX7'}, 'BX8': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFCA7C10>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFD28820>, 'route_id': 'BX8'}, 'BX9': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFCA5F30>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFD29E70>, 'route_id': 'BX9'}, 'M1': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFD2A950>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFD2B4F0>, 'route_id': 'M1'}, 'M10': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFD2A410>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFDA0BB0>, 'route_id': 'M10'}, 'M101': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFD2A2F0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFDA2260>, 'route_id': 'M101'}, 'M102': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFDA0EE0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000268FFDA38E0>, 'route_id': 'M102'}, 'M103': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFDA2560>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026902D74FA0>, 'route_id': 'M103'}, 'M104': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000268FFDA2BF0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026902D76620>, 'route_id': 'M104'}, 'M106': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026902D75540>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026902D77CA0>, 'route_id': 'M106'}, 'M11': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026902D76C20>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026902DE9360>, 'route_id': 'M11'}, 'M116': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026902DE9F00>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026902DEAA10>, 'route_id': 'M116'}, 'M12': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026902DEB4F0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026906DA00A0>, 'route_id': 'M12'}, 'M15': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026902DEB040>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026906DA1720>, 'route_id': 'M15'}, 'M2': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026906DA2290>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026906DA2DD0>, 'route_id': 'M2'}, 'M20': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026906DA38B0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026906E18460>, 'route_id': 'M20'}, 'M21': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026906DA33D0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026906E19B10>, 'route_id': 'M21'}, 'M22': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026906E1A650>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026906E1B190>, 'route_id': 'M22'}, 'M3': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026906E1BCD0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690ADD4880>, 'route_id': 'M3'}, 'M31': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026906E19F90>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690ADD5ED0>, 'route_id': 'M31'}, 'M34': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690ADD69E0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690ADD7550>, 'route_id': 'M34'}, 'M34A': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690ADD7F40>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690AE54C10>, 'route_id': 'M34A'}, 'M4': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690ADD4DC0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690AE562F0>, 'route_id': 'M4'}, 'M42': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690AE56E60>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690AE57940>, 'route_id': 'M42'}, 'M5': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690AE55000>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690AEB9000>, 'route_id': 'M5'}, 'M50': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690AEB9B70>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690AEBA6E0>, 'route_id': 'M50'}, 'M57': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690AEB9AB0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690AEBBA60>, 'route_id': 'M57'}, 'M66': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690AEBAD10>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690DEA53F0>, 'route_id': 'M66'}, 'M7': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690DEA5F30>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690DEA6A70>, 'route_id': 'M7'}, 'M72': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690DEA7550>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690DF0C130>, 'route_id': 'M72'}, 'M8': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690DEA7070>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690DF0D7B0>, 'route_id': 'M8'}, 'M9': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690DF0E1A0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002690DF0EE30>, 'route_id': 'M9'}, 'M96': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690DF0F940>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026911EC84C0>, 'route_id': 'M96'}, 'Q1': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002690DF0DC30>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026911EC9B70>, 'route_id': 'Q1'}, 'Q10': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026911EC8820>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026911ECB1F0>, 'route_id': 'Q10'}, 'Q100': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026911ECA110>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026911F488B0>, 'route_id': 'Q100'}, 'Q101': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026911ECB7F0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026911F49F30>, 'route_id': 'Q101'}, 'Q102': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026911F4AA70>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026911F4B5E0>, 'route_id': 'Q102'}, 'Q103': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026911F48D30>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026915EE8CA0>, 'route_id': 'Q103'}, 'Q104': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026915EE97B0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026915EEA320>, 'route_id': 'Q104'}, 'Q11': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026915EE8FD0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026915EEB9A0>, 'route_id': 'Q11'}, 'Q12': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026915EE9090>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026915F69060>, 'route_id': 'Q12'}, 'Q13': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026915F69B70>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026915F6A6E0>, 'route_id': 'Q13'}, 'Q15': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026915F6B1F0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026919F20040>, 'route_id': 'Q15'}, 'Q15A': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026915F6A9E0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026919F211B0>, 'route_id': 'Q15A'}, 'Q16': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026919F21D20>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026919F22AA0>, 'route_id': 'Q16'}, 'Q17': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026919F233A0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026919F21510>, 'route_id': 'Q17'}, 'Q18': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026919F22A70>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026919F815D0>, 'route_id': 'Q18'}, 'Q2': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026919F820E0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026919F82C50>, 'route_id': 'Q2'}, 'Q20A': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026919F837C0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002691DF34340>, 'route_id': 'Q20A'}, 'Q21': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026919F819C0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002691DF359C0>, 'route_id': 'Q21'}, 'Q22': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002691DF364D0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002691DF37040>, 'route_id': 'Q22'}, 'Q24': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002691DF37AF0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002691DFB4700>, 'route_id': 'Q24'}, 'Q27': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002691DF35E40>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002691DFB5D80>, 'route_id': 'Q27'}, 'Q28': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002691DFB68F0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002691DFB7400>, 'route_id': 'Q28'}, 'Q29': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002691DFB7F10>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026921F70AC0>, 'route_id': 'Q29'}, 'Q3': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002691DFB6200>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026921F72170>, 'route_id': 'Q3'}, 'Q30': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026921F72CB0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026921F737F0>, 'route_id': 'Q30'}, 'Q31': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026921F72470>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026921FD8EE0>, 'route_id': 'Q31'}, 'Q32': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026921FD9A20>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026921FDA560>, 'route_id': 'Q32'}, 'Q33': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026921FDB070>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026921FDBBE0>, 'route_id': 'Q33'}, 'Q35': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026921FD9360>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000269220512A0>, 'route_id': 'Q35'}, 'Q36': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269220503A0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026922052920>, 'route_id': 'Q36'}, 'Q39': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026922053430>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026925FF8100>, 'route_id': 'Q39'}, 'Q4': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026922051720>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026925FF9660>, 'route_id': 'Q4'}, 'Q40': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026925FFA170>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026925FFACE0>, 'route_id': 'Q40'}, 'Q41': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026925FFB7F0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002692607C2E0>, 'route_id': 'Q41'}, 'Q43': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026925FF9AE0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002692607DA50>, 'route_id': 'Q43'}, 'Q46': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002692607E560>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002692607F0D0>, 'route_id': 'Q46'}, 'Q47': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002692607E1D0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026929068790>, 'route_id': 'Q47'}, 'Q48': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002692607F760>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026929069E10>, 'route_id': 'Q48'}, 'Q49': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002692906A950>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002692906B490>, 'route_id': 'Q49'}, 'Q5': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002692906BFA0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000269290DCB50>, 'route_id': 'Q5'}, 'Q50': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002692906A290>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000269290DE1D0>, 'route_id': 'Q50'}, 'Q54': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269290DECE0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000269290DF850>, 'route_id': 'Q54'}, 'Q55': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269290DD240>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002692D084F10>, 'route_id': 'Q55'}, 'Q56': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269290DD3F0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002692D0865C0>, 'route_id': 'Q56'}, 'Q58': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002692D087070>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002692D087C40>, 'route_id': 'Q58'}, 'Q59': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002692D085390>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002692D0FD300>, 'route_id': 'Q59'}, 'Q6': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002692D0FC070>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002692D0FE980>, 'route_id': 'Q6'}, 'Q60': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002692D0FF490>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000269310B8040>, 'route_id': 'Q60'}, 'Q67': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002692D0FD780>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000269310B96C0>, 'route_id': 'Q67'}, 'Q69': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269310B8370>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000269310BAD70>, 'route_id': 'Q69'}, 'Q7': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269310B9E40>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026931130400>, 'route_id': 'Q7'}, 'Q72': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269310BB400>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026931131AB0>, 'route_id': 'Q72'}, 'Q76': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269311325C0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026931133130>, 'route_id': 'Q76'}, 'Q8': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026931133B20>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693411C7F0>, 'route_id': 'Q8'}, 'Q83': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026931131F30>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693411DE70>, 'route_id': 'Q83'}, 'Q84': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693411E920>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693411F4F0>, 'route_id': 'Q84'}, 'Q85': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693411E6B0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693419CBB0>, 'route_id': 'Q85'}, 'Q88': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693411E2F0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693419E230>, 'route_id': 'Q88'}, 'Q9': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693419CEE0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693419F8B0>, 'route_id': 'Q9'}, 'S40': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693419D2D0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026934200F70>, 'route_id': 'S40'}, 'S44': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026934201A80>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000269342025F0>, 'route_id': 'S44'}, 'S46': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269342016F0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026934203C70>, 'route_id': 'S46'}, 'S48': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026934202C80>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000269381B9330>, 'route_id': 'S48'}, 'S51': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269381B9E40>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000269381BA9B0>, 'route_id': 'S51'}, 'S52': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269381B9AB0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693822C070>, 'route_id': 'S52'}, 'S53': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269381B97B0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693822D6F0>, 'route_id': 'S53'}, 'S57': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693822E200>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693822ED70>, 'route_id': 'S57'}, 'S59': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693822DF00>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693C1E0400>, 'route_id': 'S59'}, 'S61': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693822DB70>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693C1E1AB0>, 'route_id': 'S61'}, 'S62': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693C1E25C0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693C1E3130>, 'route_id': 'S62'}, 'S74': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693C1E3CA0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693C2607F0>, 'route_id': 'S74'}, 'S76': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693C1E37C0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693C261E70>, 'route_id': 'S76'}, 'S78': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693C262950>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002693C2634F0>, 'route_id': 'S78'}, 'SB44': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693C262680>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026940218BB0>, 'route_id': 'SB44'}, 'SBS12': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x000002693C263BB0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002694021A230>, 'route_id': 'SBS12'}, 'SBS15': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026940218EE0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x000002694021B8B0>, 'route_id': 'SBS15'}, 'SBS41': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269402192D0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026940284F70>, 'route_id': 'SBS41'}, 'SBS60': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x0000026940285A80>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x00000269402865F0>, 'route_id': 'SBS60'}, 'SBS79': {'model': <statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper object at 0x00000269402856F0>, 'predictions': <statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper object at 0x0000026940287C70>, 'route_id': 'SBS79'}}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store the models, predictions, and route_ids\n",
    "sarimax_results = {}\n",
    "\n",
    "# Iterate over the unique route_ids\n",
    "for route_id in filtered_df['route_id'].unique():\n",
    "    # Filter the data for the current route_id\n",
    "    route_data = filtered_df[filtered_df['route_id'] == route_id]\n",
    "    \n",
    "    # Set the frequency of the index to monthly\n",
    "    route_data.index = pd.date_range(start='2015-01-01', periods=len(route_data), freq='M')\n",
    "    \n",
    "    # Define the endogenous variable (target)\n",
    "    endog = route_data['rolling_mean_diff']\n",
    "\n",
    "    # Define the exogenous variables\n",
    "    exog = route_data[['average_percipitation', 'avg_temp', 'vehicle_count_automated_traffic_volume_counts']]\n",
    "    \n",
    "    # Add a constant to the exogenous variables\n",
    "    exog = sm.add_constant(exog)\n",
    "    \n",
    "    # Perform test/train split\n",
    "    train_size = 0.8  # You can adjust this ratio as needed\n",
    "    endog_train, endog_test, exog_train, exog_test = train_test_split(\n",
    "    endog, exog, train_size=train_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Set the frequency of the time series to monthly\n",
    "    freq = 'M'\n",
    "    \n",
    "    # Create the SARIMAX model\n",
    "    model = sm.tsa.SARIMAX(endog_train, exog = exog_train, order=(0, 1, 0), seasonal_order=(0, 1, 1, 12), freq = freq)\n",
    "    \n",
    "    # Fit the model\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    forecast = model_fit.get_forecast(steps=len(endog_test), exog=exog_test)\n",
    "    \n",
    "    # Save the model, predictions, and route_id to the dictionary\n",
    "    sarimax_results[route_id] = {'model': model_fit, 'predictions': forecast, 'route_id': route_id}\n",
    "\n",
    "# Print the dictionary of models, predictions, and route_ids\n",
    "print(sarimax_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dashboard to visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dropdown with unique route_ids\n",
    "route_id_options = [{'label': str(route_id), 'value': route_id} for route_id in sarimax_results.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dash app\n",
    "app = dash.Dash(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.Label('Select Route Id:', style={'font-weight': 'bold', 'margin-bottom': '10px'}),\n",
    "    dcc.Dropdown(\n",
    "        id='route-id-dropdown',\n",
    "        options=route_id_options,\n",
    "        value=route_id_options[0]['value'],\n",
    "        style={'width': '50%', 'margin-bottom': '20px'}\n",
    "    ),\n",
    "    dcc.Graph(id='time-series-plot',\n",
    "        config={'displayModeBar': False})\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback to update the plot based on the selected Route Id\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('time-series-plot', 'figure'),\n",
    "    [dash.dependencies.Input('route-id-dropdown', 'value')]\n",
    ")\n",
    "def update_plot(selected_route_id):\n",
    "    # Retrieve model and predictions for the selected Route Id\n",
    "    model_fit = sarimax_results[selected_route_id]['model']\n",
    "    predictions = sarimax_results[selected_route_id]['predictions']\n",
    "    route_data = filtered_df[filtered_df['route_id'] == selected_route_id]\n",
    "    endog_train = route_data['rolling_mean_diff'][:int(len(route_data) * 0.8)]\n",
    "    endog_test = route_data['rolling_mean_diff'][int(len(route_data) * 0.8):]\n",
    "\n",
    "    # Plot actual values from the training set\n",
    "    trace1 = go.Scatter(x=endog_train.index, y=endog_train, mode='lines', name='Actual (Training Set)', line=dict(color='blue'))\n",
    "\n",
    "    # Plot actual values from the test set\n",
    "    trace2 = go.Scatter(x=endog_test.index, y=endog_test, mode='lines', name='Actual (Test Set)', line=dict(color='blue', dash='dash'))\n",
    "\n",
    "    # Plot predicted values from the test set\n",
    "    trace3 = go.Scatter(x=endog_test.index, y=predictions.predicted_mean.to_numpy(), mode='lines', name='Predicted (Test Set)', line=dict(color='orange'))\n",
    "\n",
    "    # Set layout options\n",
    "    layout = dict(\n",
    "        title='Actual vs Predicted Values',\n",
    "        xaxis=dict(title='Date'),\n",
    "        yaxis=dict(title='Wait Assessment'),\n",
    "        legend=dict(x=0, y=1, traceorder='normal')\n",
    "    )\n",
    "\n",
    "    # Create the figure\n",
    "    figure = dict(data=[trace1, trace2, trace3], layout=layout)\n",
    "\n",
    "    return figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, use_reloader=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
